[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Decizie și estimare în prelucrarea informației (DEPI)",
    "section": "",
    "text": "Prefață\nAceastă carte cuprinde notele de curs pentru disciplina “Decizie și estimare în prelucrarea informației”, predată la Facultatea de Electronică, Telecomunicații și Tehnologia Informației (ETTI), din cadrul Universității Tehnice “Gheorghe Asachi” din Iași.\n\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "01_Intro.html",
    "href": "01_Intro.html",
    "title": "Introducere",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "01_01_VariabileAleatoare.html#definiții",
    "href": "01_01_VariabileAleatoare.html#definiții",
    "title": "1  Variabile aleatoare",
    "section": "1.1 Definiții",
    "text": "1.1 Definiții\nO variabilă aleatoare (v.a.) este o variabilă care denumește o valoare produsă printr-un fenomen aleator. Practic, reprezintă un nume \\(X\\), \\(Y\\) etc. atașat unei valori arbitrare.\nO realizare a unei variabile aleatoare este o valoare particulară posibilă pe care o poate lua respectiva variabilă.\nSpațiul realizărilor \\(\\Omega\\) este mulțimea tuturor realizărilor (mulțimea tuturor valorilor posibile ale unei variabile aleatoare).\nO variabilă aleatoare este discretă dacă \\(\\Omega\\) este o mulțime discretă, sau continuă dacă \\(\\Omega\\) este o mulțime compactă.\nVariabilele aleatoare modelează semnale afectate de zgomot, cum ar fi un semnal de tensiune într-un circuit electric (zgomot termic etc), sau imagini afectate de zgomot\n\n\n\n\n\n\nExemple\n\n\n\n\nFie \\(Z\\) = numărul obținut prin aruncarea unui zar. Spațiul realizărilor este \\[\\Omega = \\left\\{1, 2, 3, 4, 5, 6\\right\\}\\] \\(Z\\) este o variabilă aleatoare discretă.\nFie \\(V_{in}\\) = voltajul măsurat al unei baterii. Spațiul realizărilor este \\[\\Omega = [1, 1.7] V\\] \\(V_in\\) este o variabilă aleatoare continuă.\nFie \\(X\\) = rezultatul obținut la aruncarea unei monede, notat cu 0 sau 1. Spațiul realizărilor este \\[\\Omega = \\lbrace 0, 1 \\rbrace V\\] \\(X\\) este o variabilă aleatoare discretă.\n\n(sursa imaginii: https://www.mathsisfun.com/data/random-variables.html)\n\nMai jos sunt ilustrate câteva o serie de semnale afectate de zgomot.\n\nSemnal sinusoidal\n\nimport matplotlib.pyplot as plt, numpy as np, math;\nx = np.linspace(0, 99, 100);\ns = np.sin(2*math.pi*0.02*x)\nplt.figure(figsize=(10,6));\nplt.plot(x,s);\nplt.ylim(-3,3)\nplt.xlabel('t');\nplt.ylabel('sin(x)');\nplt.title('Sinusiodal signal');\nplt.savefig('fig/01_RandomSignals_Sine.png', transparent=True, bbox_inches='tight', dpi=300)\nplt.close()\n\n\nSemnal sinusoidal + zgomot (distribuție normală, \\(\\mu = 0, \\sigma^2 = 1\\))\n\nimport matplotlib.pyplot as plt, numpy as np, math;\nx = np.linspace(0, 99, 100);\ns = np.sin(2*math.pi*0.02*x)\nsn = s + np.random.randn(100)\nplt.plot(x,s, x, sn);\nplt.ylim(-3,3)\nplt.xlabel('t');\nplt.ylabel('sin(x)');\nplt.title('Sinusiodal signal + random noise');\nplt.savefig('fig/01_RandomSignals_SinePlusRandn.png', transparent=True, bbox_inches='tight', dpi=300)\nplt.close()\n\n\nSemnal sinusoidal + zgomot + zgomot (distribuție uniformă \\(\\mathcal{U} [-1,1]\\))\nCe diferă? Tipul distribuției\n\nimport matplotlib.pyplot as plt, numpy as np, math;\nx = np.linspace(0, 99, 100);\ns = np.sin(2*math.pi*0.02*x)\nsn = s + np.random.uniform(-1,1,100)\nplt.plot(x,s,x,sn);\nplt.ylim(-3,3)\nplt.xlabel('t');\nplt.ylabel('sin(x)');\nplt.title('Sinusiodal signal  + random noise');\nplt.savefig('fig/01_RandomSignals_SinePlusRand.png', transparent=True, bbox_inches='tight', dpi=300)\nplt.close()\n\n\nImagine originală\n\nimport matplotlib.pyplot as plt, numpy as np, math, PIL;\nfrom PIL import Image\nmyImage = Image.open(\"img/TestImageGirl.gif\").convert(\"L\");\nim = np.array(myImage)\nplt.imshow(im, cmap='gray', vmin=0, vmax=255)\nplt.savefig('fig/01_RandomSignals_ImageClean.png', transparent=True, bbox_inches='tight', dpi=300)\nplt.close()\n\n\nImagine + zgomot (normal, \\(\\mu = 0, \\sigma^2 = 1\\))\n\nimport matplotlib.pyplot as plt, numpy as np, math, PIL;\nfrom PIL import Image\nmyImage = Image.open(\"img/TestImageGirl.gif\").convert(\"L\");\nim = np.array(myImage)\nsigma = math.sqrt(225);\nimn = im + sigma*np.random.randn(im.shape[0], im.shape[1])\nplt.imshow(imn, cmap='gray', vmin=0, vmax=255)\nplt.savefig('fig/01_RandomSignals_ImageRandn1.png', transparent=True, bbox_inches='tight', dpi=300)\nplt.close()\n\n\nImagine + zgomot mai mare (normal, \\(\\mu = 0, \\sigma^2 = 10\\))\n\nimport matplotlib.pyplot as plt, numpy as np, math, PIL;\nfrom PIL import Image\nmyImage = Image.open(\"img/TestImageGirl.gif\").convert(\"L\");\nim = np.array(myImage)\nsigma = math.sqrt(1500);\nimn = im + sigma*np.random.randn(im.shape[0], im.shape[1])\nplt.imshow(imn, cmap='gray', vmin=0, vmax=255)\nplt.savefig('fig/01_RandomSignals_ImageRandn2.png', transparent=True, bbox_inches='tight', dpi=300)\nplt.close()\n\n\nImagine + zgomot (uniform, \\(\\mathcal{U} [-5, 5]\\))\n\nimport matplotlib.pyplot as plt, numpy as np, math, PIL;\nfrom PIL import Image\nmyImage = Image.open(\"img/TestImageGirl.gif\").convert(\"L\");\nim = np.array(myImage)\nimn = im + sigma*np.random.uniform(-5, 5, im.shape)\nplt.imshow(imn, cmap='gray', vmin=0, vmax=255)\nplt.savefig('fig/01_RandomSignals_ImageRandUnif.png', transparent=True, bbox_inches='tight', dpi=300)\nplt.close()"
  },
  {
    "objectID": "01_01_VariabileAleatoare.html#densitate-de-probabilitate",
    "href": "01_01_VariabileAleatoare.html#densitate-de-probabilitate",
    "title": "1  Variabile aleatoare",
    "section": "1.2 Densitate de probabilitate",
    "text": "1.2 Densitate de probabilitate\n\n1.2.1 Pentru variabile aleatoare discrete\nVariabilele aleatoare discrete sunt caracterizate prin două funcții: funcția masă de probabilitate (discretă) și funcția de repartiție (care e “în trepte”).\nFie o v.a. discretă \\(A\\). Se definește funcția masă de probabilitate (FMP) (“probability mass function”, lb.eng.) \\(w_A(x)\\) ca fiind probabilitatea ca \\(A\\) să aibă valoarea egală cu \\(x\\): \\[w_A(x)= P \\left\\{A = x \\right\\}\\]\nFuncția de repartiție (FR) \\(F_A(x)\\) a unei variabile aleatoare \\(A\\) reprezintă probabilitatea ca \\(A\\) să aibă valoarea mai mică sau egală cu \\(x\\): \\[F_A(x) = P\\left\\{ A \\leq x \\right\\}\\]\nFMP se poate utiliza pentru a calcula probabilitatea unor valori:\n\nProbabilitatea ca \\(A\\) să aibă valoarea \\(v\\): \\[P\\left\\{ A = v\\right\\} = w_A(v)\\]\nProbabilitatea ca A să fie între valorile \\(a\\) și \\(b\\) (inclusiv): \\[P\\left\\{ a \\leq A \\leq b\\right\\} = \\sum_{x=a}^b w_A(x)\\]\n\nȘi funcția de repartiție poate fi folosită pentru a calcula diverse probabiități:\n\nProbabilitatea ca \\(A\\) să aibă valoarea \\(v\\): \\[P\\left\\{ A = v\\right\\} = F_A(v) - F_A(v-1)\\]\nProbabilitatea ca A să fie între valorile \\(a\\) și \\(b\\) (inclusiv): \\[P\\left\\{ a \\leq A \\leq b\\right\\} = P\\left\\{ A \\leq b\\right\\} - P\\left\\{ A \\leq a\\right\\} = F_A(b) - F_A(a-1)\\]\n\nÎntre funcția masă de probabilitate și funcția de repartiție există următoarea legătură. FR este suma cumulativă (un fel de “integrală discretă”) a FMP: \\[F_A(x) = \\sum_{t = -\\infty}^{t = x} w_A(t)\\]\nFMP mai e numită, în limbaj uzual, “distribuția” variabilei aleatoare.\n\n\n\n\n\n\nExemplu\n\n\n\nFuncția masă de probabilitate pentru valoarile unui zar este următoarea:\n\nFuncția de repartiție a valorilor unui zar este următoarea:\n\nPentru variabile aleatoare discrete, funcția de repartiție este întotdeauna “în trepte”.\n\n\n\n\n1.2.2 Pentru variabile aleatoare continue\nVariabilele aleatoare continue sunt caracterizate prin două funcții: funcția densitate de probabilitate și funcția de repartiție.\nFie o variabilă aleatoare continuă \\(A\\). Funcția densitate de probabilitate (FDP) \\(w_A(x)\\) se definește ca probabilitatea ca valoarea lui \\(A\\) să fie într-o vecinătate \\(\\epsilon\\) mică în jurul lui \\(x\\), împărțit la \\(\\epsilon\\) \\[w_A(x) = \\lim_{\\epsilon \\to 0}{\\frac{P(A \\in [x, x+\\epsilon])}{\\epsilon}}\\]\n\n\n\n\n\n\nÎn limbaj informal, densitatea de probabilitate poate fi numită mai simplu “distribuția” variabilei A.\n\n\n\nFuncția de repartiție (FR) \\(F_A(x)\\) se definește la fel ca la variabile discrete, adică reprezintă probabilitatea ca \\(A\\) să aibă valoarea mai mică sau egală cu \\(x\\): \\[F_A(x) = P\\left\\{ A \\leq x \\right\\}\\]\nÎntre cele două funcții există următoarea legătură. Funcția de repartiție este integrala densității de probabilitate, sau, altfel spus, densitatea de probabilitate este derivata funcției de repartiție: \\[F_A(x) = \\int_{-\\infty}^x w_A(u) \\mathrm{d}u\\]\n\\[\\begin{split}\nw_A(x) &= \\lim_{\\epsilon \\to 0}{\\frac{P(A \\in [x, x+\\epsilon])}{\\epsilon}} \\\\\n&= \\lim_{\\epsilon \\to 0}{\\frac{P(A \\leq x+\\epsilon) - P(A \\leq x)}{\\epsilon}} \\\\\n&= \\lim_{\\epsilon \\to 0}{\\frac{F_A(x+\\epsilon) - F_A(x)}{\\epsilon}} \\\\\n&= \\frac{\\mathrm{d}F_A(x)}{\\mathrm{d}x} = F'_A(x)\n\\end{split}\\]\n\n\n\n\n\n\nDensitatea are o definiție identică în fizică:\n\\[\\rho(x) = \\frac{dM}{dV}\\]\nDensitatea unui punct = derivata masei = masa unei mic volum V în jurul acelui punct împărțit la volumul V, pentru \\(V \\to 0\\).\n\n\n\nDensitatea de probabilitate se poate folosi pentru a calcula probabilități, dar numai prin integrare:\n\nProbabilitatea ca A să fie între valorile \\(a\\) și \\(b\\) = integrala FDP între \\(a\\) și \\(b\\): \\[P\\left\\{ a \\leq A \\leq b\\right\\} = \\int_a^b w_A(x) dx\\]\n\n(sursa: “https://intellipaat.com/blog/tutorial/statistics-and-probability-tutorial/probability-distributions-of-continuous-variables/*)\nProbabilitatea ca \\(A\\) să aibă exact valoarea \\(v\\) este întotdeauna 0 \\[P\\left\\{ A = v\\right\\} = \\int_v^v w_A(x) dx = 0\\]\n(în interpretarea grafică, aria de sub un punct este nulă)\n\nFuncția de repartiție se poate folosi de asemenea pentru calculul unor probabilități, în mod direct, la fel ca la variabile discrete:\n\nProbabilitatea ca valoarea lui A să fie între \\(a\\) și \\(b\\): \\[P\\left\\{ a \\leq A \\leq b\\right\\} = F_A(b) - F_A(a)\\]\nNu contează dacă se consideră un interval deschis sau închis: \\[P\\left\\{ a \\leq A \\leq b\\right\\} = P\\left\\{ a < A < b\\right\\}\\]\n\n\n\n1.2.3 Interpretarea densității de probabilitate\nO variabilă aleatoare continuă poate lua o infinitate de valori posibile. Așadar, probabilitatea ca o variabilă aleatoare continuă \\(A\\) să ia exact o anume valoare precisă \\(x\\), dintr-o infinitate de alternative, este întotdeauna zero.\nAtunci ce ne spune densitatea de probabilitate \\(w_A(x)\\)?\nDensitatea de probabilitate \\(w_A(x)\\) într-un punct \\(x = x_1\\) ne spune probabilitatea ca \\(A\\) să ia valori în jurul acelei valori \\(x_1\\), comparativ cu a lua valori în jurul unei alte valori \\(x_2\\). Ea nu reprezintă probabilitatea unei valori anume, care este mereu zero.\nÎn consecință valorile lui \\(w_A(x)\\) se pot folosi în mod direct pentru comparații (“e mai probabil ca \\(A\\) să ia valori în jurul lui 5, sau în jurul lui 7?”), dar pentru calculul unor probabiltăți trebuie să apelăm mereu la integrala sa.\nLa variabile aleatoare discrete, funcția masă de probabilitate joacă același rol ca densitatea de probabilitate, cu diferența că ea ne dă chiar probabilitatea unei valori \\(x\\), nu doar probabilitatea de a fi în jurul lui \\(x\\). De asemenea, fiind funcții discrete, operația de integrare se înlocuiește cu o sumă.\n\n(sursa imaginii: “Probability Distributions: Discrete and Continuous”, Seema Singh, https://towardsdatascience.com/probability-distributions-discrete-and-continuous-7a94ede66dc0)\n\n\n1.2.4 Proprietăți ale funcțiilor de repartiție și de densitate\nFuncția de repartiție:\n\nFR este mereu pozitivă: \\[F_A(x) \\geq 0\\]\nFR este monoton crescătoare\nFR pornește din 0 și ajunge la valoarea 1: \\[F_A(-\\infty) = 0 \\;\\;\\;\\; F_A(\\infty) = 1\\]\n\nDensitatea de probabilitate / funcția masă de probabilitate:\n\nEste pozitivă: \\[w_A(x) \\geq 0\\]\nIntegrala/suma pe întreg domeniul este 1 \\[\\int_{-\\infty}^\\infty w_A(x) \\mathrm{d}x = 1 \\;\\;\\;\\; \\sum_{x = -\\infty}^\\infty w_A(x) = 1\\]"
  },
  {
    "objectID": "01_01_VariabileAleatoare.html#distribuția-normală",
    "href": "01_01_VariabileAleatoare.html#distribuția-normală",
    "title": "1  Variabile aleatoare",
    "section": "1.3 Distribuția normală",
    "text": "1.3 Distribuția normală\nÎn cele ce urmează, vom considera numai variabile aleatoare discrete.\nCea mai des întâlnită distribuție în practică este distribuția normală.\nDensitatea de probabilitate are expresia matematică: \\[w_A(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x-\\mu)^2}{2 \\sigma^2}}\\] și depinde de doi parametri:\n\nmedia \\(\\mu\\) definește “centrul” funcției\ndeviația standard \\(\\sigma\\) controlează “lățimea” funcției\n\n\\(\\sigma\\) mic = funcție îngustă și înaltă\n\\(\\sigma\\) mare = funcție largă și joasă\n\n\nimport matplotlib.pyplot as plt, numpy as np, math;\nmu = 3;\nsigma = 1;\nx = np.linspace(mu-5*sigma,mu+5*sigma,200);\npdf = 1/(sigma*math.sqrt(2*math.pi))*np.exp(-(x-mu)**2/(2*sigma**2)); #**\nplt.plot(x,pdf);\nplt.xlabel('x');\nplt.ylabel('fdp(x)');\nplt.title('The normal distribution $\\mathcal{N}(\\mu=3,\\sigma=1)$');\nplt.savefig('fig/01_RandomSignals_DistributionNormal.png', transparent=True, bbox_inches='tight', dpi=300)\nplt.close()\n\nTermenul \\(\\frac{1}{\\sigma \\sqrt{2 \\pi}}\\) de la începutul expresiei este o constantă care asigură normalizarea, adică faptul că probabilitatea totală (integrala totală) este 1: \\[\\int_{-\\infty}^\\infty w_A(x) \\mathrm{d}x = 1\\]\nDistribuția normală se notează cu \\(\\mathcal{N}(\\mu, \\sigma^2)\\).\nCând \\(\\mu=0\\) și \\(\\sigma=1\\) avem distribuția normală standard.\nCum interptetăm distribuția normală? Fie o variabilă aleatoare \\(A \\sim \\mathcal{N}(\\mu, \\sigma^2)\\) (\\(A\\) ia valori conform distribuției normale cu media \\(\\mu\\) și deviația \\(\\sigma\\)). Putem spune următoarele:\n\n\\(A\\) poate avea orice valoare \\(x \\in \\mathbb{R}\\), întrucât \\(w_A(x) > 0, \\forall x \\in \\mathbb{R}\\) (nici o valoare nu este a priori exclusă);\nValorile cele mai probabile ale lui \\(A\\) sunt în jurul mediei \\(\\mu\\);\nProbabilitatea unor valori \\(x\\) e mai mică cu cât \\(x\\) este mai îndepărtat de centrul \\(\\mu\\), datorită termenului \\(-(x - \\mu)^2\\) de la exponent\n\nDistribuția exprimă așadar o preferință pentru valori apropiate de \\(\\mu\\), cu probabilitate din ce în ce mai scăzută la valori mai depărtate de \\(\\mu\\).\n\n\n\n\n\n\nExemple\n\n\n\nExemple de valori generate cu distribuția normală standard \\(\\mathcal{N}(\\mu=0, \\sigma^2=1)\\):\nimport matplotlib.pyplot as plt, numpy as np, math;\nmu = 0;\nsigma = 1;\nx = np.linspace(1, 200, 200)\nv = mu + np.sqrt(sigma)*np.random.randn(200)\nplt.plot(x,v)\nplt.ylim(-5,5)\nplt.title('Sample values from the normal distribution');\nplt.savefig('fig/01_RandomSignals_DistributionNormalSampleValues1.png', transparent=True, bbox_inches='tight', dpi=300)\nplt.close()\n\nExemple de valori generate cu distribuția normală \\(\\mathcal{N}(\\mu=2, \\sigma^2=4)\\):\nimport matplotlib.pyplot as plt, numpy as np, math;\nmu = 2;\nsigma = 4;\nx = np.linspace(1, 200, 200)\nv = mu + np.sqrt(sigma)*np.random.randn(200)\nplt.plot(x,v)\nplt.ylim(-5,5)\nplt.title('Sample values from the normal distribution');\nplt.savefig('fig/01_RandomSignals_DistributionNormalSampleValues2.png', transparent=True, bbox_inches='tight', dpi=300)\nplt.close()"
  },
  {
    "objectID": "01_01_VariabileAleatoare.html#distribuția-uniformă",
    "href": "01_01_VariabileAleatoare.html#distribuția-uniformă",
    "title": "1  Variabile aleatoare",
    "section": "1.4 Distribuția uniformă",
    "text": "1.4 Distribuția uniformă\nDensitatea de probabilitate uniformă este o funcție constantă între două limite \\(a\\) și \\(b\\):\n\\[w_A(x) =\n\\begin{cases}\n\\frac{1}{b-a}, & x \\in [a, b] \\\\\n0, &\\textrm{elsewhere}\n\\end{cases}\\]\nSe notează cu \\(\\mathcal{U} \\;[a, b]\\).\nimport matplotlib.pyplot as plt, numpy as np, math\na = -1\nb = 3\nx = np.linspace(-2, 4, 60)\npdf = np.hstack( (np.zeros((10)), 1/(b-a)*np.ones((40)),  np.zeros((10))))  #*\nplt.plot(x,pdf)\nplt.xlabel('x')\nplt.ylabel('fdp(x)')\nplt.title('The uniform distribution $\\mathcal{U}\\;[-1,3]$')\nplt.savefig('fig/01_RandomSignals_DistributionUniform.png', transparent=True, bbox_inches='tight', dpi=300)\nplt.close()\n\nCum interpretăm distribuția uniformă?\n\nSunt posibile doar valori din intervalul \\([a, b]\\), restul sunt absolut excluse;\nToate valorile din intervalul \\([a, b]\\) au aceeași șansă.\n\n“Înălțimea” funcției este \\(\\frac{1}{b-a}\\) pentru a se asigura normalizarea (aria totală este 1)"
  },
  {
    "objectID": "01_01_VariabileAleatoare.html#calculul-probabilității-pentru-distribuția-normală",
    "href": "01_01_VariabileAleatoare.html#calculul-probabilității-pentru-distribuția-normală",
    "title": "1  Variabile aleatoare",
    "section": "1.5 Calculul probabilității pentru distribuția normală",
    "text": "1.5 Calculul probabilității pentru distribuția normală\nProbabilitatea ca \\(A\\) sa aibă valori între \\(a\\) și \\(b\\) este \\(\\int_a^b w_A(x) dx\\), pentru o distribuție continuă. Însă, pentru distribuția normală această integrală nu se poate calcula prin formula algebrice (este funcție ne-elementară).\nÎn schimb, pentru calcul se folosesc algoritmi numerici, pe baza funcției de eroare \\(erf(z)\\) (“the error function”): \\[erf(z) = \\frac{2}{\\sqrt{\\pi}} \\int_0^z e^{-t^2} dt\\]\n\n\n\n\n\n\nTip\n\n\n\nValorile funcției erf() sunt tabelate sau se calculează numeric cu algoritmi specializati. De ex., pe Google, căutați \\(erf(0.5)\\)\n\n\nFuncția de repartiție a unei distribuții normale oarecare \\(\\mathcal{N}(\\mu, \\sigma^2)\\) se poate calcula ca: \\[F_A(X) = \\frac{1}{2}(1 + erf(\\frac{x - \\mu}{\\sigma \\sqrt{2}}))\\]\nAlte valori folositoare:\n\n\\(erf(-\\infty) = -1\\)\n\\(erf(\\infty) = 1\\)\n\n\n\n\n\n\n\nExercițiu\n\n\n\nFie \\(A\\) o variabilă aleatoare cu distribuția \\(\\mathcal{N}(3, 2)\\).\nCalculați probabilitatea ca \\(A \\in [2, 4]\\)\n\n\n\n\n\n\n\n\nExercițiu\n\n\n\nFie \\(A\\) o v.a. cu distribuția \\(\\mathcal{N}(\\mu, \\sigma)\\).\n\nCalculați probabilitatea ca \\(A\\) să fie la cel mult \\(\\pm\\sigma\\) distanță de valoare medie\nCalculați probabilitatea ca \\(A\\) să fie la cel mult \\(\\pm 2\\sigma\\) distanță de valoare medie\nCalculați probabilitatea ca \\(A\\) să fie la cel mult \\(\\pm 3\\sigma\\) distanță de valoare medie\n\n\n\n\n\n\n\n\n\nÎn multe aplicații, anomaliile într-un set de valori se definesc ca fiind valorile aflate la peste \\(3 \\sigma\\) distanță față de medie. De ce oare?"
  },
  {
    "objectID": "01_01_VariabileAleatoare.html#medii-statistice",
    "href": "01_01_VariabileAleatoare.html#medii-statistice",
    "title": "1  Variabile aleatoare",
    "section": "1.6 Medii statistice",
    "text": "1.6 Medii statistice\nVariabilele aleatoare sunt caracterizate prin medii statistice (“momente”), care caracterizează densitatea de probabilitate.\n\n1.6.1 Valoarea medie\nValoarea medie (momentul de ordin 1) a unei variabila aleatoare \\(A\\), notată în mod uzual cu \\(\\mu\\), \\(E\\lbrace A \\rbrace\\) sau \\(\\overline{A}\\), se definește astfel:\n\nPentru v.a. continue: \\[\\overline{A} = E\\{A\\} = \\int_{-\\infty}^{\\infty} x \\cdot w_A(x) dx\\]\nPentru v.a. discrete: \\[\\overline{A} = E\\{A\\} = \\sum_{x=-\\infty}^{\\infty} x \\cdot w_A(x)\\]\n\n\n\n\n\n\n\nTermenul în limba engleză este “expected value”.\n\n\n\nIn termeni informali, valoarea medie este o sumă în care apar toate valorile posibile \\(x\\) înmulțite cu probabilitatea fiecăreia (pentru cazul continuu, folosim integrala și densitatea de probabilitate, cu aceeași semnificație).\n\n\n\n\n\n\nExemplu\n\n\n\nEntropia este valoarea medie a informației \\(i(s_n) = -\\log_2{p(s_n)}\\) asociată unui eveniment cu probabilitatea \\(p(s_n)\\): \\[H(X) = \\sum p(s_n) i(s_n)) = - \\sum p(s_n) log_2(p(s_n))\\]\n\n\nCe semnificație are, practic, valoarea medie a unei variabile aleatoare? Informal, ea ne dă valoarea numerică centrală în jurul căreia “se învârt” toate valorile pe care le poate lua \\(A\\). Ca interpretare grafică, de multe ori ea este situată “pe la mijlocul” distribuției.\n\nValorile care au probabilitate / densitate de probabilitate ridicată “trag” valoarea medie înspre ele.\nPentru distribuții cu formă simetrică (de ex. distribuția normală, distribuția uniformă), valoarea medie este valoarea centrală a funcției. Ambele laturi ale funcției “trag” valoare medie înspre ele în mod egal, valoarea medie rămâne la mijloc.\nDacă avem de-a face cu un semnal \\(x(t)\\) sau \\(x[n]\\) a cărui valori respectă o distribuție \\(w_A(x)\\), valoarea medie a distribuției va fi componenta continuă a semnalului respectiv.\n\nAlte câteva interpretări:\n\nDacă am avea \\(N \\to \\infty\\) valori aleatoare conform distribuției respective, valoarea medie ar fi media aritmentică a tuturor acestor valori;\nDacă trebuie să prezicem valoarea unei variabile aleatoare \\(X\\), și plătim un cost proporțional cu pătratul erorii pe care o facem, \\((u - X)^2\\), valoarea medie \\(\\mu\\) este cea mai bună alegere, întrucât minimizează costul global: \\[\\mu = \\arg\\min_u \\int_{-\\infty}^{\\infty} (u - x)^2\\cdot w(x) dx\\]\n\nDemonstrație: la tablă: derivare, derivata = 0\n\n\nPentru distribuția normală \\(\\mathcal{N}(\\mu, \\sigma)\\), valoarea medie este chiar parametrul \\(\\mu\\): \\[\\overline{X} = \\mu\\]\nPentru o distribuție uniformă \\(\\mathcal{U} [a, b]\\), valoarea medie este valoarea de la mijlocul intervalului: \\[\\overline{X} = \\frac{a + b}{2}\\]\nCalculul valorii medii este o operație liniară. Pentru două variabile aleatoare independente \\(A\\) și \\(B\\), și oricare două numere reale \\(c_1\\) și \\(c_2\\), avem: \\[E\\{c_1A + c_2B\\} = c_1E\\{A\\} + c_2E\\{B\\}\\]\nsau: \\[E\\{cA\\} = c E\\{A\\}, \\forall c \\in \\mathbb{R}\\] \\[E\\{A + B\\} = E\\{A\\} + E\\{B\\}\\]\n\n\n\n\n\n\nExercițiu\n\n\n\nAruncăm trei zaruri \\(A\\), \\(B\\), \\(C\\) și definim \\(D\\) ca suma celor trei valori obținute: \\[D = A+B+C\\]\nCât este valoarea medie a lui \\(D\\)?\n\n\n\n\n1.6.2 Valoarea pătratică medie\nValoarea pătratică medie (momentul de ordin 2) reprezintă valoarea medie a pătratelor valorilor unei variabile \\(A\\).\nPentru variabile aleatoare continue: \\[\\overline{A^2} = E\\{A^2\\} = \\int_{-\\infty}^{\\infty} x^2 \\cdot w_A(x) dx\\]\nȘi pentru cele discrete: \\[\\overline{A^2} = E\\{A^2\\} = \\sum_{-\\infty}^{\\infty} x^2 \\cdot w_A(x)\\]\nValoarea pătratică medie are o interpretare legată de magnitudinea valorilor posibile. Dacă avem de-a face cu un semnal \\(x(t)\\) sau \\(x[n]\\) a cărui valori sunt generate de o distribuție \\(w_A(x)\\), valoarea pătratică medie a distribuției va fi puterea medie a semnalului respectiv.\n\n\n1.6.3 Varianța\nVarianța (momentul centrat de ordin 2) reprezintă valoarea pătratică medie a abaterilor față de valoarea medie.\nPentru variabile aleatoare continue: \\[\\sigma^2 = \\overline{\\left\\{ A - \\mu \\right\\}^2} = \\int_{-\\infty}^{\\infty} (x-\\mu)^2 \\cdot w_A(x) dx\\]\nPentru variabile aleatoare discrete: \\[\\sigma^2 = \\overline{\\left\\{ A - \\mu \\right\\}^2} = \\sum_{-\\infty}^{\\infty} (x-\\mu)^2 \\cdot w_A(x)\\]\nCu alte cuvinte, din valorile variabilei aleatoare \\(A\\) scădem mereu valoarea medie, obținând astfel valori centrate pe \\(0\\) (media lor devine \\(0\\)), și calculăm apoi varianța a ceea ce obținem.\nRădăcina pătrată \\(\\sigma\\) a varianței unei distribuții se numește deviație standard.\nVarianța, sau deviația standard, ne spun cat de mult pot fluctua valorile în jurul valorii medii.\n\nvarianță mică: valorile deviază puțin în jurul mediei, sunt concentrate în jur;\nvarianță mare: valorile deviază mult de la medie.\nDacă avem de-a face cu un semnal \\(x(t)\\) sau \\(x[n]\\) a cărui valori sunt generate de o distribuție \\(w_A(x)\\), varianța va fi puterea medie a componentei alternative a semnalului respectiv (adică puterea medie a semnalului din care am scăzut componenta continuă).\n\n\n\n1.6.4 Legătura între cele trei mărimi statistice\nPentru orice distribuție, cele trei mărimi statistice satisfac relația următoare: \\[\\begin{split}\n\\sigma^2 &= \\overline{\\left\\{ A - \\mu \\right\\}^2} \\\\\n&= \\overline{A^2 - 2 \\cdot A \\cdot \\mu + \\mu^2} \\\\\n&= \\overline{A^2} - 2 \\mu \\overline{A} + \\mu^2 \\\\\n&= \\overline{A^2} - \\mu^2\n\\end{split}\\]\nDacă avem de-a face cu un semnal \\(x(t)\\) sau \\(x[n]\\) a cărui valori urmează o distribuție \\(w_A(x)\\), relația poate fi interpretată în sens energetic:\n\n\\(\\overline{A^2}\\) este puterea totală a semnalului\n\\(\\mu^2\\) este puterea componentei continue\n\\(\\sigma^2\\) este puterea componentei alternative\nputerea totată a semnalului = puterea componentei continue + puterea componentei alternative"
  },
  {
    "objectID": "01_01_VariabileAleatoare.html#operații-cu-variabile-aleatoare",
    "href": "01_01_VariabileAleatoare.html#operații-cu-variabile-aleatoare",
    "title": "1  Variabile aleatoare",
    "section": "1.7 Operații cu variabile aleatoare",
    "text": "1.7 Operații cu variabile aleatoare\nFie o variabilă aleatoare \\(A\\), și fie \\(D = c + A\\), unde \\(c\\) este un număr real.\n\\(D\\) este tot o variabilă aleatoare, a cărui distribuție \\(w_D(x)\\) este distribuția lui \\(A\\) “translată” cu \\(c\\) la dreapta:\n\\[w_D(x) = w_A(x - c)\\]\n\n\n\n\n\n\nExemplu\n\n\n\nFie A o variabilă aleatoare cu distribuție normală \\(w_A(x) = \\mathcal{N}(\\mu=3, \\sigma^2=2)\\).\nDistribuția variabilei \\(D\\) definită ca: \\[D = 5 + A\\] este: \\[w_D(x) = \\mathcal{N}(\\mu=8, \\sigma^2=2)\\]\n\n\nSuma a două sau mai multe variabile aleatoare independente este tot o variabilă aleatoare, a cărei densitate de probabilitate este convoluția densităților termenilor.\nFie două variabile aleatoare \\(A\\) și \\(B\\), independente. Dacă \\(C = A + B\\), atunci:\n\\[w_C(x) = w_A(x) \\star w_B(x)\\]\nPentru cazul particular cand \\(A\\) și \\(B\\) sunt variabile normale cu \\(\\mathcal{N}(\\mu_A, \\sigma_A^2)\\) și \\(\\mathcal{N}(\\mu_B, \\sigma_B^2)\\), atunci suma lor \\(C\\) are tot o distribuție normală \\(\\mathcal{N}(\\mu_C, \\sigma_C^2)\\), având media lui \\(C\\) egală cu suma mediilor lui \\(A\\) și \\(B\\):\n\\[\\mu_C = \\mu_A + \\mu_B\\]\niar varianța egală cu suma varianțelor:\n\\[\\sigma_C^2 = \\sigma_A^2 + \\sigma_B^2\\]\nÎn general, o funcție aplicată unei variabile aleatoare produce o altă variabilă aleatoare, cu altă distribuție, posibil cu totul diferită de cea inițială.\n\n\n\n\n\n\nExemple\n\n\n\nDacă \\(A\\) este o v.a. distribuită \\(\\mathcal{U}\\;[0,10]\\), atunci\n\n\\(B = 5 + A\\) este o altă v.a., distribuită \\(\\mathcal{U}\\;[5,15]\\)\n\\(C = A^2\\) este de asemenea o v.a.\n\\(D = cos(A)\\) este de asemenea o v.a.\n\n\n\nVariabilele A, B, C, D nu sunt însă independente, întrucât o anumită valoare a uneia implică automat și valoarea celorlalte."
  },
  {
    "objectID": "01_01_VariabileAleatoare.html#sisteme-de-mai-multe-variabile-aleatoare",
    "href": "01_01_VariabileAleatoare.html#sisteme-de-mai-multe-variabile-aleatoare",
    "title": "1  Variabile aleatoare",
    "section": "1.8 Sisteme de mai multe variabile aleatoare",
    "text": "1.8 Sisteme de mai multe variabile aleatoare\nFie un sistem cu două variabile aleatoare continue, \\(A\\) și \\(B\\). Care este probabilitatea ca \\(A\\) să ia valori în jurul lui \\(x\\) ȘI B să ia valori în jurul lui \\(y\\)?\nDistribuția valorilor perechii \\((A,B)\\) este descrisă de o densitatea de probabilitate comună \\(w_{AB}(x,y)\\), și de o funcția de repartiție comună \\(F_{AB}(x,y)\\).\nFuncția de repartiție comună se definește ca: \\[F_{AB}(x,y) = P_{AB}\\left\\{ A \\leq x \\cap B \\leq y \\right\\}\\]\nDensitatea de probabilitate comună: \\[w_{AB}(x,y) = \\frac{\\partial^2 F_{AB}(x,y)}{\\partial x \\partial y}\\]\nDensitatea de probabiliate comună ne dă probabilitatea ca perechea \\((A,B)\\) să aibă valoarea într-o vecinătate a \\((x,y)\\)\nCele două funcții se definesc similar și pentru variabile discrete, înlocuind integralele cu sume: \\[w_{AB}(x,y) = P\\left\\{ A = x \\cap B = y \\right\\}\\]\n\n1.8.1 Variabile independente\nDouă variabile \\(A\\) și \\(B\\) sunt independente dacă se respectă relația: \\[w_{AB}(x,y) = w_A(x) \\cdot w_B(y)\\]\nCa interpretare, acest lucru înseamnă că valoarea uneia nu influențează în nici un fel valoarea celeilalte.\nRelația este valabilă și pentru funcția de repartiție, atât pentru variabile continue cât și pentru discrete, și se extinde similar pentru cazul în care sunt mai mult de două variabile.\n\n\n\n\n\n\nExercițiu\n\n\n\nCalculați probabilitatea ca trei v.a. \\(X\\), \\(Y\\) și \\(Z\\) i.i.d. \\(\\mathcal{N}(-1,1)\\) să fie toate pozitive (prescuratea i.i.d* = “independente și identic distribuite”)."
  },
  {
    "objectID": "01_01_VariabileAleatoare.html#distribuția-normală-multivariată",
    "href": "01_01_VariabileAleatoare.html#distribuția-normală-multivariată",
    "title": "1  Variabile aleatoare",
    "section": "1.9 Distribuția normală multivariată",
    "text": "1.9 Distribuția normală multivariată\nDistribuția normală se poate extinde în mod natural la vectori cu dimensiune \\(N\\).\nPentru un vector \\(\\mathbf{x}\\) de dimensiune N \\[\\mathbf{x} = [x_1, x_2, ... x_N]\\] distribuția se definește ca: \\[w_A(\\mathbf{x})= \\frac{1}{\\sqrt{(2\\pi)^N |\\Sigma|}}\ne^{-\\frac{1}{2}(\\mathbf{x} - \\boldsymbol{\\mu})^T\\Sigma^{-1}(\\mathbf{x} - \\boldsymbol{\\mu})}\\]\nFuncția are doi parametri matriciali:\n\nmedia \\(\\boldsymbol{\\mu} = [\\mu_1, \\mu_2, ... \\mu_N]\\) este un vector de dimensiune \\(N\\) care definește “centrul” funcției;\nmatricea de covarianță \\(\\Sigma\\) este o matrice $ N N$ care definește orientarea și forma eliptică a funcției.\n\nDistribuția normală multivariată are forma de tipul unui “munte” elipsoid, pentru care media \\(\\boldsymbol{\\mu}\\) reprezintă coordonatele vârfului central. Matricea de covarianță \\(\\Sigma\\) determina forma “muntelui”, în felul următor:\n\nMatrice are \\(N\\) vectori proprii \\(\\mathbf{e_i}\\) care dau direcțiile ortogonale ale axelor care definesc elipsa;\nCele \\(N\\) valori proprii \\(\\lambda_i\\) controlează extinderea elipsei de-a lungul fiecărei axe.\n\n\n\n\n\n\n\nExemple\n\n\n\n\n\n\nDistribuția normală 2D (bivariată)\n\n\n\nsursa: https://www.statsref.com/HTML/multivariate_distributions.html\n\n\n\n\nDistribuții normală 2D (bivariată)\n\n\n\nsursa: https://www.rhayden.us/covariance-matrix-2/the-multivariate-normal-distribution.html\n\nVectorii proprii \\(\\mathbf{e_i}\\) ai matricei de covarianță \\(\\Sigma\\) ne dau direcțiile dupa care e aliniată forma eliptică a funcției, iar valorile proprii \\(\\lambda_i\\) ne dau alungirea funcției în aceste direcții (varianța în aceste direcții).\n\n\n\nDistribuții normală 2D (bivariată)\n\n\n\nsursa: https://www.rhayden.us/covariance-matrix-2/the-multivariate-normal-distribution.html\n\n\n\n\n1.9.1 Caz particular: componente independente\nÎn cazul în care matricea de covarianță este o matrice diagonală:\n\\[\\Sigma =\n\\begin{bmatrix}\n\\sigma^2_1 & 0 & 0 & \\cdots & 0 \\\\\n0 & \\sigma^2_2 & 0 & \\cdots & 0 \\\\\n0 & 0 & \\sigma^2_3 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & 0 & \\cdots & \\sigma^2_N \\\\\n\\end{bmatrix}\\]\ndistribuția multiavariată se descompune ca un produs de distribuții individuale, ceea ce reflectă faptul că componentele vectorului \\(\\mathbf{x}\\) sunt independente:\n\\[\\begin{split}\nw_A(\\mathbf{x}) &=\n\\frac{1}{\\sigma_1 \\cdot ... \\cdot \\sigma_N \\sqrt{(2\\pi)^N}}\ne^{(-\\frac{(\\mathbf{x_1} - \\boldsymbol{\\mu_1})^2}{2\\sigma^2_1}) \\cdot (-\\frac{(\\mathbf{x_2} - \\boldsymbol{\\mu_2})^2}{2\\sigma^2_2}) \\cdot \\dots (-\\frac{(\\mathbf{x_N} - \\boldsymbol{\\mu_N})^2}{2\\sigma^2_N})}  \\\\\n&=\\frac{1}{\\sigma_1 \\sqrt{(2\\pi)}} e^{-\\frac{(\\mathbf{x_1} - \\boldsymbol{\\mu_1})^2}{2\\sigma^2_1}}\n\\cdot\n\\frac{1}{\\sigma_2 \\sqrt{(2\\pi)}} e^{-\\frac{(\\mathbf{x_2} - \\boldsymbol{\\mu_2})^2}{2\\sigma^2_2}}\n\\cdot \\dots \\cdot\n\\frac{1}{\\sigma_N \\sqrt{(2\\pi)}} e^{-\\frac{(\\mathbf{x_N} - \\boldsymbol{\\mu_N})^2}{2\\sigma^2_N}} \\\\\n&=w_1(x_1) \\cdot w_2(x_2) \\cdot \\dots \\cdot w_N(x_N)\n\\end{split}\\]\nAcest lucru înseamnă, practic, că fiecare componentă \\(x_k\\) din vectorul \\(\\mathbf{x}\\) este independentă de toate celelalte și respectă o distribuție normală cu media \\(\\mu_k\\) și varianța \\(\\sigma^2_k\\). Cu alte cuvinte:\n\\[\\mathcal{N}(\\boldsymbol{\\mu}, \\Sigma) = \\mathcal{N}(\\mu_1, \\sigma_1) \\cdot \\mathcal{N}(\\mu_2, \\sigma_2) \\cdot \\dots \\cdot \\mathcal{N}(\\mu_N, \\sigma_N)\\]\n\n\n1.9.2 Caz particular: distribuție izotropă\nÎn cazul în care matricea de covarianță este de forma unei matrici matricea unitate, având aceeași valoare \\(\\sigma\\) pe toate liniile: \\[\\Sigma = \\sigma^2 \\mathbf{I}_N\\]\navem o distribuție normală multivariată izotropă:\n\n\n\n\n\n\nTermenul “izotrop” înseamnă “cu aceleași proprietăți în orice direcție” și se referă la forma circulară a funcției.\n\n\n\n\\[\\begin{split}\nw_A(\\mathbf{x}) &= \\frac{1}{\\sigma^N \\sqrt{(2\\pi)^N}}\ne^{-\\frac{1}{2}(\\mathbf{x} - \\boldsymbol{\\mu})^T \\Sigma^{-1} (\\mathbf{x} - \\boldsymbol{\\mu})} \\\\\n&=\\frac{1}{\\sigma^N \\sqrt{(2\\pi)^N}}\ne^{-\\frac{ \\sum_i (x_i - \\mu_i)^2 }{2 \\sigma^{2N}}} \\\\\n\\end{split}\\]\nÎn acest caz, toata componentele \\(x_k\\) sunt independente și respectă fiecare o distribuție normală cu medie \\(\\mu_k\\), dar cu aceeași varianță \\(\\sigma^2\\).\nSe observă că în acest caz valoarea densității de probabilitate într-un punct \\(\\mathbf{x}=[x_1,...x_N]\\) depinde de distanța de la punctul respectiv la punctul central \\(\\boldsymbol{\\mu} = [\\mu_1,...\\mu_N]\\).\nDistanța Euclideană (geometrică) între 2 vectori N-dimensionali se definește astfel:\n\\[d(\\mathbf{u},\\mathbf{v}) = \\| \\mathbf{u}-\\mathbf{v} \\| = \\sqrt{(u_1-v_1)^2+...+(u_N - v_N)^2}\\]\nCazuri particulare în funcție de dimensiunea \\(N\\):\n\nUnidimensional: \\(\\|\\mathbf{u}-\\mathbf{v}\\| = |u-v|\\)\n2D: \\(\\|\\mathbf{u}-\\mathbf{v}\\| = \\sqrt{(u_1 - v_1)^2 + (u_2 - v_2)^2}\\)\n3D: \\(\\|\\mathbf{u}-\\mathbf{v}\\| = \\sqrt{(u_1 - v_1)^2 + (u_2 - v_2)^2 + (u_3 - v_3)^2}\\)\n…\nN-dimensional: \\(\\|\\mathbf{u}-\\mathbf{v}\\| = \\sqrt{\\sum_{i=1}^N(u_i - v_i)^2}\\)\n\nAceeași relație se poate extinde și pentru semnale continue, văzute ca vectori cu o infinitate de puncte unul lângă altul:\nÎn cazul unei distribuții normale multivariate izotrope, densitatea de probabilitate într-un punct depinde de pătratul distanței Euclidiene față de media \\(\\boldsymbol{\\mu} = [\\mu_1,...\\mu_N]\\)\n\nValoarea maximă este chiar in punctul \\(\\boldsymbol{\\mu}\\)\nPuncte aproapiate de \\(\\mu\\) au probabilitate mai mare\nPuncte mai depărtate de \\(\\mu\\) au probabilitate mai redusă\nDouă puncte la aceeași distanță de \\(\\mu\\) au aceeași probabilitate\n\nDistribuția normală 2D, izotropă, este prezentată mai jos:\n\nVedere de sus:\n\nÎn această figură, \\(\\mu = (0,0)\\). Se observă că probabilitatea scade pe măsură ce crește distanța față de centru, în cercuri concentrice (simetric), întrucât e vorba de o distribuție izotropă. În cazul general, în loc de cercuri concentrice am fi avut elipse concentrice."
  },
  {
    "objectID": "01_02_ProceseAleatoare.html#definiție",
    "href": "01_02_ProceseAleatoare.html#definiție",
    "title": "2  Procese aleatoare",
    "section": "2.1 Definiție",
    "text": "2.1 Definiție\nUn proces aleator reprezintă modelul matematic pentru ideea de “semnal aleator”, sau “zgomot”.\nUn proces aleator este o secvență de variabile aleatoare indexate (înșiruite) în timp.\nProces aleator în timp discret \\(f[n]\\) este format din variabile aleatoare la momente de timp discrete de ex. o secvență de 50 aruncări de zar, sau cotația zilnică a unor acțiuni la bursă.\nProces aleator în timp continuu \\(f(t)\\) conține câte o variabilă aleatoate la orice moment de timp \\(t\\), cum ar fi un semnal tip zgomot de tensiune.\nFiecare eșantion dintr-un proces aleator \\(f\\) este o variabilă aleatoare de sine stătătoare, diferită de celelalte. Așadar, \\(f(t_0)\\), valoarea la momentul \\(t_0\\), este o variabilă aleatoare, la fel și \\(f(t_1)\\) etc.\nO realizare a unui proces aleator reprezintă o secvență particulară de realizări ale v.a. componente.\nDe exemplu, când obsservăm un anume semnal de zgomot pe un osciloscop, vedem o anume realizare a procesului aleator. Am fi putut obține orice altă realizare, la fel de “haotică”, dar cu alte valori particulare.\nPentru a indica o anume realizare, folosim indicele \\((k)\\), de ex. \\(f^{(k)}[n]\\) sau \\(f^{(k)}(t)\\).\n\n\n\n\n\n\nCând ne referim la un proces aleator, luăm în calcul întregul set de realizări posibile, chiar dacă vedem o singură realizare, cea care s-a întâmplat să fie.\nLa fel se întâmplă și la variabile aleatoare: când aruncăm un zar, vedem o realizare particulară, să zicem valoarea \\(5\\), dar știm că am fi putut obține oricare altă valoare și luăm în calcul întreg setul de valori posibile.\n\n\n\nCa interpretare grafică, este util sa vizualizăm un proces aleator în două dimensiuni, corespunzător celor două axe:\n\naxa timpului (\\(t\\) sau \\(n\\))\naxa realizărilor, care enumeră diferite realizări posibile \\(f^{(k)}[n]\\) sau \\(f^{(k)}(t)\\)\n\n\n\nsursa: “Information-Based Inversion and Processing with Applications” Edited by Tadeusz J. Ulrych, Mauricio D. Sacchi, Volume 36,\n\n\n\nsursa: Razdolsky, L. (2014). Random Processes. In Probability-Based Structural Fire Load (pp. 89-136). Cambridge: Cambridge University Press\n\n\n\nsursa: https://www.quora.com/What-is-the-difference-between-a-stationary-ergodic-and-a-stationary-non-ergodic-process"
  },
  {
    "objectID": "01_02_ProceseAleatoare.html#distribuții-ale-proceselor-aleatoare",
    "href": "01_02_ProceseAleatoare.html#distribuții-ale-proceselor-aleatoare",
    "title": "2  Procese aleatoare",
    "section": "2.2 Distribuții ale proceselor aleatoare",
    "text": "2.2 Distribuții ale proceselor aleatoare\nEșantioanele unui proces aleator sunt variabile aleatoare, care pot depinde sau nu unele de altele, în diverse moduri.\nDe aceea, pentru a descrie un proces aleator, folosim diferite tipuri de distribuții:\n\ndistribuții de ordin 1, care descriu statistica fiecărui eșantion\ndistribuții de ordin 2, care descriu statistica fiecărei perechi de eșantioane\n…\ndistribuții de ordin N, care descriu statistica fiecărui grup de N eșantioane\netc.\n\n\n2.2.1 Distribuții de ordin 1\nFiecare eșantion \\(f(t_1)\\) dintr-un proces aleator este o variabilă aleatoare, având o distribuție de ordin 1 caracteriată de:\n\no funcție de repartiție \\[F_1(x;t_1) = P\\lbrace f(t_1) \\leq x\\rbrace\\]\no densitate de probabilitate \\[w_1(x;t_1) = \\frac{dF_1(x;t_1)}{dx}\\]\n\nAceste funcții depinde de momentul \\(t_1\\) considerat. Un eșantion la alt moment \\(t_2\\) este o v.a. diferită, cu statistică posibil diferită:\n\no altă funcție de repartiție \\(F_1(x;t_2)\\)\no altă densitate de probabilitate \\(w_2(x;t_2) = \\frac{dF_1(x;t_2)}{dx}\\)\n\nAceste funcții descriu distribuția valorilor câte unui singur eșantion, sunt funcții matematice de o singură variabilă, lucru marcat și prin indicele \\(w_1\\).\n\n\n2.2.2 Distribuții de ordin 2\nO pereche de v.a. \\(f(t_1)\\) și \\(f(t_2)\\) formează un sistem de 2 v.a., care e descris de o distribuție de ordin 2:\n\nexista o funcție de repartiție comună \\[F_2(x_i, x_j; t_1, t_2)\\]\nexistă densitatea de probabilitate comună \\[w_2(x_i, x_j; t_1, t_2) = \\frac{\\partial^2 F_2(x_i, x_j;t_1, t_2)}{\\partial x_i \\partial x_j}\\]\n\nAcestea sunt funcții de două varabile, descriu cum variază perechea de eșantioane de la momentele \\(t_1\\) și \\(t_2\\).\n\n\n2.2.3 Distribuții de ordin N\nConceptele se pot generaliza pentrub orice \\(N\\).\nUn set de \\(N\\) v.a. \\(f(t_1), ...f(t_N)\\) dintr-un proces aleator \\(f(t)\\) sunt descrise de o distribuție de ordin N, având:\n\no funcție de repartiție comună \\[F_N(x_1,... x_N; t_1,... t_N)\\]\no densitate de probabilitate comună \\[w_n(x_1,... x_N; t_1,... t_N) = \\frac{\\partial^2 F_n(x_1,... x_N;t_1,... t_N)}{\\partial x_1 ... \\partial x_N}\\]\n\nAceste funcțiisunt funcții de câte N variabile, și descriu cum sunt distribuite valorile seturilor de \\(N\\) eșantioane de la momentele \\(t_1\\), \\(t_2\\), … \\(t_N\\)."
  },
  {
    "objectID": "01_02_ProceseAleatoare.html#medii-statistice",
    "href": "01_02_ProceseAleatoare.html#medii-statistice",
    "title": "2  Procese aleatoare",
    "section": "2.3 Medii statistice",
    "text": "2.3 Medii statistice\nLa procese aleatoare se pot defini două tipuri de valori medii:\nValori medii statistice sunt cele calculate la un timp fixat \\(t\\), de-a lungul axei realizărilor, considerând toate realizărilor posibile care s-ar fi putut întâmpla la acel moment \\(t\\).\nValori medii temporale sunt cele calculate pentru o realizare \\(k\\) fixată, de-a lungul axei timpului.\n\n\nsursa: https://www.quora.com/What-is-the-difference-between-a-stationary-ergodic-and-a-stationary-non-ergodic-process\n\nMediile statistice sunt de obicei cele de dorit, dar ele necesită cunoașterea distribuțiilor \\(w(x)\\), care în practică sunt rareori cunoscute.\nÎn practică, de obicei avem acces doar la o singură realizare, obținută printr-o măsurătoare, deci putem calcula doar mediile temporale pe acea realizare\nDin fericire, în multe cazuri mediile statistice și temporale sunt identice, proprietate care poartă numele de “ergodicitate”.\n\n2.3.1 Medii statistice de ordinul 1\nMediile statistice se calculează pe baza distribuțiilor de ordin 1, 2, … N, corespunzătoare momentelor considerate.\nMediile de ordin 1 se referă la un singur moment de timp fixat (\\(t_1\\)), luând în calcul toate realizările posibile. Ele caracterizează doar eșantionul de la momentul \\(t_1\\). La alt moment de timp \\(t_2\\), v.a. \\(f(t_2)\\) este diferită, și valorile medii pot diferi.\nPentru procese continue:\n\nValoarea medie \\[\\overline{f(t_1)} = \\mu(t_1) = \\int_{-\\infty}^{\\infty} x \\cdot w_1(x; t_1) dx\\]\nValoarea pătratică medie \\[\\overline{f^2(t_1)} = \\int_{-\\infty}^{\\infty} x^2 \\cdot w_1(x; t_1) dx\\]\nVarianța \\[\\sigma^2(t_1) = \\overline{\\left\\{ f(t_1) - \\mu(t_1) \\right\\}^2} = \\int_{-\\infty}^{\\infty} (x-\\mu(t_1)^2 \\cdot w_1(x; t_1) dx\\]\n\nCele trei mărimi satisfac relația:\n\\[\\begin{split}\n\\sigma^2(t_1) =& \\overline{\\left\\{ f(t_1) - \\mu(t_1) \\right\\}^2} \\\\\n=& \\overline{f(t_1)^2 - 2f(t_1)\\mu(t_1) + \\mu(t_1)^2} \\\\\n=& \\overline{f^2(t_1)} - \\mu(t_1)^2\n\\end{split}\\]\n\n\n2.3.2 Autocorelația\nAutocorelația este o medie statistică de ordinul 2, care caracterizează o pereche de eșantioane de la momentele \\(t_1\\) și \\(t_2\\):\n\nAutocorelația \\[R_{ff}(t_1,t_2) = \\overline{f(t_1) f(t_2)} = \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty x_1 x_2 w_2(x_1, x_2; t_1, t_2) dx_1 dx_2\\]\n\nDefiniția de poate extinde și pentru două procese aleatoare diferite, \\(f(t)\\) și \\(g(t)\\):\n\nCorelația \\[R_{fg}(t_1,t_2) = \\overline{f(t_1) g(t_2)} = \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty x_1 y_2 w_2(x_1, y_2; t_1, t_2) dx_1 dy_2\\]\n\n\n\n2.3.3 Procese aleatoare discrete\nPentru procese aleatoare discrete, se înlocuiește \\(\\int\\) cu \\(\\sum\\), și notația \\(f(t)\\) cu \\(f[t]\\):\n\n\\(\\overline{f[t_1]} = \\mu(t_1) = \\sum_{x=-\\infty}^{\\infty} x \\cdot w_1(x; t_1)\\)\n\\(\\overline{f^2[t_1]} = \\sum_{x=-\\infty}^{\\infty} x^2 \\cdot w_1(x; t_1)\\)\n\\(\\sigma^2(t_1) = \\overline{\\left\\{ f[t_1] - \\mu(t_1) \\right\\}^2} = \\sum_{x=-\\infty}^{\\infty} (x-\\mu(t_1)^2 \\cdot w_1(x; t_1)\\)\n\\(R_{ff}(t_1,t_2) = \\overline{f[t_1] f[t_2]} = \\sum_{x_1=-\\infty}^\\infty \\sum_{x_2=-\\infty}^\\infty x_1 x_2 w_2(x_1, x_2; t_1, t_2)\\)\n\\(R_{fg}(t_1,t_2) = \\overline{f[t_1] g[t_2]} = \\sum_{x_1=-\\infty}^\\infty \\sum_{x_2=-\\infty}^\\infty x_1 y_2 w_2(x_1, y_2; t_1, t_2)\\)"
  },
  {
    "objectID": "01_02_ProceseAleatoare.html#medii-temporale",
    "href": "01_02_ProceseAleatoare.html#medii-temporale",
    "title": "2  Procese aleatoare",
    "section": "2.4 Medii temporale",
    "text": "2.4 Medii temporale\nMediile temporale se calculează pentru o singură realizare \\(f^{(k)(t)}\\), de-a lungul timpului.\nAcesta este cazul uzual în practică, atunci când prin masurare avem acces la o singură realizare.\nAceste medii nu mai depind de timpul \\(t\\), întrucât de-a lungul timpului are loc medierea. În schimb, ele caracterizează o singură realizare \\((k)\\).\nMedii temporale pentru procese aleatoare continue:\n\nValoarea medie temporală \\[\\overline{f^{(k)}(t)} = \\mu^{(k)} = \\lim_{T \\to \\infty} \\frac{1}{T} \\int_{T/2}^{T/2} f^{(k)}(t) dt\\]\nValoarea medie pătratică temporală \\[\\overline{[f^{(k)}(t)]^2} = \\lim_{T \\to \\infty} \\frac{1}{T} \\int_{-T/2}^{T/2} [f^{(k)}(t)]^2 dt\\]\nVarianța temporală \\[\\sigma^2 = \\overline{\\left\\{ f^{(k)}(t) - \\mu^{(k)} \\right\\}^2} = \\lim_{T \\to \\infty} \\frac{1}{T} \\int_{-T/2}^{T/2} (f^{(k)}(t)-\\mu^{(k)})^2 dt\\]\nRelația dintre cele trei mărimi: \\[\\sigma^2 = \\overline{[f^{(k)}(t)]^2} - [\\mu^{(k)}]^2\\]\nAutocoreația temporală \\[\\begin{split}\nR_{ff}(t_1,t_2) =& \\overline{f^{(k)}(t_1 + t) f^{(k)}(t_2+t)} \\\\\n=& \\lim_{T \\to \\infty} \\frac{1}{T} \\int_{-T/2}^{T/2} f^{(k)}(t_1+t) f^{(k)}(t_2 + t) dt\n\\end{split}\\]\nCorelația temporală (pentru două procese diferite \\(f(t)\\) și \\(g(t)\\)) \\[\\begin{split}\nR_{fg}(t_1,t_2) =& \\overline{f^{(k)}(t_1 + t) g^{(k)}(t_2+t)}\\\\\n=& \\lim_{T \\to \\infty} \\frac{1}{T} \\int_{-T/2}^{T/2} f^{(k)}(t_1+t) g^{(k)}(t_2 + t) dt\n\\end{split}\\]\n\n\n2.4.1 Procese aleatoare discrete\nPentru procese aleatoare discrete, se înlocuiește \\(\\int\\) cu \\(\\sum\\), \\(T\\) cu \\(N\\), și se împarte la \\(2N+1\\) în loc de \\(2T\\).\n\n\\(\\overline{f^{(k)}[t]} = \\mu^{(k)} = \\lim_{N \\to \\infty} \\frac{1}{2N+1} \\sum_{t=-N}^{N} f^{(k)}[t]\\)\n\\(\\overline{[f^{(k)}[t]]^2} = \\lim_{N \\to \\infty} \\frac{1}{2N+1} \\sum_{t=-N}^{N} (f^{(k)}[t])^2\\)\n\\(\\sigma^2 = \\overline{\\left\\{ f^{(k)}[t] - \\mu^{[k]} \\right\\}^2} = \\lim_{N \\to \\infty} \\frac{1}{2N+1} \\sum_{t=-N}^{N} (f^{(k)}[t]-\\mu^{(k)})^2\\)\nAutocorelația temporală:\n\\[\\begin{split}\nR_{ff}(t_1,t_2) =& \\overline{f^{(k)}[t_1 + t] f^{(k)}[t_2+t]} \\\\\n=& \\lim_{N \\to \\infty} \\frac{1}{2N+1} \\sum_{t=-N}^{N} f^{(k)}[t_1+t] f^{(k)}[t_2 + t]\n\\end{split}\\]\nCorelația temporală:\n\\[\\begin{split}\nR_{fg}(t_1,t_2) =& \\overline{f^{(k)}[t_1 + t] g^{(k)}[t_2+t]}\\\\\n=& \\lim_{N \\to \\infty} \\frac{1}{2N+1} \\sum_{t=-N}^{N} f^{(k)}[t_1+t] g^{(k)}[t_2 + t]\n\\end{split}\\]\n\n\n\n2.4.2 Realizări de lungime finită\nÎn practică, de obicei avem o realizare de lungime finită, de exemplu un vector cu 1000 de eșantioane.\nÎn acest caz, mediile temporale se calculează doar asupra datelor avute la dispoziție, de la \\(\\int_{t_{min}}^{t_{max}}\\) sau \\(\\sum_{t_{min}}^{t_{max}}\\) în loc de la \\(-\\infty\\) la \\(\\infty\\)\n\n\n\n\n\n\nExercițiu\n\n\n\nCalculați mediile temporale pentru următoarea realizarea de lungime finită: \\[\\{1,-1,2,-2,3,-3,4,-4,5,-5\\}\\]"
  },
  {
    "objectID": "01_02_ProceseAleatoare.html#staționaritate",
    "href": "01_02_ProceseAleatoare.html#staționaritate",
    "title": "2  Procese aleatoare",
    "section": "2.5 Staționaritate",
    "text": "2.5 Staționaritate\nPână acum am considerat că mediile statistice depind de timp, adică pot fi diferite pentru la momentul \\(t_1\\) față de momentul \\(t_2\\). În practică, pentru multe fenomene valorile mediilor sunt egale între ele, ceea ce simplifică analiza.\nUn proces aleator este staționar dacă mediile statistice rămân aceleași la modificarea originii timpului (întârzierea semnalului). Altfel spus, distribuțiile eșantioanelor rămân identice la modificarea originii timpului cu un \\(\\tau\\) oarecare:\n\\[w_N(x_1,...x_N; t_1,...t_N) = w_N(x_1,...x_N; t_1+\\tau,... t_N + \\tau)\\]\nAcest lucru înseamnă că toate mediile statistice nu mai depind explicit de timpul \\(t\\).\nUn proces aleator este staționar în sens strict dacă relația e valabilă pentru distribuțiile de orice ordin \\(N\\), ceea ce face ca absolut toate mediile să nu depindă de originea timpului \\(t\\) (valoarea medie, valoarea pătratică medie, varianța, autocorelația și toate celelalte statistici de ordin superior).\nÎn practică, condiția aceasta poate fi excesiv de strictă, motiv pentru care în unele aplicații se folosește o condiție mai relaxată.\nUn proces aleator este staționar în sens larg dacă relația e valabilă doar pentru distribuțiile de ordin \\(1\\) și \\(2\\) (distribuțiile unui singur eșantion și a două eșantioane), adică doar valoarea medie, valoarea pătratică medie, varianța și autocorelația nu depind de originea timpului \\(t\\), dar statisticile de ordin superior pot depinde.\n\n\n\n\n\n\nExemplu\n\n\n\nEste procesul aleator schițat mai jos staționar sau nu?\n\n\nsursa: SEX, LIES & STATISTICS, Ned Wright, http://www.astro.ucla.edu/~wright/statistics/\n\nRăspuns: este ne-staționar, întrucât se observă că varianța nu este aceeași la toate momentele de timp.\n\n\n\n2.5.1 Consecințe ale staționarității\nPentru un proces aleator staționar în sens larg, toate distribuțiile de ordin \\(1\\) (ale unui eșantion) sunt egale și nu mai depind de timp:\n\\[w_1(x_i;t_1) = w_1(x_i; t_2) = w_1(x_i)\\]\nValoarea medie, valoarea medie pătratică, varianța unui eșantion sunt identice la orice moment de timp \\(t\\):\n\\[\\overline{f(t)} = constant, \\forall t\\] \\[\\overline{f^2(t)} = constant, \\forall t\\] \\[\\sigma^2(t) = constant, \\forall t\\]\nDistribuțiile de ordin \\(2\\) depind doar de diferența de timp între cele două momente, nu de valorile lor absolute:\n\\[w_2(x_i,x_j;t_1,t_2) = w_2(x_i,x_j;0, t_2-t_1) = w_2(x_i,x_2; t_2-t_1)\\]\nAutocorelația pentru două eșantioane \\(t_1\\) și \\(t_2\\) depinde doar de diferența de timp \\(\\tau = t_2 - t_1\\) dintre ele:\n\\[R_{ff}(t_1,t_2) = R_{ff}(0, t_2 - t_1) = R_{ff}(\\tau) = \\overline{f(t) f(t + \\tau)}\\]\nDefiniția autocorelației statistice rămâne aceeași, dar definiția autocorelației temporale se poate simplifica:\n\npentru p.a. continue: \\[\\begin{split}\nR_{ff}(\\tau) = \\overline{f(t) f(t + \\tau)} = \\lim_{T \\to \\infty} \\frac{1}{T} \\int_{-T/2}^{T/2} f^{(k)}(t) f^{(k)}(t + \\tau) dt\n\\end{split}\\]\npentru p.a. discrete: \\[\\begin{split}\nR_{ff}(\\tau) = \\overline{f(t) f(t + \\tau)} = \\lim_{N \\to \\infty} \\frac{1}{2N+1} \\sum_{t=-N}^{N} f^{(k)}[t] f^{(k)}[t + \\tau]\n\\end{split}\\]\npentru realizări de lungime finită, se limitează integralele / sumele la intervalul avut la dispoziție\n\nDefiniția corelației suferă aceleași modificări ca cea a autocorelației.\n\n\n2.5.2 Interpretarea autocorelației\nAutocorelația temporală \\[R_{ff}(\\tau) = \\overline{f(t) f(t + \\tau)}\\] reprezintă media produsului a două eșantioane situate la distanță de \\(\\tau\\).\nEa ne dă spune ceva despre modul în care variază eșantioanele împreună, de exemplu dacă valorile tind să varieze în același sens, sau în sens contrar.\nSa luăm un exemplu mai detaliat:\n\ndacă \\(R_{ff}(0.5) > 0\\), atunci două eșantioane decalate cu \\(0.5\\) secunde tind să varieze în aceeași direcție (ambele pozitive, ambele negative), ceea ce face ca produsele să fie majoritar pozitive;\ndacă \\(R_{ff}(1) < 0\\), atunci două eșantioane decalate cu 1 secundă tind să varieze în direcții opuse (când unul e pozitiv, celălalt e negativ) ceea ce face ca produsele să fie majoritar negative;\nîn ambele cazuri de mai sus, dacă se cunoaște una dintre valori, se poate “ghici” ceva despre cealaltă;\ndacp \\(R_{ff}(2) = 0\\), atunci două eșantioane decalate cu 2 secunde sunt necorelate adică cele două eșantioane au la fel de multe șanse de a fi de același semn sau cu semne contrare, produsele lor fiind în medie 0; în acest caz, dacă se cunoaște una dintre ele, nu se mai poate “ghici” ceva despre cealaltă.\n\nInterpretarea se face la fel și pentru corelație, doar că în acest caz eșantioanele provin din p.a. diferite, \\(f\\) și \\(g\\)."
  },
  {
    "objectID": "01_02_ProceseAleatoare.html#ergodicitate",
    "href": "01_02_ProceseAleatoare.html#ergodicitate",
    "title": "2  Procese aleatoare",
    "section": "2.6 Ergodicitate",
    "text": "2.6 Ergodicitate\nUn proces aleator este ergodic dacă mediile temporale pe orice realizare sunt egale între ele, și egale cu mediile statistice.\nAcest lucru înseamnă că se pot calcula toate mediile pe baza unei singure realizări, oricare, întrucât toate realizările sunt similare unele cu altele din punct de vedere statistic.\nMajoritatea proceselor aleatoare de interes (de ex. zgomote de tensiune) sunt ergodice și staționare.\n\n\n\n\n\n\nExemplu\n\n\n\nUn exemplu amuzant de proces aleator ne-ergodic este ilustrat mai jos:\n\n\nXKCD 221 (link aici: https://xkcd.com/221/)\n\nFuncția respectivă produce o secvență de valori aleatoare, egale între ele, dar totusi aleatoare pentru ca valoarea 4 a fost obținută cu un zar, deci e aleatoare “garantat”! În loc de 4, zarul ar fi putut da oricare altă valoare.\nCare e problema aici?\n\neste acesta un proces aleator staționar sau ne-staționar?\neste acesta un proces aleator ergodic sau ne-ergodic?"
  },
  {
    "objectID": "01_03_Autocorelatia.html#definiții",
    "href": "01_03_Autocorelatia.html#definiții",
    "title": "3  Proprietăți ale autocorelației",
    "section": "3.1 Definiții",
    "text": "3.1 Definiții\nReminder: Pentru un proces aleator staționar (în sens larg) \\(f\\), autocorelația, văzută ca o funcție de \\(\\tau\\), se definește astfel:\n\\[R_{ff}(\\tau) = \\overline{f(t) f(t + \\tau)}\\]\nși reprezintă valoarea medie a produsului între oricare două eșantioane situate la o distanță \\(\\tau\\) între ele.\nDensitatea spectrală de putere (DSP) \\(S_{ff}(\\omega)\\) este funcția care reprezintă puterea unui semnal în funcție de frecvență (\\(f\\) sau \\(\\omega = 2 \\pi f\\)).\nPentru un semnal determinist (ne-aleator), DPS este dată de modului transformatei Fourier la pătrat: \\[S_{ff}(\\omega) = |F(\\omega)|^2\\]\nPentru un semnal aleator, vom vedea mai jos.\nDSP este o densitate, și ca atare asupra ei se lucrează cu integrala. Integrala din DSP ne dă puterea într-o anumită bandă de frecvențe.\n\nPuterea în banda de frecvență \\([f_1, f_2]\\) este \\(\\int_{f_1}^{f_2} S_{ff}(\\omega) d\\omega\\)\nPuterea totală este \\(P = \\int_{-\\infty}^{\\infty} S_{ff}(\\omega) d\\omega\\)\nPentru o singură frecvență individuală \\(f_1\\), puterea este mereu 0, excepție făcând daca spectrul semnalului conține un Dirac la acea frecvență.\n\nDensitatea spectrală de putere este o funcție măsurabilă practic, care poate fi determinată experimental, fiind importantă în aplicații practice (inginerești). (de ex. puterea de emisie într-o anumită bandă radio nu trebuie să treacă peste un anume nivel, pentru a nu interfera cu alte comunicații).\nCe reprezintă DSP pentru un proces aleator? Spre deosebire de un semnal determinist, un proces aletor nu este un singur semnal, ci o infinitate de realizări posibile. Fiecare realizare are o transformată Fourier proprie, diferită, așadar DSP este de fapt ea însăși un proces aleator.\nDSP a unui proces aleator trebuie înțeleasă ca fiind media DSP pentru toate realizările posibile. Ea are aceeași utilitate și semnificație ca în cazul unui semnal determinist, doar că în medie în raport cu toate realizările posibile."
  },
  {
    "objectID": "01_03_Autocorelatia.html#teorema-wiener-hincin",
    "href": "01_03_Autocorelatia.html#teorema-wiener-hincin",
    "title": "3  Proprietăți ale autocorelației",
    "section": "3.2 Teorema Wiener-Hincin",
    "text": "3.2 Teorema Wiener-Hincin\nTeorema Wiener-Hincin:\nDensitatea spectrală de putere este transformata Fourier a funcției de autocorelație: \\[S_{ff}(\\omega) = \\int_{-\\infty}^{\\infty} R_{ff}(\\tau) e^{- j \\omega \\tau} d\\tau\\] \\[R_{ff}(\\tau) = \\frac{1}{2 \\pi}\\int_{-\\infty}^{\\infty} S_{ff}(\\omega) e^{j \\omega \\tau} d\\omega\\]\nFără demonstrație.\nTeorema Wiener-Hincin e importantă întrucât leagă două concepte de natură complet diferită:\n\nfuncția de autocorelație, care este o proprietate statistică legată de modul de fluctuație al eșantioanelor unui proces aleatpr\ndensitatea spectrală de putere, o proprietate de natură fizică, care ține de energia semnalului"
  },
  {
    "objectID": "01_03_Autocorelatia.html#zgomot-alb",
    "href": "01_03_Autocorelatia.html#zgomot-alb",
    "title": "3  Proprietăți ale autocorelației",
    "section": "3.3 Zgomot alb",
    "text": "3.3 Zgomot alb\nUn zgomot alb este un proces aleator a cărui funcție de autocorelație este un Dirac în origine: \\[R_{ff}(\\tau) = \\delta(\\tau)\\]\nsau, echivalent, a cărui densitate spectrală de putere este constantă pentru orice frecvență:\n\\[S_{ff}(\\omega) = constant, \\forall \\omega \\]\n(Reminder: transformata Fourier a unui Dirac este un semnal constant).\nNoțiunile cheie din această definiție sunt următoarele:\n\nZgomotul alb este proces aleator, așadar orice eșantion este o variabilă aleatoare care fluctuează\nAutocorelația sa este un Dirac, adică este egală cu 0 pentru orice \\(\\tau \\neq 0\\), adică oricare două eșantioane diferite (\\(\\tau \\neq 0\\)) au corelație zero (necorelate). Ca interpretare, putem spune că valorile a două eșantioane distincte nu au legătură între ele, adică valoarea unuia nu implică nimic legat de valoarea altuia.\nDensitatea spectrală de putere este constantă, adică zgomotul afectează în mod egal toate frecvențele, până la \\(f = \\infty\\)\n\n\n\n\n\n\n\nImportant\n\n\n\nZgomotul alb poate avea orice distribuție (normală, uniformă etc.). Termenul “alb” nu se referă la densitatea de probabilitate a eșantioanelor, ci la faptul că valorile eșantioanele sunt necorelate între ele.\n\n\nZgomotul alb este mai degrabă un model matematic. În practică, zgomotele se pot abate de la definiție.\nDe exemplu, în practică, pentru orice semnal puterea scade la \\(0\\) când se ajunge la frecvențe foarte înalte, pentru că puterea totală \\(P = \\int_{-\\infty}^{\\infty} S_{ff}(\\omega)\\) nu poate fi infinită. Un astfel de zgomot de numește zgomot alb de bandă limitată. În acest caz, autocorelația este aproximativ un Dirac, dar nu chiar infinit de “subțire”, ceea ce face ca eșantioane foarte apropiate să fie totuși corelate (de ex. din cauza unor mici capacități parazite inevitabile).\nDe asemenea, nu toate zgomotele sunt albe. Exista fenomene care produc zgomote pentru care DSP scade odată cu frecvența. De exemplu, zgomotul tip \\(1/f\\) dintr-un circuit electric este un zgomot a cărui DSP este proporțională cu \\(1/f\\).\nModelul de zgomot cel mai întâlnit în aplicații este cel de zgomot alb, Gaussian, aditiv (AWGN, Additive White Gaussian Noise), ceea ce înseamnă:\n\nzgomot: este un proces aleator (fiecare eșantion este aleator, fiecare realizare este diferită)\nalb: valorile eșantioanelor sunt necorelate între ele\ngaussian: eșantioanele individuale au distribuția normală\naditiv: zgomotul se adună peste semnalul original (adică de ex. nu se multiplică cu acesta)"
  },
  {
    "objectID": "01_03_Autocorelatia.html#proprietățile-funcției-de-autocorelație",
    "href": "01_03_Autocorelatia.html#proprietățile-funcției-de-autocorelație",
    "title": "3  Proprietăți ale autocorelației",
    "section": "3.4 Proprietățile funcției de autocorelație",
    "text": "3.4 Proprietățile funcției de autocorelație\nSe pot formula o serie de proprietăți ale funcției de autocorelație:\n\nEste o funcție pară \\[R_{ff}(\\tau) = R_{ff}(-\\tau)\\]\n\nDemonstrație: Schimbare de variabilă în definiție\n\nLa infinit, tinde la o valoare constantă \\[R_{ff}(\\infty) = \\overline{f(t)}^2 = const\\]\n\nDem.: două eșantioane la un interval \\(\\infty\\) sunt necesar independente\n\nAre valoarea maximă în 0 \\[R_{ff}(0) \\geq R_{ff}(\\tau)\\]\n\nDem.: se pornește de la \\(\\overline{(f(t) - f(t + \\tau))^2} \\geq 0\\)\nInterpretare: eșantioane diferite mai pot varia diferit, dar un eșantion variază întotdeauna identic cu sine însuși\n\nValoarea în 0 = puterea procesului aleator \\[R_{ff}(0) = \\frac{1}{2 \\pi} \\int_{-\\infty}^{\\infty} S_{ff}(\\omega) d\\omega\\]\n\nDem.: Se pune \\(\\tau = 0\\) în transf. Fourier inversă din teorema Wiener-Hincin\n\nVarianța = diferența între valoarea din 0 și cea de la \\(\\infty\\) \\[\\sigma^2 = R_{ff}(0) - R_{ff}(\\infty)\\]\n\nDem.: \\(R_{ff}(0) = \\overline{f(t)^2}\\), \\(R_{ff}(\\infty) = \\overline{f(t)}^2\\)"
  },
  {
    "objectID": "01_03_Autocorelatia.html#autocorelația-unui-proces-aleator-filtrat",
    "href": "01_03_Autocorelatia.html#autocorelația-unui-proces-aleator-filtrat",
    "title": "3  Proprietăți ale autocorelației",
    "section": "3.5 Autocorelația unui proces aleator filtrat",
    "text": "3.5 Autocorelația unui proces aleator filtrat\nFie un proces aleator \\(x\\) aplicat la intrarea unui sistem oarecare \\(H\\), producând o ieșire \\(y\\):\n\nfie în timp continuu: intrarea \\(x(t)\\), sistemul \\(H(s)\\), ieșirea \\(y(t)\\)\nfie în timp discret: intrarea \\(x[n]\\), sistemul \\(H(z)\\), ieșirea \\(y[n]\\)\n\nDacă se știe că \\(y\\) este convoluția lui \\(x\\) cu răspunsul la impuls \\(h\\) al sistemului, cum depinde autocorelația ieșirii \\(y\\) de cea a intrării \\(x\\)?\nTeoremă\nLegătura dintre densitatea spectrală de putere la ieșie unui filtru, \\(S_{yy}(\\omega)\\), și cea a semnalului de intrare, S_{xx}(), este: \\[S_{yy}(\\omega) = S_{xx}(\\omega) \\cdot |H(\\omega)|^2\\]\nDSP a lui \\(y\\) este DSP a lui \\(x\\) multiplicată cu răspunsul în amplitudine, la pătrat, al filtrului\nDemonstrație\nFacem demonstrația doar pentru un proces aleator în timp discret. Avem: \\[\\begin{split}\nR_{yy}(\\tau) =& \\overline{y[n] y[n + \\tau]}\\\\\n=& \\overline{\\sum_{k_1=-\\infty}^\\infty h[k_1] x[n-k_1] \\sum_{k_2=-\\infty}^\\infty h[k_2] x[n+\\tau-k_2]}\\\\\n=& \\sum_{k_1=-\\infty}^\\infty \\sum_{k_2=-\\infty}^\\infty h[k_1] h[k_2] \\overline{x[n-k_1] x[n+\\tau-k_2]}\\\\\n=& \\sum_{k_1=-\\infty}^\\infty \\sum_{k_2=-\\infty}^\\infty h[k_1] h[k_2] R_{xx}[\\tau - k_1 + k_2]\n\\end{split}\\]\nDin teorema Wiener-Hincin se știe că: \\[S_{ff}(\\omega) = \\sum_{\\tau = -\\infty}^{\\infty} R_{ff}(\\tau) e^{- j \\omega \\tau}\\] așadar: \\[\nS_{yy}(\\omega) = \\sum_{\\tau=-\\infty}^{\\infty} \\sum_{k_1=-\\infty}^\\infty \\sum_{k_2=-\\infty}^\\infty h[k_1] h[k_2] R_{xx}[\\tau - k_1 + k_2] e^{- j \\omega \\tau}\n\\]\nSe face schimbare de variabilă \\(\\tau - k_1 + k_2 = u\\), și rezultă că \\(\\tau = u + k_1 - k_2\\). Înlocuind: \\[\\begin{split}\nS_{yy}(\\omega) =& \\sum_{u=-\\infty}^{\\infty} \\sum_{k_1=-\\infty}^\\infty \\sum_{k_2=-\\infty}^\\infty h[k_1] h[k_2] R_{xx}[u] e^{- j \\omega (u + k_1 + k_2)}\\\\\n=& \\sum_{u=-\\infty}^{\\infty} R_{xx}[u] e^{- j \\omega u} \\sum_{k_1=-\\infty}^\\infty h[k_1] e^{- j \\omega k_1} \\sum_{k_2=-\\infty}^\\infty h[k_2]  e^{ j \\omega k_2}\\\\\n=& S_{xx}(\\omega) \\cdot H(\\omega) \\cdot H*^(\\omega)\\\\\n=& S_{xx}(\\omega) \\cdot |H(\\omega)|^2\\\\\n\\end{split}\\]\nRelația este valabilă și pentru procese aleatoare continue."
  },
  {
    "objectID": "01_03_Autocorelatia.html#aplicații-ale-autocorelației",
    "href": "01_03_Autocorelatia.html#aplicații-ale-autocorelației",
    "title": "3  Proprietăți ale autocorelației",
    "section": "3.6 Aplicații ale (auto)corelației",
    "text": "3.6 Aplicații ale (auto)corelației\n\n3.6.1 Căutarea unei anume porțiuni într-un semnal mai mare\n\nCorelația a două semnale = o măsura a similarității celor două semnale\n\nFuncția de corelație măsoară similaritatea unui semnal cu toate versiunile decalate ale celuilalt\nExemplu numeric la tablă, semnale de lungime finită\n\nCorelația poate fi utilizată pentru localizare\n\nFuncția de (auto)corelație are valori mari atunci când cele două semnale se potrivesc\nValori mari sunt atunci când valorile pozitive / negative ale semnalelor se potrivesc\nValori mici atunci când nu se potrivesc\n\n\nSemnalul căutat:\nimport matplotlib.pyplot as plt, numpy as np\nx1 = np.array([1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1])\nx2 = np.hstack((np.random.randn(800), x1, np.random.randn(300)))\ncorr = np.correlate(x2, x1)\nplt.figure(figsize=(12,6))\nplt.stem(x1); plt.title ('Signal to look for');plt.axis([0, 20, -1.5, 1.5])\nplt.savefig('fig/01_RandomSignals_CorrSearch_Pattern.png', transparent=True, bbox_inches='tight', dpi=300)\nplt.close()\n\nSemnalul de dimensiuni mari:\nimport matplotlib.pyplot as plt, numpy as np\nx1 = np.array([1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1])\nx2 = np.hstack((np.random.randn(800), x1, np.random.randn(300)))\ncorr = np.correlate(x2, x1)\nplt.figure(figsize=(12,6))\nplt.stem(x2); plt.title ('Signal to search in');\nplt.savefig('fig/01_RandomSignals_CorrSearch_CompleteSignal.png', transparent=True, bbox_inches='tight', dpi=300)\nplt.close()\n\nRezultatul corelației:\nimport matplotlib.pyplot as plt, numpy as np\nx1 = np.array([1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1])\nx2 = np.hstack((np.random.randn(800), x1, np.random.randn(300)))\ncorr = np.correlate(x2, x1)\nplt.figure(figsize=(12,6))\nplt.stem(corr); plt.title ('Correlation signal');\nplt.savefig('fig/01_RandomSignals_CorrSearch_Result.png', transparent=True, bbox_inches='tight', dpi=300)\nplt.close()\n\n\n\n3.6.2 Identificare de sistem\n\nDeterminarea răspunsului la impuls al unui sistem necunoscut, liniar și invariant în timp\nSe bazează pe corelația intrării cu ieșirea sistemlui\n\n\n\n\nSystem identification setup\n\n\n\\[\\begin{split}\nR_{fg}(\\tau) =& \\overline{f[n] g[n + \\tau]}\\\\\n=& \\overline{f[n] \\sum_{k=-\\infty}^\\infty h[k] f[n+\\tau-k]}\\\\\n=& \\sum_{k=-\\infty}^\\infty h[k] \\overline{f[n] f[n+\\tau-k]}\\\\\n=& \\sum_{k=-\\infty}^\\infty h[k] R_{ff}[\\tau - k]\\\\\n=& h[\\tau] \\star R_{ff}[\\tau]\n\\end{split}\\]\n\nDacă intrarea \\(f\\) este zgomot alb cu puterea \\(A\\), \\(R_{ff}[n] = A \\cdot \\delta[n]\\), și \\[R_{fg}(\\tau) = h[\\tau] \\star R_{ff}[\\tau] = A \\cdot h[\\tau] \\star \\delta[\\tau] = A \\cdot h[\\tau]\\]\nCorelația măsurată este proporțională cu răspunsul la impuls al sistemului necunoscut"
  },
  {
    "objectID": "02_01_Detectia1Esantion.html#introducere",
    "href": "02_01_Detectia1Esantion.html#introducere",
    "title": "4  Decizie cu un singur eșantion",
    "section": "4.1 Introducere",
    "text": "4.1 Introducere\nO problemă de decizie înseamnă, pe scurt, a decide între două alternative.\nÎn contextul comunicațiilor, detecția semnalelor înseamnă a decide care semnal este prezent dintre două sau mai multe posibilități, în condițiile în care semnalul este afectat de zgomot aditiv (se adună la semnalul original)\nDificultatea este cauzată de zgomot, care ne poate “păcăli” în a lua o decizie greșită. Se pune așadar problema cum putem decide în mod robust, minimizând efectul zgomotului.\nPentru fixarea ideilor, prezentăm mai jos o schemă de principiu a unui sistem de comunicații..\n\n\n\nFigure 4.1: Schema bloc a unui sistem de comunicație\n\n\nElemente:\n\nSursa de informație: generează mesajele \\(a_n\\)\nGenerator: generează semnalele diferite \\(s_1(t)\\),…\\(s_n(t)\\)\nModulator: transmite semnalul \\(s_n(t)\\) aferent mesajului \\(a_n\\)\nCanal: adaugă zgomot aleator\nEșantionare: ia eșantioane din semnalul \\(s_n(t)\\)\nReceptor: decide ce mesaj \\(a_n\\) s-a fost recepționat\nUtilizator: primește mesajele recuperate\n\nAplicații:\n\nTransmisii de date cu diverse modulații binare:\n\nnivele constante de tensiune (de ex. \\(s_n(t)\\) = constant 0 sau 5V)\nmodulație PSK (Phase Shift Keying): \\(s_n(t)\\) = cosinus cu aceeași frecvență dar faze inițiale diferite\nmodulație FSK (Frequency Shift Keying): \\(s_n(t)\\) = cosinus cu frecvențe diferite\nmodulație OFDM (Orthogonal Frequency Division Multiplexing): caz particular de FSK\n\nDetecții radar\nSe emite un semnal, iar în cazul unui obstacol, semnalul se reflectă înapoi. Receptorul așteaptă posibilele reflecții ale semnalului emis și decide:\n\ndacă nu este prezentă o reflecție, se decide că nu există nici un obiect\ndacă semnalul reflectat este prezent, se decide că există un obiect\n\n\nProblema se poate generaliza în cazul mai multor semnale posibile.\nDecizie se poate baza pe un singur eșantion, pe mai multe eșantioane, sau pe observarea întregului semnal continuu pentru un timp \\(T\\), cazuri care vor fi tratate separat."
  },
  {
    "objectID": "02_01_Detectia1Esantion.html#decizie-cu-1-eșantion",
    "href": "02_01_Detectia1Esantion.html#decizie-cu-1-eșantion",
    "title": "4  Decizie cu un singur eșantion",
    "section": "4.2 Decizie cu 1 eșantion",
    "text": "4.2 Decizie cu 1 eșantion\nVom analiza mai întâi cel mai simplu scenariu, când la recepție se ia un singur eșantion din semnalul recepționat, și se decide pe baza sa.\nVom porni de la cea mai simplu exemplu posibil.\nSă prespunem că se transmite un bit, 0 logic sau 1 logic, folosind două nivele de tensiune constante. De exemplu, pentru 0 logic se poate transmite semnalul \\[s_0(t) = 0\\] iar pentru 1 logic se poate transmite semnalul \\[s_1(t) = 5\\]\nPe canalul de transmisie se suprapune zgomot. La recepție se ia un singur eșantion \\(r\\), și valoarea sa este \\(3.5\\).\nCe decizie luăm? Am recepționat un 0 sau un 1 logic?\nProblema se poate formula mai general astfel:\n\nExistă două mesaje posibile \\(a_0\\) și \\(a_1\\) (0 logic sau 1 logic)\nSe transmite un semnal \\(s(t)\\), care poate fi \\(s(t) = s_0(t)\\), a transmite \\(a_0\\), sau \\(s(t) = s_1(t)\\), pentru a transmite \\(a_1\\)\nPeste semnal se suprapune zgomotul \\(n(t)\\)\nLa recepție se primește un semnal cu zgomot, \\(r(t) = s(t) + n(t)\\)\nProblema deciziei: pe baza \\(r(t)\\), care semnal a fost cel transmis?\n\nVom introduce următoarea terminologie, cu notațiile aferente.\nExistă două ipoteze, notate \\(H_0\\) și \\(H_1\\):\n\n\\(H_0\\): semnalul adevărat este \\(s(t) = s_0(t)\\)\n\\(H_1\\): semnalul adevărat este \\(s(t) = s_1(t)\\)\n\nReceptorul poate lua una din două decizii, notate \\(D_0\\) și \\(D_1\\):\n\n\\(D_0\\): receptorul decide că semnalul corect este \\(s(t) = s_0(t)\\)\n\\(D_1\\): receptorul decide că semnalul corect este \\(s(t) = s_1(t)\\)\n\nExistă 4 situații posibile:\n\nRejecție corectă: ipoteza corectă este \\(H_0\\), decizia este \\(D_0\\)\n\nProbabilitatea este \\(P_r = P(D_0 \\cap H_0)\\)\nSe mai numește si “True Negative”\n\nAlarmă falsă: ipoteza corectă este \\(H_0\\), decizia este \\(D_1\\)\n\nProbabilitatea este \\(P_{af} = P(D_1 \\cap H_0)\\)\nSe mai numește și “False Positive”\n\nPierdere: ipoteza corectă este \\(H_1\\), decizia este \\(D_0\\)\n\nProbabilitatea este \\(P_p = P(D_0 \\cap H_1)\\)\nSe mai numește și “False Negative”\n\nDetecție corectă: ipoteza corectă este \\(H_1\\), decizia este \\(D_1\\)\n\nProbabilitatea este \\(P_d = P(D_1 \\cap H_1)\\)\nSe mai numește și “True Positive”\n\n\nTerminologia folosită are la origine aplicațiile radar, în care un semnal se emite de către sursă, iar semnalul recepționat poate conține, sau nu, o posibilă reflecție din partea unei ținte. Reflecția e puternic afectată de zgomot, ceea ce ne poate induce în eroare:\n\n“alarmă falsă” înseamnă ca nu există un obiect în realitate (ipoteza \\(H_0\\)), dar decizia este greșită și considră că există (\\(D_1\\)) nu există semnal reflectat (doar zgomot)\n“pierdere” (“miss”, lb.eng.) înseamnă că există un obiect în realitate (ipoteza \\(H_1\\)), dar decizia este că nu e nimic acolo (\\(D_0\\))\n\nÎn general se consideră zgomot aditiv, alb, staționar suprapus peste semnalul original\n\naditiv = zgomotul se adună cu semnalul\nalb = eșantioane distincte sunt necorelate\nstaționar = are aceleași proprietăți statistice la orice moment de timp\n\nSemnalul de zgomot \\(n(t)\\) este necunoscut, dar este o realizare a unui proces aleator, pentru care se cunoaște doar distribuția.\nLa recepție se primește semnalul \\(r(t) = s(t) + n(t)\\), unde:\n\n\\(s(t)\\) = semnalul original, fie \\(s_0(t)\\), fie \\(s_1(t)\\)\n\\(n(t)\\) = semnalul de zgomot necunoscut\n\nDin semnalul recepționat se ia un eșantion la momentul $t_0, adică: \\[r(t_0) = s(t_0) + n(t_0)\\] unde \\(s(t_0)\\) = fie \\(s_0(t_0)\\), fie \\(s_1(t_0)\\), iar \\(n(t_0)\\) este un eșantion de valoare necunoscută din semnalul de zgomot.\nEșantionul \\(n(t_0)\\) este o variabilă aleatoare, fiind un eșantion de zgomot (un eșantion dintr-un proces aleator)\nAșadar valoarea \\(r(t_0) = s(t_0) + n(t_0)\\) este suma dintre o constantă și o variabilă aleatoare, ceea ce înseamnă ce este este de asemenea o variabilă aleatoare, având aceeași distribuție ca eșantionaul de zgomot, dar translată cu valoarea constantei.\n\n\n\n\n\n\nExemplu\n\n\n\nSe transmite un semnal \\(s(t) = 2 \\cos(2\\pi \\cdot 1000 \\cdot t)\\), peste care se suprapune un zgomot gaussian \\(n(t)\\) cu distribuția \\(\\mathcal{N}(\\mu=0, \\sigma^2=0.5)\\). \\[r(t) = s(t) + n(t)\\]\nLa recepție se ia un eșantion la momentul \\(t_0 = 1\\). Atunci eșantionul are valoarea \\[r = r(1) = s(1) + n(1) = 2 \\cos(2\\pi \\cdot 1000 \\cdot 1) + n(1) = 2 + n(1)\\]\nÎntrucât \\(n(1)\\) are distribuția \\(\\mathcal{N}(\\mu=0, \\sigma^2=0.5)\\), atunci \\(r\\) are distribuția \\(\\mathcal{N}(\\mu=2, \\sigma^2=0.5)\\)."
  },
  {
    "objectID": "02_01_Detectia1Esantion.html#funcții-de-plauzibilitate",
    "href": "02_01_Detectia1Esantion.html#funcții-de-plauzibilitate",
    "title": "4  Decizie cu un singur eșantion",
    "section": "4.3 Funcții de plauzibilitate",
    "text": "4.3 Funcții de plauzibilitate\nSă presupunem că distribuția unui eșantion de zgomot este \\(w(x)\\).\n\nÎn ipoteza \\(H_0\\), adică dacă semnalul adevărat era \\(s_0(t)\\), atunci eșantionul \\(r\\) are distribuția: \\[w(r|H_0) = s_0(t_0) + w(x) = w(x)\\textrm{ translat cu } s_0(t_0)\\]\nÎn ipoteza \\(H_1\\), adică dacă semnalul adevărat era \\(s_1(t)\\), atunci eșantionul \\(r\\) are distribuția: \\[w(r|H_1) = s_1(t_0) + w(x) = w(x)\\textrm{ translat cu } s_1(t_0)\\]\n\nCele două distribuții vor fi numite distribuțiile condiționate sau funcțiile de plauzilibilate\nProblema deciziei se poate formula astfel:\n“Care dintre cele două distribuții, \\(w(r|H_0)\\) și \\(w(r|H_0)\\), este mai probabil să fi generat valoarea \\(r\\) a eșantionului observat la recepție?”\n\n\n\n\n\n\nExercițiu\n\n\n\nUn semnal constant \\(s(t)\\) poate avea două valori posibile, 0 sau 4. Semnalul este afectat de zgomot \\(\\mathcal{N}(\\mu=0, \\sigma^2 = 2)\\). Care e distribuția unui eșantion \\(r\\), în ambele ipoteze?\n\n\nSe definește plauzibilitatea unei ipoteze \\(H_i\\) pe baza observației \\(r\\) ca fiind: \\[L(H_i | r) = w(r | H_i)\\] adică valoarea distribuției condiționate de ipoteza \\(H_i\\), evaluată la valoarea \\(r\\) a eșantionului observat.\nÎn cazul nostru, plauzibilitatea ipotezei \\(H_0\\) este: \\[L(H_0 | r) = w(r | H_0)\\] și a ipotezei \\(H_1\\) este: \\[L(H_1 | r) = w(r | H_1)\\]"
  },
  {
    "objectID": "02_01_Detectia1Esantion.html#criteriul-plauzibilității-maxime-maximum-likelihood",
    "href": "02_01_Detectia1Esantion.html#criteriul-plauzibilității-maxime-maximum-likelihood",
    "title": "4  Decizie cu un singur eșantion",
    "section": "4.4 Criteriul Plauzibilității Maxime (Maximum Likelihood)",
    "text": "4.4 Criteriul Plauzibilității Maxime (Maximum Likelihood)\nDacă trebuie să decidem care dintre cele două ipoteze, \\(H_0\\) sau \\(H_1\\), este “responsabilă” pentru producerea valorii \\(r\\), o alegere naturală este ipoteza cu plauzibilitate mai mare.\nCriteriul plauzibilității maxime (“Maximum Likelihood”, ML): \\[\\frac{L(H_1 | r)}{L(H_0 | r)} = \\frac{w(r|H_1)}{w(r|H_0)} \\grtlessH 1\\]\nFracția \\(\\frac{w(r|H_1)}{w(r|H_0)}\\) poartă numele de raport de plauzibilitate. În criteriul ML, raportul de plauzibilitate se compară cu 1:\n\ndacă este supraunitar, se ia decizia \\(D_1\\) (\\(w(r|H_1)\\) e mai mare)\ndacă este subunitar, se ia decizia \\(D_0\\) (\\(w(r|H_0)\\) e mai mare)\ndacă este egal cu 1, avem o indecizie (plauzibilitățile sunt egale)\n\nPractic, decizia se ia alegând ipoteza cu cea mai mare plauzibilitate pentru valoarea \\(r\\), adică se alege valoarea maximă dintre \\(w(r(t_0)|H_0)\\) și \\(w(r(t_0) | H_1)\\).\n\n\n\n\n\n\nExemplu: Frunze\n\n\n\nDin care copac a căzut frunza?\n\n\n\nFigure 4.2: Vizualizare criteriu ML\n\n\n\n\n\n\n\n\n\n\nExercițiu\n\n\n\nUn semnal constant \\(s(t)\\) poate avea două valori posibile, 0 sau 4. Semnalul este afectat de zgomot \\(\\mathcal{N}(\\mu=0, \\sigma^2 = 2)\\). Care e distribuția unui eșantion \\(r\\), în ambele ipoteze?\nCare e decizia luată cu criteriul ML, pentru un eșantion \\(r=1.6\\)?\n\n\nSe schițează a celor două distribuții condiționate \\(w(r|H_0)\\) și \\(w(r|H_1)\\)\nCare funcție e mai mare în dreptul lui \\(r = 1.6\\)?\n\nDiscuție: ce decizie se ia pentru diferite valori ale lui \\(r\\)\nDiscuție: care este pragul \\(T\\) pentru decizii?\n\n\n\n4.4.1 Praguri și regiuni de decizie\nPunctele în care cele două distribuții condiționate \\(w(r|H_0)\\) și \\(w(r|H_1)\\) se intersectează determină niște praguri de decizie. Alegerea valorii celei mai apropiate pentru o decizie, echivalează, defapt, cu compararea lui \\(T\\) cu aceste praguri.\nRegiunile de decizie reprezintă intervalul de valori ale eșantionului \\(r\\) pentru care se ia o anumită decizie\n\nRegiunea de decizie \\(R_0\\) = intervalul de valori ale lui \\(r\\) care conduc la decizia \\(D_0\\)\nRegiunea de decizie \\(R_1\\) = intervalul de valori ale lui \\(r\\) care conduc la decizia \\(D_1\\)\n\nRegiunile de decizie acoperă întreg domeniul de valori ale lui \\(r\\) (toată axa reală), exceptând punctele sau regiunile de indecizie, unde nu se poate lua nici decizie \\(D_0\\) nici \\(D_1\\).\n\n\n4.4.2 Probabilități condiționate\nProbabilitățile condiționate ale celor 4 rezultate posibile ale unei decizii binare se definesc în felul următor.\nProbabilitatea condiționată a rejecției corecte reprezintă probabilitatea de a lua decizia \\(D_0\\) când ipoteza este \\(H_0\\), și se calculează ca probabilitatea lui \\(r\\) să fie în \\(R_0\\), calculată pe distribuția \\(w(r|H_0)\\) \\[P(D_0 | H_0) = \\int_{R_0} w(r|H_0) dx\\]\nProbabilitatea condiționată a alarmei false reprezintă probabilitatea de a lua decizia \\(D_1\\) când ipoteza corectă este \\(H_0\\), și se calculează ca probabilitatea ca \\(r\\) să fie în \\(R_1\\), calculată pe distribuția \\(w(r|H_0)\\) \\[P(D_1 | H_0) = \\int_{R_1} w(r|H_0) dx\\]\nProbabilitatea condiționată de pierdere reprezintă probabilitatea de a lua decizia \\(D_0\\) când ipoteza corectă este \\(H_1\\), și se calculează ca probabilitatea ca \\(r\\) să fie în \\(R_0\\), calculată pe distribuția \\(w(r|H_1)\\) \\[P(D_0 | H_1) = \\int_{R_0} w(r|H_1) dx\\]\nProbabilitatea condiționată a detecției corecte reprezintă probabilitatea de a lua decizia \\(D_1\\) când ipoteza este \\(H_1\\), și se calculează ca probabilitatea ca \\(r\\) să fie în \\(R_1\\), calculată pe distribuția \\(w(r|H_1)\\) \\[P(D_1 | H_1) = \\int_{R_1} w(r|H_1) dx\\]\nCele patru probabilități condiționate corespund celor patru arii din fig.xxx, determinate ce cele două distribuții condiționate și cele două regiuni de decizie.\n\n\n\nProbabilități condiționate\n\n\n\nIgnorați textul, contează zonele colorate\n[sursa: hhttp://gru.stanford.edu/doku.php/tutorials/sdt]*\n\nÎntre cele patru probabilități există următoarele relații:\n\\[P(D_0 | H_0) + P(D_1 | H_0) = 1\\] (rejecție corectă + alarmă falsă) \\[P(D_0 | H_1) + P(D_1 | H_1) = 1\\] (pierdere + detecție corectă)\n\n\n\n\n\n\nExercițiu\n\n\n\nDemonstrați cele două relații de mai sus.\n\n\n\n\n\n\n\n\nExercițiu\n\n\n\nUn semnal constant poate avea două valori posibile, \\(0\\) sau \\(5\\). Semnalul este afectat de zgomot gaussian \\(\\mathcal{N}\\;(\\mu=0, \\sigma^2=2)\\). Receptorul decide pe baza criteriului plauzibilității maxime, folosind un singur eșantion din semnal.\n\nCalculați probabilitatea condiționată a alarmei false\nCalculați probabilitatea condiționată de pierdere\nDacă \\(P(H_0) = \\frac{1}{3}\\) și \\(P(H_1) = \\frac{2}{3}\\), calculați probabilitatea rejecției corecte și a detecției corecte (nu cele condiționate)\n\n\n\n\n\n4.4.3 Optimalitatea criteriului ML\n\n\n\n\n\n\nTeoremă: optimalitatea criteriului ML\n\n\n\nCriteriul ML minimizează suma probabilităților condiționate de eroare, \\(P(D_1 | H_0) + P(D_0 | H_1)\\).\nDemonstrație:\nInformal: de pe figura precedentă, dacă pragul \\(T\\) se deplasează fie la dreapta fie la stânga, suma celor două arii hașurate (probabilități) pentru alarmă falsă + pierdere crește.\nTODO: demonstrație riguroasă\n\n\nTeorema ne spune că criteriul ML de decizie ne asigură cea mai mică probabilitate (condiționată) de a greși."
  },
  {
    "objectID": "02_01_Detectia1Esantion.html#criteriul-probabilității-minime-de-eroare-minimum-probability-of-error-mpe",
    "href": "02_01_Detectia1Esantion.html#criteriul-probabilității-minime-de-eroare-minimum-probability-of-error-mpe",
    "title": "4  Decizie cu un singur eșantion",
    "section": "4.5 Criteriul probabilității minime de eroare (Minimum Probability of Error, MPE)",
    "text": "4.5 Criteriul probabilității minime de eroare (Minimum Probability of Error, MPE)\nCriteriul ML compară doar distribuțiile condiționate ale eșantionului observat, ceea ce înseamnă că nu ia în calcul și probabilitatea inițială celor două ipoteze, \\(P(H_0)\\) și \\(P(H_1)\\). Dacă se consideră si acestea, ajungem la un alt criteriu de decizie, intitulat criteriul probabiității minime de eroare.\nCriteriul probabilității minime de eroare (Minimum Probabilityof Error, MPE): \\[\\frac{P(H_1) \\cdot w(r | H_1)}{P(H_0) \\cdot w(r | H_0)} \\grtlessH 1\\]\nCriteriul poate fi rescris tot ca o comparație a raportului de plauzibilitate, de data aceasta comparat cu raportul celor două probabilități ale ipotezelor. \\[\\frac{w(r | H_1)}{w(r | H_0)} \\grtlessH \\frac{P(H_0)}{P(H_1)}\\]\nCriteriul MPE este o generalizare a criteriului ML, care ia în calcul și probabilitățile \\(P(H_0)\\) și \\(P(H_1)\\). Criteriul ML poate fi considerat un caz particular al MPE pentru cazul uner probabilități egale ale ipotezelor, \\(P(H_0) = P(H_1) = \\frac{1}{2}\\).\n\n\n\n\n\n\nTeoremă: Optimalitatea criteriului MPE\n\n\n\nCriteriul MPE minimizează probabilitatea totală de eroare: \\[P_e = P_{af} + P_p = P(D_1 \\cap H_0) + P(D_0 \\cap H_1)\\]\nAceste probabiiltăți nu sunt probabilitățile condiționate, ca la criteriul ML, ci sunt cele care includ \\(P(H_i)\\) (probabilități necondiționate).\nDemonstrație:\nCriteriul MPE înseamnă, de fapt, decizia în felul următor:\n\nCând \\(w(r|H_1) \\cdot P(H_1) - w(r|H_0) \\cdot P(H_0) < 0\\) se ia decizia \\(D_0\\)\nCând \\(w(r|H_1) \\cdot P(H_1) - w(r|H_0) \\cdot P(H_0) > 0\\) se ia decizia \\(D_1\\)\n\nProbabilitatea unei alarme false este: \\[\\begin{split}\nP(D_1 \\cap H_0) =& P(D_1 | H_0) \\cdot P(H_0)\\\\\n=& \\int_{R_1} w(r | H_0) dx \\cdot P(H_0)\\\\\n=& (1 - \\int_{R_0} w(r | H_0) dx \\cdot P(H_0)\n\\end{split}\\]\nProbabilitatea de pierdere este: \\[\\begin{split}\nP(D_0 \\cap H_1) =& P(D_0 | H_1) \\cdot P(H_1)\\\\\n=& \\int_{R_0} w(r | H_1) dx \\cdot P(H_1)\n\\end{split}\\]\nSuma lor reprezintă probabilitatea totală a erorilor; \\[P_e = P(H_0) + \\int_{R_0} [w(r|H_1) \\cdot P(H_1) - w(r|H_0) \\cdot P(H_0)] dx\\]\nConform criteriului MPE, regiunea de decizie \\(R_0\\) cuprinde toate valorile pentru care \\[w(r|H_1) \\cdot P(H_1) - w(r|H_0) \\cdot P(H_0) < 0,\\] adică de fapt întreaga zonă în care integrala de mai sus este negativă. Acest lucru garantează valoarea minimă a integralei, deci valoarea minimă a \\(P_e\\) (termenul \\(P(H_0)\\) fiind constant).\n\n\nExercitiu: 0/5, prag la 2.5, numar de erori."
  },
  {
    "objectID": "02_01_Detectia1Esantion.html#criteriul-riscului-minim-minimum-risk-mr",
    "href": "02_01_Detectia1Esantion.html#criteriul-riscului-minim-minimum-risk-mr",
    "title": "4  Decizie cu un singur eșantion",
    "section": "4.6 Criteriul riscului minim (Minimum Risk, MR)",
    "text": "4.6 Criteriul riscului minim (Minimum Risk, MR)\nExistă situații în care ne afectează mai mult un anume tip de erori (de ex. alarme false) decât celelalte (pierderi). Criteriul MPE tratează toate erorile la fel, ceea ce nu ajută în aceste cazuri.\nPentru a descrie un astfel de scenariu, se atribuie un cost fiecărui scenariu, \\(C_{ij}\\) fiind costul deciziei \\(D_i\\) când ipoteza adevărată este \\(H_j\\), ideaa fiind de a minimiza costul mediu.\n\n\\(C_{00}\\) = costul unei rejecții corecte\n\\(C_{10}\\) = costul unei alarme false\n\\(C_{01}\\) = costul unei pierderi\n\\(C_{11}\\) = costul unei detecții corecte\n\nVrem să minimizăm costul mediu, numit și risc, calculat astfel: \\[R = C_{00} P(D_0 \\cap H_0) + C_{10} P(D_1 \\cap H_0) + C_{01} P(D_0 \\cap H_1) + C_{11} P(D_1 \\cap H_1)\\]\nIdeea de “costuri” și minimizare a costului mediu este frecvent întâlnită în literatura de specialitate. De exemplu, în codarea informației, “costul” unui mesaj este lungimea cuvântului de cod asociat, iar minimizarea costului mediu înseamnă minimizarea lungimii medii.\nMinimizarea riscului \\(R\\) conduce la următoarea regulă de decizie.\nCriteriul riscului minim (Minimum Risk, MR): \\[\\frac{w(r|H_1)}{w(r|H_0)} \\grtlessH \\frac{(C_{10}-C_{00})p(H_0)}{(C_{01}-C_{11})p(H_1)}\\]\nSe observă că criteriul MR este o generalizare a criteriului MPE, la rândul lui o generalizare a ML, și se exprimă tot pe baza unui raport de plauzibilitate.\nAtât probabilitățile cât și costurile pot influența decizia în favoarea uneia sau alteia dintre ipoteze\nCa și caz particular, dacă \\(C_{10}-C_{00} = C_{01}-C_{11}\\), atunci MR se reduce la criteriul MPE.\n\n\n\n\n\n\nTeoremă: Optimalitatea criteriului MR\n\n\n\nCriteriul MR definit mai sus asigură valoarea minimă a riscului \\(R\\).\nDemonstrație\nLa tablă."
  },
  {
    "objectID": "02_01_Detectia1Esantion.html#forma-generală-a-criteriilor-ml-mpe-și-mr",
    "href": "02_01_Detectia1Esantion.html#forma-generală-a-criteriilor-ml-mpe-și-mr",
    "title": "4  Decizie cu un singur eșantion",
    "section": "4.7 Forma generală a criteriilor ML, MPE și MR",
    "text": "4.7 Forma generală a criteriilor ML, MPE și MR\nCriteriile ML, MPE și MR au toate forma următoare: \\[\\frac{w(r|H_1)}{w(r|H_0)} \\grtlessH K,\\] unde \\(K\\) depinde de criteriul folosit:\n\npentru ML: \\(K=1\\)\npentru MPE: \\(K=\\frac{P(H_0)}{P(H_1)}\\)\npentru MR: \\(K=\\frac{(C_{10}-C_{00})p(H_0)}{(C_{01}-C_{11})p(H_1)}\\)"
  },
  {
    "objectID": "02_01_Detectia1Esantion.html#criteriile-ml-mpe-și-mr-pentru-zgomot-gaussian",
    "href": "02_01_Detectia1Esantion.html#criteriile-ml-mpe-și-mr-pentru-zgomot-gaussian",
    "title": "4  Decizie cu un singur eșantion",
    "section": "4.8 Criteriile ML, MPE și MR pentru zgomot gaussian",
    "text": "4.8 Criteriile ML, MPE și MR pentru zgomot gaussian\nConsiderăm un caz foarte des întâlnit în practică, acela în care zgomotul are o distribuție normală cu medie 0, \\(\\mathcal{N}(0,\\sigma^2)\\). Cu alte cuvinte, avem un zgomot tip AWGN.\nConsiderând forma comună a tuturor celor trei criterii, expresia devine): \\[\\frac{w(r|H_1)}{w(r|H_0)} = \\frac{e^{-\\frac{(r-s_1(t_0))^2}{2\\sigma^2}}}{e^{-\\frac{(r-s_0(r_0))^2}{2\\sigma^2}}} \\grtlessH K\\]\nAplicăm logaritmul natural acestei relații. Întrucât orice logaritm este o funcție monoton crescătoare, el nu schimbă rezultatul unei comparații (dacă \\(A < B\\), atunci \\(\\log(A) < \\log(B)\\)). Prin urmare, deciziile nu vor fi afectate. Aplicarea logaritmului natural la ambii termeni ai relației conduce la: \\[-(r-s_1(t_0))^2 + (r-s_0(t_0))^2 \\grtlessH \\ln(K)\\] care este echivalent cu: \\[(r-s_0(t_0))^2 \\grtlessH (r - s_1(t_0))^2 + \\ln(K).\\]\nRelația de mai sus se poate interpreta ca o comparația a distanțelor geometrice. Termenul \\((r-s_0(t_0)^2\\) este pătratul distanței goemetrice, pe axa numerelor reale, dintre \\(r\\) și \\(s_0(t_0)\\), iar \\((r-s_1(t_0))^2\\) pătratul distanței de la \\(r\\) la \\(s_1(t_0)\\). Așadar, putem spune că se compară pătratul a două distanțe, cu un termen suplimentar \\(\\ln(K)\\) care influențează balanța în favoarea uneia sau alteia dintre decizii (în funcție de probabiități și/sau costuri).\nPentru criteriul ML, \\(K=1\\), \\(\\ln(K) = 0\\) și relația se reduce chiar la alegerea distanței minime dintre \\(r(t_0)\\) și \\(s_1(t_0)\\), respectiv \\(s_0(t_0)\\).\nDin acest motiv, un sistem receptor care folosește criteriul de decizie ML se mai numește receptor de distanță minimă (“minimum distance receiver”)\nLuarea unei decizii pe baza distenței minime se mai numește și principiul celui mai apropiat vecin (“nearest neighbor”), și este un principiu foarte general, foarte des întâlnit in literatura de specialitate, sub diverse alte forme.\nRelația poate fi prelucrată în continuare. Prin desfacerea parantezelor se ajunge la: \\[r \\grtlessH \\frac{s_0(t_0) + s_1(t_0)}{2} + \\frac{\\sigma^2}{s_1(t_0) - s_0(t_0)} \\cdot\\ln K\\]\nTermenul din dreapta definește valoarea de prag T. Putem spune, așadar, că decizia se ia comparându-l pe \\(r\\) cu pragul \\(T\\)."
  },
  {
    "objectID": "02_01_Detectia1Esantion.html#alte-considerații",
    "href": "02_01_Detectia1Esantion.html#alte-considerații",
    "title": "4  Decizie cu un singur eșantion",
    "section": "4.9 Alte considerații",
    "text": "4.9 Alte considerații\n\n4.9.1 Probabilitate vs plauzibilitate\nExistă o distincție subtilă între termenii “probabilitate” și “plauzibilitate”. Să considerăm distribuția condiționată \\(w(r | H_i)\\) de la exemplul anterior:\n\\[\\frac{1}{\\sigma \\sqrt{2 \\pi}}e^{-\\frac{(r - s_i(t_0))^2}{2\\sigma^2}}\\]\nCare este necunoscuta în această expresie? În general, necunoscuta este \\(r\\), dar în cazul problemei noastre de deciziei \\(r\\) este cunoscut, și necunoscuta este de fapt \\(i\\), 0 sau 1, care duce la valoarea maximă a expresiei.\nÎn general, pentru aceeași expresie matematică a funcției de distribuție, dacă se cunosc parametrii statistici (de ex. \\(\\mu\\), \\(\\sigma\\), \\(H_i\\)) și necunoscuta este valoarea însăși (de ex. \\(r\\), \\(x\\)) atunci funcția o interpretăm ca densitatea de probabilitate.\nÎn situațiile, însă, în care că se cunoaște valoarea însăși (de ex. \\(r\\), \\(x\\)) și necunoscuta este un parametru statistic (de ex. \\(\\mu\\), \\(\\sigma\\), \\(i\\)), atunci denumim funcția funcție de plauzibilitate. Acest lucru explică diferența subtilă dintre cei doi termeni, probabilitate și plauzibilitate, care în limbajul comun sunt practic sinonimi.\n\n\n4.9.2 Generalizări\nProblema de decizie analizată până acum se poate generaliza în mai multe moduri.\n\nDacă zgomotul are altă distribuție?\n\nSe schițează distribuțiile condiționate\nSe evaluează pentru \\(r = r(t_0)\\)\nCriteriul ML = se alege cea mai mare funcție \\(w(r|H_i)\\) în punctul \\(r\\) dat\n\nRegiunile de decizie sunt date de punctele de intersecție ale distribuțiilor condiționate Pot fi mai multe intersectări, în general, deci mai multe praguri.\nDacă zgomotul are distribuție diferită în ipoteza \\(H_0\\) față de ipoteza \\(H_1\\)?\nÎn mod similar:\n\nSe schițează distribuțiile condiționate\nSe evaluează pentru \\(r = r(t_0)\\)\nCriteriul ML = se alege cea mai înaltă funcție \\(w(r|H_i)\\) în punctul \\(r\\) dat\n\nDacă cele două semnale \\(s_0(t)\\) și \\(s_1(t)\\) sunt constante / nu sunt constante?\n\nNu contează forma semnalelor\nTot ce contează sunt valorile celor două semnale la momentul de eșantionare \\(t_0\\):\n\n\\(s_0(t_0)\\)\n\\(s_1(t_0)\\)\n\n\nDacă avem mai mult de 2 ipoteze?\n\nSe extinde raționamentul la \\(n\\) ipoteze\nAvem \\(n\\) semnale posibile \\(s_0(t)\\), … \\(s_{n-1}(t)\\)\nAvem \\(n\\) valori diferite \\(s_0(t_0)\\), … \\(s_{n-1}(t_0)\\)\nAvem \\(n\\) distribuții condiționate \\(w(r|H_i)\\)\nSe alege distribuția \\(w(r|H_i)\\) cea mai înaltă pentru \\(r = r(t_0)\\) dat\n\nDacă se iau mai multe eșantioane din semnale?\n\nVa fi tratat separat într-un subcapitol ulterior\n\n\n\n\n\n\n\n\nExercițiu\n\n\n\nFie decizia între două semnale constante: \\(s_0(t) = -5\\) și \\(s_1(t)=5\\). Semnalele sunt afectate de zgomot alb cu distribuție gaussiană \\(\\mathcal{N}(0, \\sigma^2=1)\\) Receptorul ia un singur eșantion cu valoarea \\(r\\).\n\nSă se găsească regiunile de decizie conform criteriului MPE\nCalculați probabilitatea alarmei false și probabilitatea de pierdere\nRepetați a) și b) dacă \\(s_1(t)\\) este afectat de zgomot uniform \\(\\mathcal{U}[-4,4]\\)?\n\n\n\n\n\n\n\n\n\nExercițiu\n\n\n\nUn sistem airbag detectează un accident prin eșantionarea semnalului de la un senzor cu 2 valori posibile: \\(s_0(t) = 0\\) (OK) sau \\(s_1(t) = 5\\) (accident).\nSemnalul este afectat de zgomot gaussian \\(\\mathcal{N}\\;(\\mu=0, \\sigma^2=1)\\).\nSe ia un singur eșantion din semnal.\nCosturile scenariilor sunt: \\(C_{00} = 0\\), \\(C_{01} = 100\\), \\(C_{10} = 10\\), \\(C_{11} = -100\\)\n\nGăsiți regiunile de decizie \\(R_0\\) și \\(R_1\\)."
  },
  {
    "objectID": "02_01_Detectia1Esantion.html#criteriul-neyman-pearson",
    "href": "02_01_Detectia1Esantion.html#criteriul-neyman-pearson",
    "title": "4  Decizie cu un singur eșantion",
    "section": "4.10 Criteriul Neyman-Pearson",
    "text": "4.10 Criteriul Neyman-Pearson\nCriteriul Neyman-Pearson:\nSe aleg regiunile de decizie pentru a maximiza probabilitatea de detecție \\(P(D_1 \\cap H_1)\\), păstrând probabilitatea alarmei false sub o limită fixată \\(P(D_1 \\cap H_0) \\leq \\lambda\\).\nAcesta este un criteriu mai general decât toate cele de până acum. Se poate arăta ca criteriile ML, MPE și MR sunt cazuri particulare ale Neyman-Pearson, pentru diverse valori ale \\(\\lambda\\).\n\n\n\n\n\n\nExercițiu\n\n\n\nO sursă de informație produce două mesaje cu probabilitățile \\(p(a_0) = \\frac{2}{3}\\) și \\(p(a_1) = \\frac{1}{3}\\).\nMesajele sunt codate ca semnale constante cu valorile \\(-5\\) (\\(a_0\\)) și \\(5\\) (\\(a_1\\)).\nSemnalele sunt afectate de zgomot alb cu distribuție uniformă \\(U [-5,5]\\).\nReceptorul ia un singur eșantion \\(r\\).\n\nGăsiți regiunile de decizie conform criteriului Neymar-Pearson, pentru \\(P_{fa} \\leq 10^{-2}\\)\nCare este probabilitatea de detecție corectă?"
  },
  {
    "objectID": "02_01_Detectia1Esantion.html#metode-de-evaluare-a-rezultatelor",
    "href": "02_01_Detectia1Esantion.html#metode-de-evaluare-a-rezultatelor",
    "title": "4  Decizie cu un singur eșantion",
    "section": "4.11 Metode de evaluare a rezultatelor",
    "text": "4.11 Metode de evaluare a rezultatelor\nCum se evaluează o problemă de decizie?\nDe exemplu, fie două problemă de decize binară:\n\nUna în care avem \\(s_0(t) = 0\\), \\(s_1(t) = 10\\), și zgomot gaussian \\(\\mathcal{N}(\\mu=0, \\sigma^2 = 4)\\).\nO altă în care \\(s_0(t) = 10\\), \\(s_1(t) = 16\\), și zgomot uniform \\(\\mathcal{U}[-8, 8]\\)\n\nCare dintre cele două probleme e mai dificilă? Cu alte cuvinte, în care vom obține rezultate mai slabe?\n\n4.11.1 Caracteristica de operare a receptorului (ROC)\nPerformanța unui receptor poate fi ilustrată cu un grafic numit “Caracteristica de operare a receptorului” (“Receiver Operating Characteristic”, ROC)\nAcesta reprezintă graficul probabilității \\(P_{dc} = P(D_1 | H_1)\\) în funcție de probabilitatea \\(P_{af} = P(D_1 | H_0)\\), pentru diferite praguri T. Fiecare punct de pe curbă corespunde unei valori a lui \\(T\\).\n\n\n\nSample ROC curves\n\n\n[sursa: http://www.statisticshowto.com/receiver-operating-characteristic-roc-curve/]\nGraficul ne arată că există întotdeauna un compromis între \\(P_d\\) (bun) și \\(P_{fa}\\) (rău). Creșterea \\(P_d\\) implică și creșterea \\(P_{fa}\\), și vice-versa.\nO măsură a performanței globale a unui astfel de sistem este Area Under the Curve (AUC) a curbei ROC, care reprezintă, după cum îi spune și numele, aria totală de sub curba graficului. Aceasta valoare, cuprinsă între 0 și 1, este o valoare globală care caracterizează întregul sistem, indiferent de alegerea unui prag sau a altuia, deci indiferent de utilizarea unui criteriu sau al altuia.\nUn AUC=1 înseamnă un sistem perfect, în care este posibil să obținem \\(P_d = 1\\) și simultan \\(P_{fa} = 0\\). În practică, desigur, se obțin valori mai mici decât 1.\nAșadar, două situații diferite (două semnale diferite, algoritmi etc) se pot compara prin afișarea ROC si compararea AUC-urilor asociate\n\n\n4.11.2 Caracteristica Precision vs Recall\nUn grafic echivalent este cel de tip “Precision vs Recall”, întâlnit îndeosebi în literatura de specialitate din domeniul învățării automate (“machine learning”).\nCei doi termeni se definesc astfel:\nPrecision = \\(\\frac{P(D_1 \\cap H_1)}{P(D_1 \\cap H_1) + P(D_1 \\cap H_0)} = \\frac{\\textrm{True Positives}}{\\textrm{True Positives + False Positives}}\\)\nRecall = \\(\\frac{P(D_1 \\cap H_1)}{P(D_1 \\cap H_1) + P(D_0 \\cap H_1)} = P(D_1 | H_1) = \\frac{\\textrm{True Positives}}{\\textrm{True Positives + False Negatives}}\\)\n\n\n\nCurba Precision vs Recall dintr-o aplicație practică\n\n\nAplicația pentru care este obținut graficul precedent:\n\n\n\nDetecția mașinilor cu metode de inteligență artificială\n\n\n\n\n4.11.3 Raportul Semnal-Zgomot\nRaportul semnal zgomot (SNR) al unui sistem se definește ca \\[SNR = \\frac{\\text{puterea semnalului util}}{\\text{puterea zgomotului}}\\]\nPerformanțele oricărei probleme de decizie depind în mod fundamental de raportul semnal-zgomot al sistemului.\n\nSNR mare: performanță bună\nSNR mic: performanță slabă\n\nDe exemplu, să analizăm cum se pot îmbunătăți performanțele deciziei în situația din Fig.xxx. Aceasta se poate obține în două moduri:\n\nCreșterea diferenței dintre \\(s_0(t)\\) și \\(s_1(t)\\), ceea ce înseamnă creșterea amplitudinilor, deci crește puterea semnalelor;\nScăderea zgomotului, adică scade puterea zgomotului.\n\nAmbele soluții înseamnă, de fapt, creșterea raportului semnal zgomot.\n\n\n\n\n\n\nExemplu: Performanțele detecției în zgomot alb gaussian\n\n\n\nConsiderăm probabilități egale \\(P(H_0) = P(H_1) = \\frac{1}{2}\\).\nDeciziile se iau pe baza raportului de plauzibilitate \\[\\frac{w(r|H_1)}{w(r|H_0)} \\grtlessH K\\]\nProbabilitatea detecției corecte este \\[\\begin{split}\nP_d =& P(D_1 | H_1)\\\\\n=& \\int_{T}^{\\infty} w(r | H_1) \\\\\n=& (F(\\infty) - F(T)) \\\\\n=& \\frac{1}{2} \\left( 1 - erf \\left( \\frac{T - s_1(t_0)}{\\sqrt{2}\\sigma} \\right) \\right) \\\\\n=& Q \\left( \\frac{T - s_1(t_0)}{\\sqrt{2}\\sigma} \\right) \\\\\n\\end{split}\\]\nProbabilitatea alarmei false este \\[\\begin{split}\nP_{fa} =& P(D_1 | H_0) \\\\\n=& \\int_{T}^{\\infty} w(r | H_0) \\\\\n=& (F(\\infty) - F(T)) \\\\\n=& \\frac{1}{2} \\left( 1 - erf \\left( \\frac{T - s_0(t_0)}{\\sqrt{2}\\sigma} \\right) \\right) \\\\\n=& Q \\left( \\frac{T - s_0(t_0)}{\\sqrt{2}\\sigma} \\right) \\\\\n\\end{split}\\]\nRezultă \\(\\frac{T - s_0(t_0)}{\\sqrt{2}\\sigma} = Q^{-1} \\left( P_{fa}\\right)\\),\nși: \\(\\frac{T - s_1(t_0)}{\\sqrt{2}\\sigma} = Q^{-1} \\left( P_{fa}\\right) + \\frac{s_0(t_0) - s_1(t_0)}{\\sqrt{2}\\sigma}\\)\nÎnlocuind în \\(P_d\\), obținem:\n\\[P_d = Q \\left( \\underbrace{Q^{-1} \\left(P_{fa}\\right)}_{constant} + \\frac{s_0(t_0) - s_1(t_0)}{\\sqrt{2}\\sigma} \\right)\\]\nFie un scenariu simplu:\n\n\\(s_0(t_0) = 0\\)\n\\(s_1(t_0) = A = constant\\)\n\nObținem: \\[P_d = Q \\left( \\underbrace{Q^{-1} \\left(P_{fa}\\right)}_{constant} - \\frac{A}{\\sqrt{2}\\sigma} \\right)\\]\n\n\n\nPerformanțele detecției depind de SNR\n\n\n[sursa: Fundamentals of Statistical Signal Processing, Steven Kay]"
  },
  {
    "objectID": "02_01_Detectia1Esantion.html#alte-aplicații-ale-teoriei-deciziei",
    "href": "02_01_Detectia1Esantion.html#alte-aplicații-ale-teoriei-deciziei",
    "title": "4  Decizie cu un singur eșantion",
    "section": "4.12 Alte aplicații ale teoriei deciziei",
    "text": "4.12 Alte aplicații ale teoriei deciziei\nAceste criterii de decizie se pot utiliza și în alte aplicații, dintre cele mai generale, nu doar pentru a decide între semnale.\nEsența matematică a problemei este întotdeauna sub forma următoare:\n\navem 2 (sau mai multe) distribuții posibile\navem 1 valoare observată\ndeterminăm cea mai plauzibilă distribuție, pe baza valorii observate\n\nCu toate acestea, decizia se poate lua într-o varietate de situații:\n\nmedicină: un semnal ECG indică o boală sau nu?\nbusiness: va cumpăra clientul un produs, sau nu?\n\n\n\n\n\n\n\nExemplu (pur imaginar)\n\n\n\nO persoană sănătoasă are concentrația de trombocite pe ml de sânge distribuită aproximativ \\(\\mathcal{N} \\; (\\mu=100, \\sigma^2 = 20)\\).\nO persoană suferind de boala B are o valoare mult mai scăzută, distribuită aproximativ \\(\\mathcal{N} \\; (30, \\sigma^2=10)\\).\nÎn urma analizelor de laborator, ai obținut valoarea \\(r = 79\\). Decideți: sănătos sau nu?"
  },
  {
    "objectID": "02_02_DetectiaMaiMulteEsantioane.html",
    "href": "02_02_DetectiaMaiMulteEsantioane.html",
    "title": "5  Decizie cu mai multe eșantioane",
    "section": "",
    "text": "6 Decizie cu mai multe eșantioane\nPrin “observare continuă” înțelegem faptul se folosește întreg semnalul continuu, fără eșantionare. Acest lucru poate fi tratat ca un caz limită al deciziei cu \\(N\\) eșantioane, dar cu \\(N \\to \\infty\\)\nProblema se pune în același mod.\nSemnalele originale sunt \\(s_0(t)\\) si \\(s_1(t)\\), afectate de zgomot \\(n(t)\\). Presupunem doar zgomot Gaussian, pentru simplitate. Semnalul recepționat este \\(r(t)\\).\nÎn aceste condiții, recurgem tot la interpretarea deciziei folosind spații euclideene:\nToate criteriile de decizie sunt aceleași:\nÎn cazul zgomotului tip AWGN, folosim exact aceleași reguli de decizie, cea bazată pe distanțe, fie cea bazată pe produse scalare.\nDecizia pe baza distanței Euclideene: \\[d(\\vec{r}, \\vec{s_0})^2 \\grtlessH d(\\vec{r}, \\vec{s_1})^2  + 2 \\sigma^2 \\ln(K)\\] Singura diferență este că distanța se calculează cu formula precedentă, cu integrală, adecvată semnalelor continue.\nDecizie pe baza produselor scalare: \\[\\langle \\vec{r}, \\vec{s_1} \\rangle - \\frac{E_1}{2} \\grtlessH \\langle \\vec{r},\\vec{s_0} \\rangle - \\frac{E_0}{2} + \\sigma^2 \\ln(K)\\] Produsul scalar se calculează cu formula precedentă, cu integrală, adecvată semnalelor continue.\nSe observă așadar că toate interpretările rămân identice, se schimbă doar tipul de semnal cu care lucrăm.\nUn spațiu vectorial este o mulțime cu următoarele două proprietăți:\nSe presupune că există operațiile aritmetice de bază (suma, multiplicare cu o constantă).\nExemple:\nOperația fundamentală într-un spațiu vectorial este produsul scalar, definit ca:\nNorma (lungimea) unui vector = radical din produsul scalar cu sine însuși:\n\\[\\|\\vec{x}\\| = \\sqrt{ \\langle \\vec{x},\\vec{x} \\rangle }\\]\nDistanța între doi vectori = norma diferenței dintre ei:\n\\[d(\\vec{x}, \\vec{y}) = \\|\\vec{x} - \\vec{y}\\|\\]\nEnergia unui semnal = norma la pătrat:\n\\[E_x = \\|\\vec{x}\\|^2 = \\langle \\vec{x},\\vec{x} \\rangle\\]\nUnghiul dintre doi vectori:\n\\[cos(\\alpha) = \\frac{\\langle x,y \\rangle}{||x|| \\cdot ||y||}\\]\nTermenul \\(cos(\\alpha)\\) are are valoare între -1 și 1. În particular, dacă \\(\\langle x,y \\rangle = 0\\), vectorii se numesc ortogonali (perpendiculari).\nBonus: transformata Fourier = produs scalar al unui semnal \\(x(t)\\) cu semnale de forma \\(e^{j \\omega t}\\):\n\\[\\mathcal{F} \\{ x(t)\\} = \\langle x(t), e^{j \\omega t}\\rangle = \\int x(t) e^{-j \\omega t}\\]\nPentru semnale complexe, în formula produsului scalar cel de-al doilea termen se conjugă, de aceea este \\(-j\\) în loc de \\(j\\):\n\\[\\langle \\vec{x},\\vec{y} \\rangle = \\sum_i x_i y_i^*\\] \\[\\langle \\vec{x},\\vec{y} \\rangle = \\int x(t) y(t)^*\\]\nTrandformata Fourier pentru semnale discrete se definește similar, tot pe baza produsului scalar.\nConcluzie: definirea algoritmilor în mod generic, pe bază de produse scalare / distanțe / norme, ne permite să aplicăm aceeași definiție sau algoritm tuturor spațiilor vectoriale, în mod automat, indiferent ca e vorba de semnale discrete sau continue, mai scurte sau mai lungi etc."
  },
  {
    "objectID": "02_02_DetectiaMaiMulteEsantioane.html#definiția-problemei",
    "href": "02_02_DetectiaMaiMulteEsantioane.html#definiția-problemei",
    "title": "5  Decizie cu mai multe eșantioane",
    "section": "6.1 Definiția problemei",
    "text": "6.1 Definiția problemei\nSe transmite un semnal necunoscut \\(s(t)\\). Există două ipoteze:\n\n\\(H_0\\): semnalul original este \\(s(t) = s_0(t)\\)\n\\(H_1\\): semnalul original este \\(s(t) = s_1(t)\\)\n\nReceptorul poate lua două decizii:\n\n\\(D_0\\): se decide că semnalul a fost \\(s(t) = s_0(t)\\)\n\\(D_1\\): se decide că semnalul a fost \\(s(t) = s_1(t)\\)\n\nÎn total, vor fi 4 scenarii posibile.\nSemnalul e afectat de zgomot (necunoscut), așadar se recepționează un semnal afectat de zgomot:\n\\(r(t) = s(t) + n(t)\\)\nDin \\(r(t)\\) se iau N eșantioane, nu doar 1. Fiecare eșantion \\(r_i = r(t_i)\\) se ia la momentul \\(t_i\\). Eșantioanele formează vectorul de eșantioanelor\n\\[\\vec{r} = [r_1, r_2, ... r_N]\\]\nFiecare eșantion \\(r_i\\) este o variabilă aleatoare, obținută ca suma dintre o constantă \\(s(t_i)\\) și un eșantion de zgomot \\(n(t_i)\\):\n\\(r(t_i) = s(t_i) + n(t_i)\\) = constantă + o v.a.\nÎntreg vectorul \\(\\vec{r}\\) reprezintă un set de \\(N\\) v.a. dintr-un proces aleator, iar valorile vectoruluisunt descrise de distribuții de ordin \\(N\\):\n\nÎn ipoteza \\(H_0\\): \\[w_N(\\vec{r} | H_0) = w_N(r_1, r_2, ...r_N | H_0)\\]\nÎn ipoteza \\(H_1\\): \\[w_N(\\vec{r} | H_1) = w_N(r_1, r_2, ...r_N | H_1)\\]"
  },
  {
    "objectID": "02_02_DetectiaMaiMulteEsantioane.html#criterii-de-decizie",
    "href": "02_02_DetectiaMaiMulteEsantioane.html#criterii-de-decizie",
    "title": "5  Decizie cu mai multe eșantioane",
    "section": "6.2 Criterii de decizie",
    "text": "6.2 Criterii de decizie\nSe vor aplica exact aceleași criterii de decizie, bazate pe raportul de plauzibilitate similar ca în cazul unui singur eșantion, cu diferența că acum \\(\\vec{r}\\) este un vector:\n\\[\\frac{w_N(\\vec{r} | H_1)}{w_N(\\vec{r} | H_0)} \\grtlessH K\\]\nObservații:\n\n\\(\\vec{r}\\) este un vector; prin el se consideră plauzibilitatea tuturor eșantioanelor\n\\(w_N(\\vec{r} | H_0)\\) = plauzibilitatea vectorului \\(\\vec{r}\\) în ipoteza \\(H_0\\)\n\\(w_N(\\vec{r} | H_1)\\) = plauzibilitatea vectorului \\(\\vec{r}\\) în ipoteza \\(H_1\\)\nvaloarea lui \\(K\\) este dată de criteriul de decizie utilizat\n\nDacă zgomotul este alb (cel mai întâlnit în practică), atunci eșantioanele \\(r_i\\) sunt independente, și distribuția vectorului \\(\\vec{r}\\) poate fi descompusă ca un produs\n\\[w_N(\\vec{r} | H_j) = w(r_1|H_j) \\cdot w(r_2|H_j) \\cdot ... \\cdot w(r_N|H_j)\\]\nDe exemplu, plauzibilitatea obținerii vectorului \\([5.1, 4.7, 4.9]\\) = plauzibilitatea obținerii lui \\(5.1\\) \\(\\times\\) plauzibilitatea obținerii lui \\(4.7\\) \\(\\times\\) plauzibilitatea obținerii lui \\(4.9\\)\nPrin urmare, criteriile bazate pe raportul de plauzibilitate devin \\[\\frac{w_N(\\vec{r} | H_1)}{w_N(\\vec{r} | H_0)} = \\frac{w(r_1|H_1)}{w(r_1|H_0)}  \\cdot\n\\frac{w(r_2|H_1)}{w(r_2|H_0)} ... \\frac{w(r_N|H_1)}{w(r_N|H_0)} \\grtlessH K\\]\nAșadar, raportul de plauzibilitate al unui vector de eșantioane se obține înmulțind rapoartele de plauzibilitate ale fiecărui eșantion în parte, și se aplică criteriile de decizie obișnuit asupra asupra rezultatului final.\nToate criteriile de decizie pot fi scrise astfel: \\[\\frac{w_N(\\vec{r} | H_1)}{w_N(\\vec{r} | H_0)} = \\frac{w(r_1|H_1)}{w(r_1|H_0)}  \\cdot\n\\frac{w(r_2|H_1)}{w(r_2|H_0)} ... \\frac{w(r_N|H_1)}{w(r_N|H_0)} \\grtlessH K\\]\nValoarea lui \\(K\\) se alege în funcție de criteriul anume care se dorește a fi folosit, la fel ca în cazul unui singur eșantion:\n\ncriteriul ML: \\(K=1\\)\ncriteriul MPE: \\(K=\\frac{P(H_0)}{P(H_1)}\\)\ncriteriul MR: \\(K=\\frac{(C_{10}-C_{00})p(H_0)}{(C_{01}-C_{11})p(H_1)}\\)"
  },
  {
    "objectID": "02_02_DetectiaMaiMulteEsantioane.html#caz-particular-zgomot-awgn",
    "href": "02_02_DetectiaMaiMulteEsantioane.html#caz-particular-zgomot-awgn",
    "title": "5  Decizie cu mai multe eșantioane",
    "section": "6.3 Caz particular: zgomot AWGN",
    "text": "6.3 Caz particular: zgomot AWGN\nÎn cazul zgomotul gaussian tip AWGN (“Additive White Gaussian Noise”, zgomot alb, gaussian, aditiv), expresiile se simplifică semnificativ.\nPentru ipoteza \\(H_1\\), avem: \\[w(r_i|H_1) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(r_i - s_1(t_i))^2}{2 \\sigma^2}}\\]\nPentru ipoteza \\(H_0\\): \\[w(r_i|H_0) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(r_i - s_1(t_i))^2}{2 \\sigma^2}}\\]\nRaportul de plauzibilitate al vectorului \\(\\vec{r}\\) va fi: \\[\\frac{w_N(\\vec{r} | H_1)}{w_N(\\vec{r} | H_0)} = \\frac{e^{-\\frac{\\sum (r_i - s_1(t_i))^2}{2 \\sigma^2}}}{e^{-\\frac{\\sum (r_i - s_0(t_i))^2}{2 \\sigma^2}}} = e^{\\frac{\\sum (r_i - s_0(t_i))^2 - \\sum (r_i - s_1(t_i))^2}{2 \\sigma^2}}\\] și se compară, așa cum am văzut, cu \\(K\\): \\[\\frac{w_N(\\vec{r} | H_1)}{w_N(\\vec{r} | H_0)} = e^{\\frac{\\sum (r_i - s_0(t_i))^2 - \\sum (r_i - s_1(t_i))^2}{2 \\sigma^2}} \\grtlessH K\\]\nAplicând logaritmul natural, obținem: \\[\\sum (r_i - s_0(t_i))^2 \\grtlessH \\sum (r_i - s_1(t_i))^2  + 2 \\sigma^2 \\ln(K)\\]\n\n6.3.1 Interpretarea 1: distanța geometrică\nCele două sume reprezintă distanța geometrică la pătrat dintre vectorul observat \\(\\vec{r}\\) și semnalele originale \\(s_1(t)\\), respectiv \\(s_0(t)\\)\n\\[\\sum (r_i - s_1(t_i))^2 = \\|\\vec{r} - \\vec{s_1(t)}\\|^2 = d(\\vec{r}, s_1(t))^2\\] \\[\\sum (r_i - s_0(t_i))^2 = \\|\\vec{r} - \\vec{s_0(t)}\\|^2 = d(\\vec{r}, s_0(t))^2\\]\nÎntrucât avem de-a face cu vectori de N eșantioane, aplicăm relația de distanță Euclideanp între vectori de dimensiune \\(N\\).\nPentru zgomot gaussian, toate criteriile de decizie se reduc așadar la a compara distanțele (la pătrat):\n\nCriteriul Maximum Likelihood:\n\n\\(K = 1\\), \\(\\ln(K) = 0\\)\nse alege distanța minimă între \\(\\vec{r}\\) și vectorii \\(s_1(t)\\), respectiv \\(s_0(t)\\))\nde unde și numele “receptor de distanță minimă”\n\nCriteriul Minimum Probability of Error:\n\n\\(K = \\frac{P(H_0)}{P(H_1)}\\)\nApare un termen suplimentar, în favoarea ipotezei mai probabile\n\nCriteriul Minimum Risk:\n\n\\(K=\\frac{(C_{10}-C_{00})p(H_0)}{(C_{01}-C_{11})p(H_1)}\\)\nTermenul suplimentar depinde și de probabilități, și de costuri\n\n\n\n\n\n\n\n\nExercițiu\n\n\n\nUn semnal poate avea două valori, \\(0\\) (ipoteza \\(H_0\\)) sau \\(6\\) (ipoteza \\(H_1\\)). Semnalul este afectat de AWGN \\(\\mathcal{N}(0, \\sigma^2=1)\\). Receptorul ia 5 eșantioane cu valorile \\(\\left\\{ 1.1, 4.4, 3.7, 4.1, 3.8 \\right\\}\\).\n\nCe decizie se ia conform criteriului plauzibilității maxime?\nCe decizie se ia conform criteriului probabilității minime de eroare. dacă \\(P(H_0) = 2/3\\) și \\(P(H_1) = 1/3\\)?\nCe decizie se ia conform criteriului roscului minim. dacă \\(P(H_0) = 2/3\\) și \\(P(H_1) = 1/3\\), iar \\(C_{00} = 0\\), \\(C_{10} = 10\\), \\(C_{01} = 20\\), \\(C_{11} = 5\\)?\n\n\n\n\n\n\n\n\n\nAlt exercițiu\n\n\n\nFie detecția unui semnal \\(s(t) = 3 \\sin(2 \\pi f t)\\) care poate fi prezent (ipoteza \\(H_1\\)) sau absent (\\(s_0(t) = 0\\), ipoteza \\(H_0\\)).\nSemnalul este afectat de zgomot alb Gaussian \\(\\mathcal{N}(0, \\sigma^2=1)\\).\nReceptorul ia două eșantioane.\n\nCare sunt cele mai bune momente de eșantionare \\(t_1\\) și \\(t_2\\) pentru a maximiza performanțele detecției?\nReceptorul ia două eșantioane \\(\\left\\{ 1.1, 4.4 \\right\\}\\), la momentele de timp \\(t_1 = \\frac{0.125}{f}\\) și \\(t_2 = \\frac{0.625}{f}\\). Care este decizia, conform criteriului plauzibilității maxime?â\nDacă se folosește criteriul probabilității minime de eroare, cu \\(P(H_0) = 2/3\\) și \\(P(H_1) = 1/3\\)?\nDacă se folosește criteriul riscului minim, cu \\(P(H_0) = 2/3\\) și \\(P(H_1) = 1/3\\), iar \\(C_{00} = 0\\), \\(C_{10} = 10\\), \\(C_{01} = 20\\), \\(C_{11} = 5\\)?\nDar dacă receptorul ia un al treilea eșantion la momentul \\(t_3 = \\frac{0.5}{f}\\). Se poate îmbunătăți detecția?\n\n\n\n\n\n6.3.2 Interpretarea 2: produs scalar\nDacă se descompun în continuare parantezele în relația: \\[\\sum (r_i - s_0(t_i))^2 \\grtlessH \\sum (r_i - s_1(t_i))^2  + 2 \\sigma^2 \\ln(K),\\]\nobținem:\n\\[\\begin{split}\n\\sum (r_i )^2 + \\sum s_0(t_i)^2& - 2 \\sum r_i s_0(t_i) \\grtlessH \\sum (r_i )^2 + \\\\\n& + \\sum s_1(t_i)^2 - 2 \\sum r_i s_1(t_i)  + 2 \\sigma^2 \\ln(K)\n\\end{split}\\]\ncare este echivalent cu: \\[\\sum r_i s_1(t_i) - \\frac{ \\sum (s_1(t_i))^2}{2} \\grtlessH \\sum r_i s_0(t_i) - \\frac{\\sum (s_0(t_i))^2 }{2}  + \\sigma^2 \\ln(K)\\]\nProdusul scalar al vectorilor \\(\\vec{a}\\) și \\(\\vec{b}\\) se definește astfel: \\[\\langle a,b \\rangle = \\sum_i a_i b_i\\]\nÎn relația noastră, avem:\n\n\\(\\sum r_i s_1(t_i) = \\langle \\vec{r}, \\vec{s_1(t)} \\rangle\\) este produsul scalar al vectorului \\(\\vec{r} = [r_1, r_2, ... r_N]\\) cu \\(\\vec{s_1(t_i)} = [s_1(t_1), s_1(t_2), ... s_1(t_N)]\\)\n\\(\\sum r_i s_0(t_i) = \\langle \\vec{r}, \\vec{s_0(t)} \\rangle\\) este produsul scalar al vectorului \\(\\vec{r} = [r_1, r_2, ... r_N]\\) cu \\(\\vec{s_0(t_i)} = [s_0(t_1), s_0(t_2), ... s_0(t_N)]\\)\n\\(\\sum (s_1(t_i))^2 = \\sum s_1(t_i) \\cdot s_1(t_i) = \\langle \\vec{s_1(t)}, \\vec{s_1(t)} \\rangle = E_1\\) este energia vectorului \\(s_1(t)\\)\n\\(\\sum (s_0(t_i))^2 = \\sum s_0(t_i) \\cdot s_0(t_i) = \\langle \\vec{s_0(t)}, \\vec{s_0(t)} \\rangle = E_0\\) este energia vectorului \\(s_0(t)\\)\n\nDecizia se poate rescris sub forma: \\[\\langle \\vec{r}, \\vec{s_1} \\rangle - \\frac{E_1}{2} \\grtlessH \\langle \\vec{r},\\vec{s_0} \\rangle - \\frac{E_0}{2} + \\sigma^2 \\ln(K)\\]\nInterpretarea pe care o dăm este următoarea. Pentru zgomot gaussian, decizia se ia comparând produsele scalare dintre semnalul recepționat și semnalele originale. În relație se scad energiile semnalelor, pentru o comparație corectă, și mai există de asemenea termenul suplimentar care depinde de criteriul de decizie ales.\nÎn matematică, produsul scalar măsoară similitudinea a două semnale, așadar putem spune că, pentru a lua o decizie, verificăm dacă vectorul eșantioanelor \\(\\vec{r}\\) este mai asemănător cu \\(s_1(t)\\) sau cu \\(s_0(t)\\)\n\n\n\nDecizie între două semnale\n\n\n[sursa: Fundamentals of Statistical Signal Processing, Steven Kay]\n\n6.3.2.1 Exemplu: BPSK\nDemodulare BPSK:\n\n\n\nDecizie BPSK: implementare directă\n\n\n\n\n\nDecizie BPSK: implementare mai eficientă\n\n\n\n\n\nDecizie QPSK: implementare directă\n\n\n\n\n\nDecizie QKSP: implementare mai eficientă\n\n\n\n\n\n6.3.3 Filtru adaptat\nProdusul scalar a doi vectori se poate calcula relativ mai simplu folosind un filtru liniar, numit filtru adaptat.\nDat fiind un semnal \\(s[n]\\) care se dorește a fi detectat, un filtru adaptat este un filtru proiectat să aibă răspunsul la impuls egal cu oglindirea semnalului care se dorește a fi detectat (eng. “matched filter”)\n\\[h[n] = s[N-1-n]\\] Spunem că filtrul este adaptat semnalului dorit.\nExemplu:\n\ndacă \\(s[n] = [\\underuparrow{1}, 2, 3, 4, 5, 6]\\)\natunci \\(h[n] = s[N-1-n] = [\\underuparrow{6}, 5, 4, 3, 2, 1]\\)\n\nDaca la intrarea unui filtru adaptat semnalului \\(s[n]\\) se pune un semnal \\(r[n]\\), atunci eșantionul de la ieșirea filtrului la momentul \\(N-1\\) este egal cu produsul scalar al vectorilor \\(r[n]\\) și \\(s[n]\\).\nDemonstrație:\nSemnalul de ieșire, \\(y[n]\\), este convoluția dintre intrarea \\(r[n]\\) și răspunsul la impuls \\(h[n]\\), adică: \\[y[n] = \\sum_k r[k] h[n-k] = \\sum_k r[k] s[N-1-n+k]\\]\nLa momentul \\(n=N-1\\), adică imediat după ultimul eșantion al semnalului de intrare, ieșirea este: \\[y[N-1] = \\sum_k r[k] s[k],\\] adică chiar produsul scalar:\n\nPentru decizia între două semnale, se folosește un filtru adaptat la semnalul \\(s_1(t_i)\\) și un alt filtru adaptat la semnalul \\(s_0(t_i)\\), se eșantionează ieșirile la momentul final \\(n = N-1\\) obținându-se valorile produselor scalare, care apoi se compară conform relației de decizie.\nDacă unul din semnale este 0, de exemplu \\(s_0(t) = 0\\), avem nevoie doar de un singur filtru adaptat pentru \\(s_1(t)\\), și se compară rezultatul cu un prag\n\n\n\nDetecție folosind un filtru adaptat\n\n\n[sursa: Fundamentals of Statistical Signal Processing, Steven Kay]"
  },
  {
    "objectID": "02_03_AlgoritmiPractici.html#algoritmul-k-nn",
    "href": "02_03_AlgoritmiPractici.html#algoritmul-k-nn",
    "title": "6  Algoritmi practici",
    "section": "6.1 Algoritmul k-NN",
    "text": "6.1 Algoritmul k-NN\n\n6.1.1 Definiția algoritmului\nAlgoritmul k-Nearest Neighbours (k-NN) este descris mai jos.\n\nIntrare:\n\nset de antrenare cu vectorii \\(\\vec{x}_1 ... \\vec{x}_N\\), din \\(L\\) clase posibile de semnal \\(C_1\\)…\\(C_L\\)\nclasele vectorilor de antrenare sunt cunoscute\nvector de test \\(\\vec{r}\\) care trebuie clasificat\nparametrul \\(k\\)\n\n\n\nSe calculează distanța între \\(\\vec{r}\\) și fiecare vector de antrenare \\(\\vec{x}_i\\)\n\nse poate utiliza distanța Euclidiană, aceeași utilizată pentru detecția semnalelor din secțiunile precedente\n\nSe aleg cei mai apropiați \\(k\\) vectori de \\(\\vec{r}\\) (cei \\(k\\) “nearest neighbours”)\nSe determină clasa lui \\(\\vec{r}\\) = clasa majoritară între cei \\(k\\) cei mai apropiați vecini\n\n\nIeșire: clasa vectorului \\(\\vec{r}\\)\n\n\n\n\nAlgoritmul k-NN ilustrat [1]\n\n\n\n\n6.1.2 Relația între k-NN și decizia ML\nDacă setul de antrenare este foarte mare, algoritmul k-NN devine simular cu decizia pe baza criteriului ML, pentru că numărul de vectori situați într-o vecinătate a unui punct \\(r\\) este proporțional cu \\(w(r|H_i)\\). Așadar, dacă sunt mai mulți vecini din clasa A decât din clasa B, caz în care k_NN ia decizia A, e totuna cu a spune că \\[w(r|H_A) > w(r|H_B)\\] care este de fapt regula de decizie ML, tot în favoarea clasei A.\nExemplu: frunze și copaci, de povestit.\n\n\n\n\n\n\nExercițiu\n\n\n\n\nFie următorul set de antrenare, compus din 5 vectori din clasa A și alți 5 vectori din clasa B:\n\nClasa A: \\[\n\\vec{v}_1 = \\begin{bmatrix}  1 \\\\ -2 \\end{bmatrix}\\;\n\\vec{v}_2 = \\begin{bmatrix} -1 \\\\  1 \\end{bmatrix}\\;\n\\vec{v}_3 = \\begin{bmatrix} -4 \\\\  2 \\end{bmatrix}\\;\n\\vec{v}_4 = \\begin{bmatrix}  2 \\\\  1 \\end{bmatrix}\\;\n\\vec{v}_5 = \\begin{bmatrix} -2 \\\\ -2 \\end{bmatrix}\\]\nClasa B: \\[\n\\vec{v}_6    = \\begin{bmatrix}  7 \\\\ 0 \\end{bmatrix}\\;\n\\vec{v}_7    = \\begin{bmatrix}  2 \\\\ 3 \\end{bmatrix}\\;\n\\vec{v}_8    = \\begin{bmatrix}  3 \\\\ 2 \\end{bmatrix}\\;\n\\vec{v}_9    = \\begin{bmatrix} -3 \\\\ 8 \\end{bmatrix}\\;\n\\vec{v}_{10} = \\begin{bmatrix} -2 \\\\ 5 \\end{bmatrix}\\]\n\nDeterminați clasa vectorului \\(\\vec{x} = \\begin{bmatrix} -3 \\\\ 6 \\end{bmatrix}\\) utilizând algoritmul k-NN, cu \\(k=1\\), \\(k=3\\), \\(k=5\\), \\(k=7\\) and \\(k=9\\)\n\n\n\n\n\n6.1.3 Discuții\nAlgoritmul k-NN este un algoritm de învățare supervizată, întrucât se cunosc clasele vectorilor din setul de antrenare.\nEfectul lui \\(k\\) se reflectă în gradul de “netezire” a frontierei de decizie: - \\(k\\) mic: frontieră foarte cotită / “șifonată” / cu multe coturi - \\(k\\) mare: frontieră mai netedă\nCum se găsește o valoare optimă pentru \\(k\\)?. În general, doar prin încercări (“băbește”), pe baza unui mic set de date de test. Această metodă se numește “cross-validation”.\n“Cross-validation” = folosirea unui mic set de test pentru a verifica care valoare a parametrului e mai bună\nAcest set de date se numește set de “cross-validare”.\nPractic, se alege \\(k=1\\), și se testează cu setul de “cross-validare” câți vectori sunt clasificați corect. Apoi se repetă pentru \\(k=2, 3, ... max\\). La final se alege valoarea lui \\(k\\) cu care s-au obținut rezultatele cele mai bune.\n\n\n6.1.4 Evaluarea algoritmilor\n\nCum se evaluează performanța algoritmului k-NN?\n\nSe folosește un set de date de testare, și se calculează procentajul vectorilor clasificați corect\n\n\n\nSetul de date pentru evaluarea finală trebuie să fie diferit de setul de “cross-validare”\n\npentru evaluarea finală se folosesc date pe care algoritmul nu le-a mai utilizat niciodată\n\n\n\nCum se împarte setul de date disponibile?\n\n\n\n6.1.5 Seturi de date\n\nPresupunem că avem în total 200 imagini tip fețe, 100 imagini ale persoanei A și 100 ale lui B\n\n\nSetul de date total se împarte în:\n\nSet de antrenare\n\nvectorii care vor fi utilizați de algoritm\ncel mai numeros, aprox. 60% din datele totale\nde ex. 60 imagini ale persoanei A și 60 ale lui B \n\nSet de cross-validare\n\nutilizat pentru a testa algoritmul în vederea alegerii parametrilor optimi (\\(k\\))\nmai mic, aprox. 20% din date (de ex. 20 imagini ale lui of A și 20 ale lui B) \n\nSet de testare\n\nutilizat pentru evaluarea finală a algoritmului, cu valorile parametrilor fixate\nmai mic, aprox. 20% din date (de ex. 20 imagini ale lui of A și 20 ale lui B)"
  },
  {
    "objectID": "02_03_AlgoritmiPractici.html#algoritmul-k-means",
    "href": "02_03_AlgoritmiPractici.html#algoritmul-k-means",
    "title": "6  Algoritmi practici",
    "section": "6.2 Algoritmul k-Means",
    "text": "6.2 Algoritmul k-Means\nk-Means este un algoritm pentru clusterizarea datelor.\nPrin clusterizare se înțelege operația de identificare a grupurilor de date apropiate între ele (clustere).\n\n6.2.1 Definiția algoritmului\nAlgoritmul k-Means funcționează astfel:\n\nIntrare:\n\nset de antrenare cu vectorii \\(\\vec{x}_1 ... \\vec{x}_N\\)\nnumărul de clase C\n\nInițializare: centroizii C iau valori aleatoare \\[\\vec{c}_i \\leftarrow \\textrm{ valori aleatoare }\\]\nRepetă\n\nClasificare: se clasifică fiecare vector \\(\\vec{x}\\) pe baza celui mai apropiat centroid: \\[class{x} = \\arg\\min_i d(\\vec{x}, \\vec{c}_i), \\forall \\vec{x}\\]\nActualizare: se actualizează centroizii \\(\\vec{c}_i\\) = media vectorilor \\(\\vec{x}\\) din clasa \\(i\\) \\[\\vec{c}_i \\leftarrow \\textrm{ media vectorilor } \\vec{x}, \\forall \\vec{x} \\textrm{ din clasa } i\\]\n\nIeșire: centroizii \\(\\vec{c}_i\\), clasele tuturor vectorilor de intrare \\(\\vec{x}_n\\)\n\nPentru explicații video pe Youtube:\n\nUrmăriți video-ul următor, de la 6:28 to 7:08\nhttps: //www.youtube.com/watch?v=4b5d3muPQmA\nUrmăriți video-ul următor, de la 3:05 la final\nhttps: //www.youtube.com/watch?v=IuRb3y8qKX4\n\n\n\n6.2.2 Discuții\nAlgoritmul k-Means este un exemplu de algoritm de învățare nesupervizată.\nÎnvățare nesupervizată = când nu se cunosc clasele semnalelor din setul de antrenare\nAlgoritmul k-Means poate să nu conveargă spre niște grupuri adecvate de date. Cu alte cuvinte, rezultate bune nu sunt garantate; rezultatele depind foarte mult de inițializarea aleatoare a centroizilor.\nO soluție frecventă, în practică, este să rulăm algoritmul de mai multe ori, pentru a alege apoi cel mai bun rezultat. De asemenea, există în literatură și unele metode de inițializare optimizate (k-Means++)\n\n\n\n\n\n\nExercițiu\n\n\n\n\nFie datele următoare: \\[\\left\\lbrace \\vec{v_n} \\right\\rbrace =\n[ 1.3, -0.1, 0.5, 4.7, 5.1, 5.8, 0.4, 4.8, -0.7, 4.9 ] \\]\nUtilizați algoritmul k-Means pentru a găsi doi centroizi \\(\\vec{c}_1\\) și \\(\\vec{c}_2\\), pornind de la valorile aleatoare \\(\\vec{c}_1 = -0.5\\) și \\(\\vec{c}_2 = 0.9\\). Realizați 5 iterații ale algoritmului."
  },
  {
    "objectID": "03_01_Estimare.html#ce-înseamnă-estimare",
    "href": "03_01_Estimare.html#ce-înseamnă-estimare",
    "title": "7  Elemente de teoria estimării",
    "section": "7.1 Ce înseamnă “estimare”?",
    "text": "7.1 Ce înseamnă “estimare”?\nVom considera următoarea problemă de bază.\nUn emițător transmite un semnal \\(s_\\Theta(t)\\), care depinde de parametru necunoscut \\(\\Theta\\) (de ex. amplitudinea e necunoscută). În afara acestui parametru, semnalul este cunoscut în totalitate.\nSemnalul acesta ajunge la receptor afectat de zgomotul \\(n(t)\\), astfel încât semnalul recepționat \\(r(t)\\) este: \\[r(t) = s_\\Theta(t) + n(t) \\]\nTeoria estimării se ocupă de problema estimării parametrului \\(\\Theta\\), cunoscând semnalul recepționat și parametrii statistici ai zgomotului.\nÎntrucât nu cunoaștem valorile exacte ale zgomotului \\(n(t)\\), nu putem găsi valoarea adevărată a parametrului necunoscut \\(\\Theta\\), tot ceea ce putem face este să o estimăm. Valoarea găsită în urma estimării va fi notată \\(\\hat{\\Theta}\\), și se numește estimatul lui \\(\\Theta\\)\nExistă întotdeauna o eroare de estimare \\(\\epsilon\\) între valoarea adevărată a lui \\(\\Theta\\) și estimatul său de la recepție: \\[\\epsilon = \\hat{\\Theta} - \\Theta\\]\nExemple:\n\nAmplitudinea unui semnal constant: \\(r(t) = A + zgomot\\), trebuie estimat \\(A\\)\nFaza unui semnal sinusoidal: \\(r(t) = \\cos(2 \\pi f t + \\phi) + zgomot\\), de estimat \\(\\phi\\)\nExemple mai complicate:\n\nDe estimat/decis ce cuvânt este pronunțat într-un semnal vocal\n\nFie următoarea problemă de estimare:\nSe recepționează un semnal \\(r(t) = A + zgomot\\), estimați-l pe \\(A\\)\nLa detecție: se alege între două valori cunoscute ale \\(A\\):\n\nde ex. \\(A\\) poate fi 0 sau 5 (ipotezele \\(H_0\\) și \\(H_1\\))\n\nLa estimare: \\(A\\) poate fi oricât => se alege între o infinitate de opțiuni ale \\(A\\)\n\n\\(A\\) poate fi orice valoare din \\(\\mathbb{R}\\), în general\n\n\nExistă o strânsă legătură între problemele de decizie și cele de estimare. Practic, prin “decizie” înțelegem o problemă de estimare restrânsă doar la un set discret, redus, de opțiuni; se alege doar una dintre cele câteva ipoteze. La rândul său, o problemă de estimare poate fi văzută ca o problemă de detecție, dar cu un număr infinit de opțiuni posibile. Metodele statistice folosite sunt foarte similare în ambele situații"
  },
  {
    "objectID": "03_01_Estimare.html#definirea-problemei",
    "href": "03_01_Estimare.html#definirea-problemei",
    "title": "7  Elemente de teoria estimării",
    "section": "7.2 Definirea problemei",
    "text": "7.2 Definirea problemei\nConsiderăm un semnal recepționat \\(r(t)\\), depinzând de parametrul cu valoare necunoscută \\(\\Theta\\), și afectat de zgomot aditiv:\n\\[r(t) = s_\\Theta(t) + zgomot\\]\nDin \\(r(t)\\) se iau N eșantioane, la momentele de timp \\(t_i\\),\n\\[r_i = r(t_i) = s_\\Theta(t_i) + n(t_i)\\]\nobținându-se vectorul de eșantioane:\n\\[\\vec{r} = [r_1, r_2, ... r_N]\\]\nFiecare eșantion \\(r_i = s_\\Theta(t_i) + n(t_i)\\) este o variabilă aleatoare, având aceeași distribuție ca eșantionul de zgomot \\(n_(t_i)\\), dar translată cu \\(s_\\Theta(t_i)\\). Distribuția eșantionului \\(r_i\\), care depinde așadar de \\(\\Theta\\), este notată:\n\\[w_i(r_i | \\Theta)\\]\nÎntregul vector de eșantioane \\(\\vec{r}\\) este o variabilă aleatoare N-dimensională ce depinde de \\(\\Theta\\), și are o distribuție N-dimensională \\(w(\\vec{r} | \\Theta)\\). Dacă zgomotul este alb, autnci eșantioane diferite de zgomot sunt independente, iar distribuția vectorului \\(\\vec{r}\\) devine egală cu produsul distribuțiilor fiecărui eșantion:\n\\[w(\\vec{r} | \\Theta) = w_1(r_1 | \\Theta) \\cdot w_2(r_2 | \\Theta) \\cdot ... \\cdot w_N(r_N | \\Theta)\\]"
  },
  {
    "objectID": "03_01_Estimare.html#estimarea-de-plauzibilitate-maximă-maximum-likelihood",
    "href": "03_01_Estimare.html#estimarea-de-plauzibilitate-maximă-maximum-likelihood",
    "title": "7  Elemente de teoria estimării",
    "section": "7.3 Estimarea de plauzibilitate maximă (Maximum Likelihood)",
    "text": "7.3 Estimarea de plauzibilitate maximă (Maximum Likelihood)\n\n7.3.1 Tipuri de estimare\nExistă două abordări ale problemelor de estimare:\n\nEstimare de plauzibilitate maximă (Maximum Likelihood Estimation, MLE): În afară de \\(\\vec{r}\\) nu se cunoaște nimic despre \\(\\Theta\\), decât cel mult vreun domeniu de existență (de ex. \\(\\Theta > 0\\))\nEstimarea ML este un caz particular al celei de-a doua abordări.\nEstimare Bayesiană: În afară de \\(\\vec{r}\\) se mai cunoaște o distribuție a priori \\(w(\\Theta)\\) a lui \\(\\Theta\\), care indică ce valori ale lui \\(\\Theta\\) sunt mai probabile sau mai puțin probabile.\n\n\n\n7.3.2 Estimarea tip Maximum Likelihood\nDacă nu se cunoaște vreo distribuție a priori se folosește metoda estimării de plauzibilitate maximă (“Maximum Likelihood”, ML)\nDat fiind vectorul de observații \\(\\vec{r}\\) cunoscut, se definește plauzibilitatea unui valori \\(\\Theta\\) astfel:\n\\[L(\\Theta | \\vec{r}) = w(\\Theta | \\vec{r})\\]\nFuncția \\(L(\\Theta | \\vec{r})\\) reprezintă funcția de plauzibilitate, care asociază pentru fiecare valoare posibilă \\(\\Theta\\) a parametrului căutat o anumită plauzibilitate. Conform ecuației, plauzibilitatea unei valori oarecare \\(\\Theta\\) reprezintă “probabilitatea” ca, dacă parametrul avea acea valoare, să se obțină vectorul $ care s-a obținut.\nComparând cu formula din Cap. 2, slide 20, se observă ce e aceeași definiție, cu diferența că aici estimăm pe \\(\\Theta\\), iar în acel caz “estimam” ipoteza corectă \\(H_i\\).\nEstimarea de plauzibilitate maximă (Maximum Likelihood, ML) constă în alege estimatul \\(\\hat{\\Theta}_{ML}\\) ca fiind valoarea care maximizează plauzibilitatea, dat fiind valorile observate \\(\\vec{r}\\), adică valoarea care maximizează \\(L(\\Theta | \\vec{r})\\):\n\\[\\hat{\\Theta}_{ML} = \\arg\\max_{\\Theta} L(\\Theta | \\vec{r}) = \\arg\\max_{\\Theta} w(\\vec{r} | \\Theta)\\]\nÎn general, se caută valoarea care maximizează funcția pe întreaga axă \\(\\mathbb{R}\\). Dacă se cunoaște că \\(\\Theta\\) aparține doar unui anumit interval, se poate face maximizarea doar pe acel interval.\nReamintim, in acest context, notațiile matematice generale\n\n\\(\\arg\\max_{x} f(x)\\) este “valoarea \\(x\\) are maximizează funcția f(x)”\n\\(\\max_{x} f(x)\\) = “valoarea maximă a funcției f(x)”\n\nSe observă faptul că estimarea ML este foarte similară cu decizia ML. Criteriul de decizie ML înseamnă, de fapt, alegerea ipotezei cu plauzibilitate mai mare: \\[\\frac{L(H_1 | r)}{L(H_0 | r)} = \\frac{w(r|H_1)}{w(r|H_0)} \\grtlessH 1\\] Același lucru este valabil și la estimare, cu diferența că nu se alege între două alternative, ci se alege valoarea reală din întregul \\(\\mathbb{R}\\) care maximizează plauzibilitatea: \\[\\hat{\\Theta}_{ML} = \\arg\\max_{\\Theta } L(\\Theta | \\vec{r}) = \\arg\\max_{\\Theta} w(\\vec{r} | \\Theta)\\]\n\n\n7.3.3 Rezolvare matematică\nÎn continuare, ne punem problema cum se rezolvă problema de maximizare, adică cum se găsește estimatul \\(\\hat{\\Theta}_{ML}\\) care maximizează \\(L(\\Theta | vec{r})\\).\nCa la orice funcție continuă, maximul se găsește prin derivare și egalare cu 0: \\[\\frac{d L(\\Theta | \\vec{r})}{d\\Theta} = 0\\] În plus, se poate aplica logaritmul natural asupra funcției \\(L(\\Theta | \\vec{r})\\) înainte de derivare, astfel încât se derivează \\(\\ln{L(\\cdot)}\\) (funcția “log-likelihood”): \\[\\frac{d \\ln\\left(L(\\Theta | \\vec{r})\\right)}{d\\Theta} = 0\\] Acest lucru ajută la simplificarea expresiilor de tip exponențial, și nu schimbă valoarea în dreptul căreia se găsește maximul funcției.\nProcedura de găsire a estimatului ML este detaliată mai jos.\n\nSe găsește expresia funcției \\[L(\\Theta | \\vec{r}) = w(\\vec{r} | \\Theta)\\]\nSe pune condiția ca derivata lui \\(L(\\Theta | \\vec{r})\\) sau a lui \\(\\ln(\\left(L(\\Theta | \\vec{r})\\right)\\) să fie 0 \\[\\frac{d L(\\Theta)}{d\\Theta} = 0, \\text{ sau }\\frac{d \\ln\\left(L(\\Theta)\\right)}{d\\Theta} = 0\\]\nSe rezolvă ecuația, se găsește valoarea \\(\\hat{\\Theta}_{ML}\\)\nSe verifică că derivata a doua în punctul \\(\\hat{\\Theta}_{ML}\\) este negativă, pentru a verifica că este un punct de maxim (și nu de minim). Reamintim că derivata este nulă și pentru maxime și pentru minime. Uneori putem ignora această etapă, dacă se cunoaște faptul că funcția are doar un punct de extrem.\n\n\n\n\n\n\n\nExemplu: semnal constant în zgomot gaussian\n\n\n\nGăsiți estimatul Maximum Likelihood pentru un semnal de valoare constantă \\(s_\\Theta(t) = A\\) din 5 măsurători afectate de zgomot \\(r_i = A + zgomot\\), cu valori egale cu \\([5, 7, 8, 6.1, 5.3]\\). Zgomotul este AWGN \\(\\mathcal{N}(\\mu=0, \\sigma^2)\\).\nSoluție: la tablă\nEstimatul \\(\\hat{A}_{ML}\\) este chiar valoarea medie a eșantioanelor (deloc surprinzător).\nimport matplotlib.pyplot as plt, numpy as np, math;\nmu = 0;\nsigma = 1;\nr = np.array([5, 7, 8, 6.1, 5.3])\nplt.stem(r, basefmt=\" \", use_line_collection=True)\nplt.plot(np.mean(r) * np.ones(r.shape), color = 'red')\nplt.xlabel('Esantioane');\nplt.ylabel('Valori');\nplt.title('Estimarea unui semnal constant');\nplt.legend(('Estimatul', 'Esantioane'))\nplt.savefig('fig/03_NumericalSim_Constant.png', transparent=True, bbox_inches='tight', dpi=300)\nplt.close()\n\n\n\nO problemă de estimare poate fi înțeleasă ca o problemă de aproximare a unei curbe, găsind cea mai bună potrivire a lui \\(s_\\Theta(t)\\) prin datele \\(\\vec{r}\\). Elementele cheie se observă din exemplul grafic anterior:\n\navem un set de date \\(\\vec{r}\\), care reprezintă o serie de puncte măsurate\nse cunoaște forma semnalului, adică o dreaptă orizontală (\\(A\\) constant)\nprin estimare se aproximează în mod optim poziția dreaptei prin setul de date\n\n\n\n7.3.4 Estimarea ML în zgomot de tip AWGN\nFie semnalul original \\(s_\\Theta(t)\\), și zgomotul de tip AWGN \\(\\mathcal{N}(\\mu=0, \\sigma^2)\\).\nEșantioanele \\(r_i\\) sunt luate la momentele \\(t_i\\), și vor avea distribuție normală, cu media \\(\\mu = s_\\Theta(t_i)\\) și varianța \\(\\sigma^2\\).\nFuncția de plauzibilitate \\(L(\\Theta | \\vec{r})\\) a întregului vector \\(\\vec{r}\\) se poate descompune ca produsul plauzibilităților fiecărui eșantion \\(r_i\\) în parte: \\[\\begin{split}\nL(\\Theta | \\vec{r}) = w(\\vec{r} | \\Theta) =& \\prod_{i=1}^N \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{- \\frac{(r_i - s_\\Theta(t_i))^2}{2 \\sigma^2}} \\\\\n=&  \\left( \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\right)^N e^{- \\frac{\\sum(r_i - s_\\Theta(t_i))^2}{2 \\sigma^2}}\n\\end{split}\\]\nLogaritmul plauzibilității (“log-likelihood”) este: \\[\\begin{split}\n\\ln\\left(L(\\Theta | \\vec{r})\\right) =& \\underbrace{\\ln\\left(\\frac{1}{\\sigma \\sqrt{2 \\pi}}\\right)}_{constant} - \\frac{\\sum(r_i - s_\\Theta(t_i))^2}{2 \\sigma^2}\n\\end{split}\\]\nMaximul funcției se atinge atunci când exponentul este minim: \\[\\hat{\\Theta}_{ML} = \\arg\\max_{\\Theta} L(\\Theta | \\vec{r}) = \\arg\\min \\sum(r_i - s_\\Theta(t_i))^2\\]\nSe observă că termenul \\(\\sum(r_i - s_\\Theta(t_i))^2\\) reprezintă chiar distanța Euclideană ridicată la pătrat dintre vectorii cu valorile \\(\\r_i\\) și \\(s_\\Theta(t_i)\\): \\[d(\\vec{r},s_\\Theta) = \\sqrt{\\sum (r_i - s_\\Theta(t_i))^2}\\] \\[\\left(d(\\vec{r},s_\\Theta)\\right)^2 = \\sum (r_i - s_\\Theta(t_i))^2\\]\nAșadar, estimarea ML în cazul zgomotului AWGN se poate rescrie sub forma: \\[\\hat{\\Theta}_{ML} = \\arg\\max_{\\Theta} L(\\Theta | \\vec{r}) = \\arg\\min_\\Theta d(\\vec{r}, \\vec{s}_\\Theta)^2\\]\nEstimatul de plauzibilitate maximă (ML) \\(\\hat{\\Theta}_{ML}\\) este acea valoare care face \\(s_\\Theta(t_i)\\) cel mai apropiat de vectorul recepționat \\(\\vec{r}\\). Ca interpretare, o distanță mică înseamnă o potrivire mai bună, deci o plauzibilitate mai bună.\nSubliniem că aceeași interpretare bazată pe distanța minimă era valabilă și pentru decizia ML, cu diferența că la decizie se alege minimul dintre două opțiuni, în timp ce aici alegem minimul dintre toate opțiunile posibile.\nRelația care definește estimarea ML pentru zgomot AWGN este valabilă pentru orice fel de spații vectoriale (vectori cu N elemente, semnale continue etc). În funcție de natura semnalelor se modifică doar definiția distanței Euclidiene, nu și regula de estimare.\nSumarizând, procedura pentru estimarea tip ML în zgomot AWGN este următoarea.\n\nSe scrie expresia pentru pătratul distanței: \\[D = \\left(d(\\vec{r},s_\\Theta)\\right)^2 = \\sum (r_i - s_\\Theta(t_i))^2\\]\nSe caută minimul expresiei, deci egalăm derivata cu 0: \\[\\frac{d D}{d\\Theta} = \\sum 2 (r_i - s_\\Theta(t_i)) (- \\frac{d s_\\Theta(t_i)}{d\\Theta}) = 0\\]\nSe rezolvă și obținem valoarea \\(\\hat{\\Theta}_{ML}\\)\nSe verifică că derivata a doua în punctul \\(\\hat{\\Theta}_{ML}\\) este pozitivă, pentru a se verifica că punctul este un minim. Uneori se poate sări peste această etapă, dacă se cunoaște ca funcția are un singur punct de extrem.\n\n\n\n\n\n\n\nExemplu: estimarea frecvenței a unui semnal sinusoidal\n\n\n\nGăsiți estimatul Maximum Likelihood pentru frecvența \\(f\\) a unui semnal \\(s_\\Theta(t) = cos(2\\pi f t_i)\\), din 10 măsurători afectate de zgomot \\(r_i = cos(2\\pi f t_i) + zgomot\\) de valori \\([...]\\). Zgomotul este AWGN \\(\\mathcal{N}(\\mu=0, \\sigma^2)\\). Momentele de eșantionare sunt \\(t_i = [0,1,2,3,4,5,6,7,8,9]\\)\n\nSoluție: la tablă\n\nFuncția de plauzibilitate este reprezentată mai jos.\nimport matplotlib.pyplot as plt, numpy as np, math;\nnp.random.seed(102)\nmu = 0;\nsigma = 0.2;\nftrue = 0.07;\nn = np.arange(0,20)\nr = np.cos(2 * math.pi * ftrue * n) + sigma*np.random.randn(20)\n\n# Log-likelihood function\nfvalues = np.linspace(0.04, 0.1, 100);\nL = np.zeros((1,500))\nL = [np.log(1./(sigma*math.sqrt(2*math.pi))) - (sum(r - np.cos(2 * math.pi * fvalue * n))**2)/2*sigma*sigma for fvalue in fvalues]\nfhat = np.amax(L)\nplt.plot(fvalues,L)\nplt.savefig('fig/03_NumericalSim_CosineFreq_LogLik.png', transparent=True, bbox_inches='tight', dpi=300)\nplt.close()\n\nimport matplotlib.pyplot as plt, numpy as np, math;\nnp.random.seed(102)\nmu = 0;\nsigma = 0.2;\nftrue = 0.07;\nn = np.arange(0,20)\nr = np.cos(2 * math.pi * ftrue * n) + sigma*np.random.randn(20)\n\n# Log-likelihood function\nfvalues = np.linspace(0.04, 1/10, 100);\nL = np.zeros((1,500))\nL = [np.log(1./(sigma*math.sqrt(2*math.pi))) - (sum(r - np.cos(2 * math.pi * fvalue * n))**2)/2*sigma*sigma for fvalue in fvalues]\nimax = np.argmax(L)\nfhat = fvalues[imax]\nplt.stem(n,r, basefmt=\"b\", use_line_collection=True)\nntoplot = np.linspace(0,20,200)\nplt.plot(ntoplot, np.cos(2 * math.pi * fhat * ntoplot), color='red')\nplt.legend(('Cosinusul estimat','Esantioane'))\nprint('Frecventa originala = %f, estimatul = %f'%(ftrue, fhat))\nplt.savefig('fig/03_NumericalSim_CosineFreq.png', transparent=True, bbox_inches='tight', dpi=300)\nplt.close()\n\n\n\n\n\n7.3.5 Parametri multipli\nCe se întâmplă dacă semnalul depinde de mai mulți parametri, nu doar de unul? De exemplu amplitudinea, frecvența și faza inițială ale unui semnal de tip cosinus: \\[s_\\vec{\\Theta}(t) = A \\cos(2 \\pi f t + \\phi)\\]\nÎn acest caz, se va considera \\(\\Theta\\) ca fiind un vector care cuprinde toți parametrii necunoscuți: \\[\\bm{\\Theta} = [\\Theta_1, \\Theta_2, ... \\Theta_M]\\] De exemplu, \\(\\bm{\\Theta} = [\\Theta_1, \\Theta_2, \\Theta_3] =[A, f, \\phi]\\).\nEstimarea se poate face cu aceeași procedură, dar în loc de o singură derivată vom avea \\(M\\) derivate, adică se rezolvă sistemul: \\[\\begin{cases}\n\\frac{\\partial L}{\\partial \\Theta_1} = 0 \\\\\n\\frac{\\partial L}{\\partial \\Theta_2} = 0 \\\\\n\\dots \\\\\n\\frac{\\partial L}{\\partial \\Theta_M} = 0 \\\\\n\\end{cases}\\]\nÎn cazuri complicate din aplicații reale, unde pot fi foarte mulți parametri, rezolvarea unui astfel de sistem este dificilă, dacă nu chiar imposibilă. În aceste situații, unde nu se pot găsi valorile optime prin formule directe, se pot folosi algoritmi iterativi tip coborâre după gradient (Gradient Descent) care îmbunătățesc valorile în mod progresiv.\nPașii fundamentali ai algoritmilor de tip coborâre după gradient (Gradient Descent) sunt următorii.\n\nSe inițializează parametrii cu valori aleatoare \\(\\bm{\\Theta}^{(0)}\\)\nRepetă la fiecare iterație \\(k\\):\n\nSe calculează funcția \\(L(\\bm{\\Theta}^{(k)} | \\vec{r})\\)\nSe calculează derivatele \\(\\frac{\\partial L}{\\partial \\Theta_i^{(k)}}\\) pentru toți \\(\\Theta_i\\) (“Gradient”)\nSe actualizează toate valorile \\(\\Theta_i\\) prin scăderea derivatei (“Descent”): \\[\\Theta_i^{(k+1)} = \\Theta_i^{(k)} - \\mu \\frac{\\partial L}{\\partial \\Theta_i^{(k)}}\\]\n\nsau, sub formă vectorială: \\[\\bm{\\Theta}^{(k+1)} = \\bm{\\Theta}^{k} - \\mu \\frac{\\partial L}{\\partial \\bm{\\Theta}^{(k)}}\\]\n\n\nPână la îndeplinirea unui criteriu de terminare (de ex. parametrii nu se mai modifică mult)\n\nCel mai proeminent exemplu de utilizare a acestor algoritmi este cel al Rețele Neurale Artificiale (a.k.a. “Rețele Neurale”, “Deep Learning”, etc.) care reprezintă motorul tehnicilor moderne de inteligență artificială."
  },
  {
    "objectID": "03_01_Estimare.html#deplasarea-și-varianța-estimatorilor",
    "href": "03_01_Estimare.html#deplasarea-și-varianța-estimatorilor",
    "title": "7  Elemente de teoria estimării",
    "section": "7.4 Deplasarea și varianța estimatorilor",
    "text": "7.4 Deplasarea și varianța estimatorilor\nCum caracterizăm calitatea unui estimator?\nUn estimator \\(\\hat{\\Theta}\\) este o variabilă aleatoare, în sensul că poate avea diverse valori, întrucât se calculează pe baza eșantioanelor recepționate, care depind de zgomot. Practic, dacă se repetă aceeași estimare pornind de la eșantioane diferite, vor rezulta mereu valori estimate ușor diferite.\nFiind o variabilă aleatoare, se pot defini următoarele mărimi:\n\nvaloarea medie a estimatorului: \\(E \\left\\{ \\hat{\\Theta} \\right\\}\\)\nvarianța estimatorului: \\(E \\left\\{ (\\hat{\\Theta} - \\Theta)^2 \\right\\}\\)\n\nDeplasarea (“bias”) unui estimator se definește ca diferența dintre valoarea medie a estimatorului și valoarea adevărată \\(\\Theta\\): \\[Deplasare = E \\left\\{ \\hat{\\Theta} \\right\\} - \\Theta\\]\nUn estimator este nedeplasat atunci când valoarea medie a estimatorului este egală cu valoarea adevărată a parametrului \\(\\Theta\\): \\[E \\left\\{ \\hat{\\Theta} \\right\\} = \\Theta\\]\nUn estimator este deplasat atunci când valoarea medie a estimatorului diferă de valoarea adevărată a parametrului \\(\\Theta\\). Diferența \\(E \\left\\{ \\hat{\\Theta} \\right\\} - \\Theta\\) reprezintă deplasarea estimatorului.\n::: {.callout-tip icon=false title=“Exemplu”} ### Exemplu\nExemplu: pentru un semnal constant \\(s_\\Theta(t) = A\\), afectat de zgomot Gaussian cu media 0, estimatorul de plauzibilitate maximă este \\[\\hat{A}_{ML} = \\frac{1}{N}\\sum_i r_i\\].\nPentru a vedea dacă acesta este deplasat sau nu, calculăm media estimatorului: \\[\\begin{split}\nE \\left\\{ \\hat{A}_{ML} \\right\\} =& \\frac{1}{N}E \\left\\{ \\sum_i r_i \\right\\} \\\\\n=& \\frac{1}{N} \\sum_{i=1}^N E \\left\\{ r_i \\right\\} \\\\\n=& \\frac{1}{N} \\sum_{i=1}^N E \\left\\{ A + zgomot \\right\\} \\\\\n=& \\frac{1}{N} \\sum_{i=1}^N A \\\\\n=& A\n\\end{split}\\]\nAșadar, acest estimator este nedeplasat, întrucât valoarea medie a estimatorului \\(\\hat{A}_{ML}\\) este egală chiar cu valoarea reală a parametrului \\(A\\).\nVarianța unui estimator măsoară “abaterile” estimatorului în jurul valorii medii (ca la orice variabolă aleatoare, de altfel).\nDacă un estimator are varianța mare, valoarea estimată poate fi departe de cea reală, chiar daca estimatorul este nedeplasat.\nDe obicei se preferă estimatori cu varianță mică, tolerându-se o eventuală mică deplasare.\nO ilustrare a deplasării și a varianței estimatorilor este în figura de mai jos.\n\n\n\nDeplasarea și varianța estimatorilor"
  },
  {
    "objectID": "03_01_Estimare.html#estimare-bayesiană",
    "href": "03_01_Estimare.html#estimare-bayesiană",
    "title": "7  Elemente de teoria estimării",
    "section": "7.5 Estimare Bayesiană",
    "text": "7.5 Estimare Bayesiană\n\n7.5.1 Distribuția a posteriori\nEstimarea Bayesiană reprezintă echivalentul din estimare pentru criteriile de decizie MPE și MR. În acest sens, se iau în calcul doi termeni suplimentari pe lângă \\(w(\\vec{r} | \\Theta\\):\n\no distribuție a priori \\(w(\\Theta)\\)\nopțional, o funcție de cost\n\nElementul cheie în estimarea Bayesiană îl reprezintă distribuția a posteriori a lui \\(\\Theta\\), date fiind observațiile \\(\\vec{r}\\). Aceasta se scrie folosind regula lui Bayes, în felul următor:\n\\[w(\\Theta | \\vec{r}) = \\frac{w(\\vec{r} | \\Theta) \\cdot w(\\Theta)}{w(\\vec{r})}\\]\nDistribuția a posteriori \\(w(\\Theta | \\vec{r})\\) este o densitate de probabilitate care descrie probabilitatea ca parametrul nostru necunoscut să aibă, în realitate, o valoare \\(\\Theta\\).\nSemnificația termenilor din această definiție este următoarea:\n\n\\(\\Theta\\) este parametrul necunoscut;\n\\(\\vec{r}\\) este vectorul de observații care e luat în calcul în estimare;\n\\(w(\\Theta | \\vec{r})\\) este distribuția a posteriori, adică densitatea de probabilitate ca parametrul să aibă valoarea \\(\\Theta\\)\n\\(w(\\vec{r} | \\Theta)\\) este funcția de plauzibilitate\n\\(w(\\Theta)\\) este distribuția a priori a lui \\(\\Theta\\), care reflectă informația avută în prealabil cu privire la probabilitatea ca parametrul să ia o valoarea sau alta;\n\\(w(\\vec{r})\\) este distribuția a priori a lui \\(\\vec{r}\\). Aceasta de consideră de obicei a fi constantă, și are rolul doar de a normaliza funcția astfel încât integrala totală din \\(w(\\Theta | \\vec{r})\\) să fie egală 1, ca la orice densitate de probabilitate.\n\nDefiniția de mai sus arată că, în general, estimarea lui \\(\\Theta\\) depinde atât de observațiile \\(\\vec{r}\\), prin termenul \\(w(\\vec{r} | \\Theta)\\), cât și de informația “a priori” avută de la bun început despre \\(\\Theta\\), prin termenul \\(w(\\Theta)\\). Distribuția a priori reflectă, așadar, ceea ce știm de dinainte referitor la probabilitatea ca parametrul căutat să fie o valoare sau alte. Ea “trage” valoarea estimată înspre valori mai probabile.\nTermenii a priori și a posteriori se raportează la momentul obținerii observațiilor \\(\\vec{r}\\)\n\ndistribuția a priori \\(w(\\Theta)\\) este probabilitatea ca o valoare oarecare \\(\\Theta\\) să fie cea corectă, înaintea obținerii observațiilor, deci fără a le lua în considerare;\ndistribuția a posteriori \\(w(\\Theta | \\vec{r})\\) este probabilitatea ca o valoare oarecare \\(\\Theta\\) să fie cea corectă, după obținerea observațiilor, deci luându-le în calcul și pe acestea.\n\n\n\n7.5.2 Estimatorul MAP\nDistribuția a posteriori \\(w(\\Theta | \\vec{r})\\) ne dă probabilitatea fiecărei valori reale de a fi valoarea corectă a parametrului nostru. Așadar, dacă trebuie să alegem o singură valoare, care este exact valoarea estimată?\nEstimatorul Maximum A Posteriori (MAP) definește valoarea estimată ca fiind valoarea \\(\\Theta\\) în care distribuția a posteriori \\(w(\\Theta | \\vec{r})\\) este maximă: \\[\\hat{\\Theta}_{MAP} = \\arg\\max_\\Theta w(\\Theta | \\vec{r}) = \\arg\\max_\\Theta w(\\vec{r} | \\Theta) \\cdot w(\\Theta)\\]\nCa interpretare, putem înțelege acest lucru ca fiind alegerea valorii care are probabilitate (plauzibilitate, mai corect spus) maximă, dar, spre deosebire de estimarea ML, ne raportăm la distribuția a posteriori, care ia în calcul pe lângă observații și distribuția a priori.\nPractic, estimatorul MAP maximizează produsul dintre plauzibilitate \\(w(\\vec{r} | \\Theta)\\) și distribuția a priori \\(w(\\Theta)\\).\nExemplu: Imagine\nRelație dintre estimarea ML și estimarea MAP se observă din alăturarea celor două expresii:\n\nEstimatorul ML: \\[\\arg\\max w(\\vec{r} | \\Theta)\\]\nEstimatorul MAP: \\[\\arg\\max w(\\vec{r} | \\Theta) \\cdot w(\\Theta)\\]\nEstimatorul ML este un caz particular de MAP pentru cazul în care \\(w(\\Theta)\\) e constant, adicî atunci cand toate valorile lui \\(\\Theta\\) sunt a priori echiprobabile. Cu alte cuvinte, nu avem extra informații despre valoarea lui \\(\\Theta\\) în afara observațiilor propriu-zise.\n\nRelația cu detecția semnalelor se observă din alăturarea cu criteriul de decizie MPE.\n\nCriteriul de decizie MPE alege ipoteza pentru care \\(w(r | H_i)\\cdot P(H_i)\\) este mai mare: \\[w(r | H_1)\\cdot P(H_1) \\grtlessH w(r | H_0) P(H_0)\\]\nEstimarea MAP: se alege valoarea care maximizează \\(w(\\vec{r} | \\Theta) \\cdot w(\\Theta)\\)\nEste același principiu, dar la decizie există doar două alternative, iar la estimare se alege o valoarea reală.\n\n\n\n7.5.3 Funcții de cost\nPentru a găsi un echivalent și pentru criteriul MR, vom introduce conceptul de funcție de cost, care generalizează costurile \\(C_{ij}\\) de la decizii.\nEroarea de estimare reprezintă diferența între estimatul \\(\\hat{\\Theta}\\) și valoarea reală \\(\\Theta\\) \\[\\epsilon = \\hat{\\Theta} - \\Theta\\]\nFuncția de cost \\(C(\\epsilon)\\) este o funcție care atribuie un anume cost fiecărei erori de estimare posibilă:\n\ncând \\(\\epsilon = 0\\), costul \\(C(0) = 0\\), întrucât nu există deloc o eroare de estimare\npentru erori de estimare \\(\\epsilon\\) mici, valorile funcției de cost sunt mici\npentru erori de estimare \\(\\epsilon\\) mari, funcția de cost are în general valori mari\n\nÎn general, funcția de cost poate fi aleasă oricum. În practică, se folosesc o serie de funcții de cost uzuale:\n\nFuncția de cost pătratică: \\[C(\\epsilon) = \\epsilon^2 = \\left( \\hat{\\Theta} - \\Theta \\right)^2\\]\nFuncția de cost uniformă: \\[C(\\epsilon) = \\begin{cases}\n0, \\text{ if } |\\epsilon| = |\\hat{\\Theta} - \\Theta | \\leq E \\\\\n1, \\text{ if } |\\epsilon| = |\\hat{\\Theta} - \\Theta | > E \\\\\n\\end{cases}\\]\nFuncția de cost liniară: \\[C(\\epsilon) = |\\epsilon| = | \\hat{\\Theta} - \\Theta |\\]\n\nFuncția de cost \\(C(\\epsilon)\\) reprezintă echivalentul costurilor \\(C_{ij}\\) de la detecție. Dacă la detecție aveam doar 4 valori posibile (\\(C_{00}\\), \\(C_{01}\\), \\(C_{10}\\), \\(C_{11}\\)) întrucât existau doar 4 scenarii posibile, în cazul estimării avem un cost pentru fiecare eroare posibilă \\(\\epsilon\\).\nImportanța funcției de cost rezidă în faptul că ea dictează, de fapt, ce valoare anume alegem din distribuția \\(w(\\Theta | \\vec{r})\\).\n\n\n\n\n\n\nExemplu: funcției de cost asimetrică\n\n\n\nDe exemplu, fie distribuția a posteriori următoare:\n\n\n\nAsymmetrical posterior distribution\n\n\n\nCare este estimatorul MAP?\nDar dacă avem funcția de cost următoare:\n\ndacă estimarea \\(\\hat{\\Theta}\\) este < valoarea reală \\(\\Theta\\), te costă 1000 $\ndacă estimarea \\(\\hat{\\Theta}\\) este > valoarea reală \\(\\Theta\\), platești 1 $\nschimbăm valoarea estimată ? :)\n\n\n\n\n\n\n7.5.4 Estimatorul EPMM\nDistribuția a posteriori \\(w(\\Theta | \\vec{r})\\) dă probabilitatea fiecărei valori \\(\\hat{\\Theta}\\) de a fi cea corectă, dar alegerea unei anume valori estimate \\(\\hat{\\Theta}\\) implică o anume eroare \\(\\epsilon\\) care are un anumit cost \\(C(\\epsilon)\\)\nRiscul se definește ca valoarea medie a costului \\(C(\\epsilon\\)): \\[R = \\int_{-\\infty}^\\infty C(\\epsilon) w(\\Theta | \\vec{r}) d\\Theta\\] Relația de mai sus este relația care definește orice valoare medie (suma dintra valorile individuale înmulțite cu probabilitatea lor). Aici mediem valorile costului \\(C(\\epsilon)\\), iar probabilitatea fiecărui cost este de fapt probabilitatea valorilor \\(\\Theta\\) care conduc la un anume \\(\\epsilon\\) și astfel la fiecare valoare de cost, așadar \\(w(\\Theta | \\vec{r})\\).\nÎn estimarea Bayesiană, valoarea estimată \\(\\hat{\\Theta}\\) se alege ca fiind valoarea \\(\\hat{\\Theta}\\) care minimizează costul mediu \\(R\\): \\[\\hat{\\Theta} = \\arg\\min_\\Theta \\int_{-\\infty}^\\infty C(\\epsilon) w(\\Theta | \\vec{r}) d\\Theta\\]\nÎn această relație se înlocuiește \\(C(\\epsilon)\\) cu funcția de cost dorită. Pentru a găsi valoarea minimă se derivează după \\(\\hat{\\Theta}\\):\n(Atenție: se derivează după \\(\\hat{\\Theta}\\), nu \\(\\Theta\\), întrucât \\(\\hat{\\Theta}\\) este valoarea pe care o căutam!.\nPentru funcția de cost pătratică, \\(C(\\epsilon) = \\epsilon^2 = \\left( \\hat{\\Theta} - \\Theta \\right)^2\\), avem: \\[R = \\int_{-\\infty}^\\infty (\\hat{\\Theta} - \\Theta)^2 w(\\Theta | \\vec{r}) d\\Theta\\] Se caută \\(\\hat{\\Theta}\\) care minimizează \\(R\\), deci derivăm: \\[\\frac{dR}{d\\hat{\\Theta}} = 2 \\int_{-\\infty}^\\infty (\\hat{\\Theta} - \\Theta) w(\\Theta | \\vec{r}) d\\Theta = 0\\] Echivalent cu \\[\\hat{\\Theta} \\underbrace{\\int_{-\\infty}^\\infty w(\\Theta | \\vec{r})}_1 d\\Theta = \\int_{-\\infty}^\\infty \\Theta w(\\Theta | \\vec{r}) d\\Theta\\]\nSe ajunge în acest fel la relația care definește estimatorul de eroare pătratică medie minimă (EPMM) (“Minimum Mean Squared Error, MMSE”): \\[\\hat{\\Theta}_{EPMM} = \\int_{-\\infty}^\\infty \\Theta \\cdot w(\\Theta | \\vec{r}) d\\Theta\\]\nEstimatorul EPMM: estimatorul \\(\\hat{\\Theta}\\) este valoarea medie a distribuției a posteriori \\(w(\\Theta | \\vec{r})\\) \\[\\hat{\\Theta}_{EPMM} = \\int_{-\\infty}^\\infty \\Theta \\cdot w(\\Theta | \\vec{r}) d\\Theta\\]\n\nEPMM = “Eroare Pătratică Medie Minimă”\nvaloarea medie = sumă (integrală) din fiecare \\(\\Theta\\) ori probabilitatea sa \\(w(\\Theta | \\vec{r})\\)\n\nEstimatprul EPMM se obține din distribuția a posteriori \\(w(\\Theta | \\vec{r})\\), considerând funcția de cost pătratică\n\n\n7.5.5 Estimatorul MAP\n\nDacă funcția de cost este uniformă \\[C(\\epsilon) = \\begin{cases}\n  0, \\text{ if } |\\epsilon| = |\\hat{\\Theta} - \\Theta | \\leq E \\\\\n  1, \\text{ if } |\\epsilon| = |\\hat{\\Theta} - \\Theta | > E \\\\\n  \\end{cases}\\]\nȘtim că \\(\\Theta = \\hat{\\Theta} - \\epsilon\\)\nSe obține \\[\\begin{split}\n  R =& \\int_{-\\infty}^{\\hat{\\Theta}-E} w(\\Theta | \\vec{r}) d\\Theta + \\int_{\\hat{\\Theta} + E}^\\infty w(\\Theta | \\vec{r}) d\\Theta \\\\\n  R =& 1 - \\int_{\\hat{\\Theta}-E}^{\\hat{\\Theta}+E} w(\\Theta | \\vec{r}) d\\Theta\n  \\end{split}\\]\n\n\n\n7.5.6 Estimatorul MAP\n\nPentru minimizarea \\(R\\), trebuie să maximizăm \\(\\int_{\\hat{\\Theta}-E}^{\\hat{\\Theta}+E} w(\\Theta | \\vec{r}) d\\Theta\\), integrala din jurul punctului \\(\\hat{\\Theta}\\)\nPentru \\(E\\) foarte mic, funcția \\(w(\\Theta | \\vec{r})\\) este aproximativ constantă, deci se va alege punctul unde funcția este maximă\nEstimatorul Maximum A Posteriori (MAP) = valoarea \\(\\hat{\\Theta}\\) care maximizează \\(w(\\Theta | \\vec{r})\\) \\[\\hat{\\Theta}_{MAP} = \\arg\\max_\\Theta w(\\Theta | \\vec{r}) = \\arg\\max\\Theta w(\\vec{r} | \\Theta) \\cdot w(\\Theta)\\]\n\n\n\n7.5.7 Interpretare\n\nEstimatorul MAP: \\(\\hat{\\Theta}\\) = valoarea care maximizează distribuția a posteriori\nEstimatorul EPMM: \\(\\hat{\\Theta}\\) = valoarea medie a distribuției a posteriori\n\n\n\n\nEstimatorul MAP vs EPMM(MMSE)\n\n\n[image from https://allenlu2007.wordpress.com]\n\n\n7.5.8 Relația între estim. MAP and EPMM\n\nEstimatorul MAP = minimizează costul mediu, folosind funcția de cost uniformă\n\nca le detecție: criteriul MPE = criteriul MR când costurile sunt la fel\n\nEstimatorul EPMM = minimizează costul mediu, folosind funcția de cost pătratică\n\nsimilar cu criteriul MR, dar la estimare\n\n\n\n\n7.5.9 Exercițiu\nExercițiu: valoare constantă, 1 măsurătoare, zgomot Gaussian același \\(\\sigma\\)\n\nVrem să estimam temperatura de astăzi din Sahara\nTermometrul indică 40 grade, dar valoarea este afectată de zgomot Gaussian \\(\\mathcal{N}(0, \\sigma^2=2)\\) (termometru ieftin)\nSe știe că de obicei în această perioadă a anului temperatura este în jur de 35 grade, cu o distribuție Gaussiană \\(\\mathcal{N}(35, \\sigma^2 = 2)\\).\nEstimați valoarea reală a temperaturii folosind estimarea ML, MAP și EPMM(MMSE)\n\n\n\n7.5.10 Exercițiu\nExercițiu: valoare constantă, 1 măsurătoare, zgomot Gaussian același \\(\\sigma\\)\n\nDacă avem trei termometre, care indică 40, 38, 41 grade?\n\nExercițiu: valoare constantă, 1 măsurătoare, zgomot Gaussian \\(\\sigma\\) diferit\n\nDacă temperatura în această perioadă a anului are distribuție Gaussiană \\(\\mathcal{N}(35, \\sigma_2^2 = 3)\\)\n\ncu varianță diferită, \\(\\sigma_2 \\neq \\sigma\\)\n\n\n\n\n7.5.11 Semnal oarecare în zgomot Gaussian (AWGN)\n\nFie semnalul original “curat” \\(s_\\Theta(t)\\)\nZgomotul este Gaussian (AWGN) \\(\\mathcal{N}(\\mu=0, \\sigma^2)\\)\nCa în cazul estimării de plauzibilitate maximă, funcția de plauzibilitate este: \\[\\begin{split}\nw(\\vec{r} | \\Theta) =&  \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{- \\frac{\\sum(r_i - s_\\Theta(t_i))^2}{2 \\sigma^2}}\n\\end{split}\\]\nDar acum aceasta se înmulțește cu \\(w(\\Theta)\\) \\[w(\\vec{r} | \\Theta) \\cdot w(\\Theta)\\]\n\n\n\n7.5.12 Semnal oarecare în zgomot Gaussian (AWGN)\n\nEstimatorul MAP estimator este cel care maximizează produsul \\[\\hat{\\Theta}_{MAP} = \\arg\\max w(\\vec{r} | \\Theta) w(\\Theta)\\]\nLogaritmând: \\[\\begin{split}\n\\hat{\\Theta}_{MAP} =& \\arg\\max \\ln \\left( w(\\vec{r} | \\Theta) \\right) + \\ln \\left( w(\\Theta) \\right) \\\\\n=& \\arg\\max - \\frac{\\sum(r_i - s_\\Theta(t_i))^2}{2 \\sigma^2} + \\ln \\left(w(\\Theta)\\right)\n\\end{split}\\]\n\n\n\n7.5.13 Distribuție “a priori” Gaussiană\n\nDacă distribuția “a priori” este de asemenea Gaussiană \\(\\mathcal{N}(\\mu_\\Theta, \\sigma_\\Theta^2)\\) \\[ \\ln \\left(w(\\Theta)\\right) = - \\frac{\\sum(\\Theta - \\mu_\\Theta)^2}{2 \\sigma_\\Theta^2}\\]\nEstimatorul MAP devine \\[ \\hat{\\Theta}_{MAP} = \\arg\\min \\frac{\\sum(r_i - s_\\Theta(t_i))^2}{2 \\sigma^2} + \\frac{\\sum(\\Theta - \\mu_\\Theta)^2}{2 \\sigma_\\Theta^2}\\]\nPoate fi rescris \\[ \\hat{\\Theta}_{MAP} = \\arg\\min d(\\vec{r},s_\\Theta)^2 + \\underbrace{\\frac{\\sigma^2}{\\sigma_\\Theta^2}}_\\lambda \\cdot d(\\Theta, \\mu_\\Theta)^2\\]\n\n\n\n7.5.14 Interpretare\n\nEstimatorul MAP în zgomot Gaussian și cu distribuție “a priori” Gaussiană \\[\\hat{\\Theta}_{MAP} = \\arg\\min d(\\vec{r},s_\\Theta)^2 + \\underbrace{\\frac{\\sigma^2}{\\sigma_\\Theta^2}}_\\lambda \\cdot d(\\Theta, \\mu_\\Theta)^2\\]\n\\(\\hat{\\Theta}_{MAP}\\) este apropiat de valoarea medie \\(\\mu_\\Theta\\) și de asemenea face ca semnalul adevărat să fie apropiat de eșantioanele recepționate \\(\\vec{r}\\)\n\nExemplu: “caut locuință aproape de serviciu dar și aproape de Mall”\n\\(\\lambda\\) controlează importanța relativă a celor doi termeni\n\nCazuri particulare\n\n\\(\\sigma_\\Theta\\) foarte mic = distribuția “a priori” este foarte specifică (îngustă) = \\(\\lambda\\) mare = termenul al doilea este dominant = \\(\\hat{\\Theta}_{MAP}\\) foarte apropiat de \\(\\mu_\\Theta\\)\n\\(\\sigma_\\Theta\\) foarte mare = distribuția “a priori” este foarte nespecifică = \\(\\lambda\\) mic = primul termen este dominant = \\(\\hat{\\Theta}_{MAP}\\) apropiat de estimatorul de plauzibilitate maximă\n\n\n\n\n7.5.15 Aplicații\n\nÎn general, aplicațiile practice:\n\nutilizează diverse tipuri de distribuții “a priori”\nestimează mai mulți parametri (un vector de parametri)\n\nAplicații\n\nreducerea zgomotului din semnale\nrestaurarea semnalelor (parți lipsă din imagini, imagini blurate etc)\ncompresia semnalelor\n\n\n\n\n7.5.16 Aplicații practice\n\nUrmărirea unui obiect (“single object tracking”) prin filtrare Kalman\n\n\nurmărirea unui obiect prin măsurători succesive (e.g. din imagini succesive)\nla fiecare nouă măsurătoare avem două distribuții ale poziției:\n\ncea dată de măsurătoare respectivă, \\(w(r | \\Theta)\\)\ncea prezisă pe baza poziției și vitezei de data trecută\nambele presupuse a fi Gaussiene, caracterizate doar prin medie și varianță\n\ncele două se combină prin regula lui Bayes => o distribuție mai precisă \\(w(\\Theta | r)\\), tot Gaussiană\npoziția exactă se estimează prin EPMM (media lui \\(w(\\Theta | r)\\)\n\\(w(\\Theta | r)\\) prezice poziția de la momentul următor\n\n\n\n7.5.17 Single object tracking\n\n\n7.5.18 Single object tracking\n\n\n7.5.19 Aplicații practice\n\nConstrained Least Squares (CLS) image restoration\n\n\nAvem o imagine \\(I\\) afectată de erori (zgomot, pixeli lipsă, blurare) \\[I_{zg} = I_{true} + Z\\]\nEstimăm imaginea originală prin: \\[\\hat{I_{true}} = argmin_{I} \\|I - I_{zg}\\|_2 + \\lambda \\cdot \\|HighPass\\lbrace I \\rbrace\\|_2\\]\nExemple:\n\nhttps://www.mathworks.com/help/images/deblurring-images-using-a-regularized-filter.html\nhttps://demonstrations.wolfram.com/ImageRestorationForDegradedImages\nGoogle it\n\n\n\n\n7.5.20 Constrained Least Squares (CLS) image restoration"
  },
  {
    "objectID": "Ex_Seminar01.html#exercițiul-1",
    "href": "Ex_Seminar01.html#exercițiul-1",
    "title": "8  Seminar 01: Variabile aleatoare și probabilități",
    "section": "8.1 Exercițiul 1",
    "text": "8.1 Exercițiul 1\nFie A o variabilă aleatoare continuă cu distribuția \\(\\mathcal{U}[0, \\; 6]\\) (distribuție uniformă între 0 și 6).\n\na). Reprezentați grafic funcția densitate de probabilitate a lui A (distribuția lui A)\nb). Calculați probabilitatea \\(P(A > 1)\\)\nc). Calculați probabilitatea \\(P(A \\in (0, \\; 2))\\)\nd). Reprezentați funcția de repartiție \\(F_A(x)\\) și scrieți-i expresia matematică\ne). Care e distribuția variabilei aleatoare \\(B\\) definită ca \\(B = A - 2\\)?\nf). Care e distribuția variabilei aleatoare \\(C\\) definită ca \\(C = 3*A\\)?\n\n\nRezolvare\na). Distribuția uniformă \\(\\mathcal{U}[0, \\; 6]\\) este reprezentată grafic mai jos.\n\n\n\nDistribuția uniformă \\(\\mathcal{U}[0, \\; 6]\\)\n\n\nb). Probabilitatea \\(P(A > 1)\\) reprezintă aria de sub densitatea de probabilitate \\(w_A(x)\\), de la 1 la infinit (aici, până la 6).\n \\[\\begin{aligned}\nP(A > 1) = \\int_{1}^{\\infty} w_A(x) dx = \\int_{1}^{6} \\frac{1}{6} dx = \\frac{5}{6}\n\\end{aligned}\\]\nc). Probabilitatea \\(P(A \\in (0, \\; 2))\\) reprezintă aria de sub densitatea de probabilitate \\(w_A(x)\\), de la 0 la 2.  \\[\\begin{aligned}\nP(A \\in (0, \\; 2)) = \\int_{0}^{2} w_A(x) dx = \\int_{0}^{2} \\frac{1}{6} dx = \\frac{1}{3}\n\\end{aligned}\\]\nd). Funcția de repartiție \\(F_A(x)\\) este integrala de la \\(-\\infty\\) la \\(x\\) a densității de probabilitate \\(w_A\\). Întrucât \\(w_A(x)\\) este constantă între 0 și 6, \\(F_A(x)\\) este o funcție liniară între 0 și 6, și constantă în afara acestui interval.\nAșadar, graficul funcției de repartiție, este cel de mai jos.\n\nExpresia matematică este: \\[F_A(x) = \\begin{cases}\n0, &x \\leq 0 \\\\\n\\frac{1}{6}x, &x \\in (0, \\; 6) \\\\\n1, &x \\geq 6\n\\end{cases}\\]\ne). Distribuția variabilei aleatoare \\(B\\) este distribuția variabilei \\(A\\) translatată cu 2 unități la stânga, așadar o distribuție uniformă între -2 și 4, \\(\\mathcal{U}[-2, \\; 4]\\).\n\nf). Distribuția variabilei aleatoare \\(C\\) este distribuția variabilei \\(A\\) scalată cu 3, așadar o distribuție uniformă între 0 și 18, \\(\\mathcal{U}[0, \\; 18]\\)."
  },
  {
    "objectID": "Ex_Seminar01.html#exercițiul-2",
    "href": "Ex_Seminar01.html#exercițiul-2",
    "title": "8  Seminar 01: Variabile aleatoare și probabilități",
    "section": "8.2 Exercițiul 2",
    "text": "8.2 Exercițiul 2\nFie A o variabilă aleatoare continuă cu distribuția normală \\(\\mathcal{N}(\\mu = 1, \\sigma^2 = 20)\\).\n\na). Calculați probabilitatea \\(P(A \\in [2, \\; 4])\\)\nb). Care e distribuția variabilei aleatoare \\(B\\) definită ca \\(B = A - 2\\)?\nc). Care este valoarea maximă a distribuției \\(w_A(x)\\), și pentru ce valoare \\(x\\) se atinge?\nd). (**) Care e distribuția variabilei aleatoare \\(C\\) definită ca \\(C = 3*A\\)?\n\n\nRezolvare\na). Probabilitatea \\(P(A \\in [2, \\; 4])\\) reprezintă aria de sub densitatea de probabilitate \\(w_A(x)\\), de la 2 la 4. \\[P(A \\in [2, \\; 4]) = \\int_{2}^{4} w_A(x) dx = F(4) - F(2)\\] unde \\(F(x)\\) este funcția de repartiție a lui \\(A\\), care se poate calcula cu formula: \\[F(x) = \\frac{1}{2} \\left(1 + erf \\left(\\frac{x - \\mu}{\\sqrt{2}\\sigma}\\right)\\right)\\] Așadar: \\[\\begin{aligned}\nP(A \\in [2, \\; 4]) &= F(4) - F(2) \\\\\n&= \\frac{1}{2} \\left(1 + erf \\left(\\frac{4 - 1}{\\sqrt{2}\\sqrt{20}}\\right)\\right) - \\frac{1}{2} \\left(1 + erf \\left(\\frac{2 - 1}{\\sqrt{2}\\sqrt{20}}\\right)\\right) \\\\\n&= ...\n\\end{aligned}\\]\n\nDistribuția variabilei aleatoare \\(B\\) este distribuția variabilei \\(A\\) translatată cu 2 unități la stânga, așadar o distribuție normală cu media -1 și cu aceeași varianță, \\(\\mathcal{N}(\\mu = -1, \\sigma^2 = 20)\\).\nInspectând graficul funcției de densitate normală, se observă că maximul este atins întotdeauna în dreptul mediei. Aici, media are valoarea 1, deci maximul este: \\[w_A(1) = \\frac{1}{\\sqrt{40 \\pi}} e^{-\\frac{(1 - 1)^2}{40}} = \\frac{1}{\\sqrt{40 \\pi}} e^{-0} = \\frac{1}{\\sqrt{40 \\pi}}\\]\n\nd). Dacă valorile lui \\(C\\) sunt triplul valorilor \\(A\\), atunci putem spune că probabilitatea ca \\(C\\) să fie în jurul unei valori \\(x\\) este egală cu probabilitatea ca \\(A\\) să ia valori în jurul lui \\(\\frac{x}{3}\\). Acest lucru se traduce prin relația: \\[w_C(x) = w_A\\left(\\frac{x}{3}\\right)\\] Întrucăt \\(A\\) urmează o distribuție normală, avem: \\[\\begin{aligned}\nw_C(x) &= w_A\\left(\\frac{x}{3}\\right) = \\frac{1}{\\sqrt{40 \\pi}} e^{-\\frac{\\left(\\frac{x}{3} - 1\\right)^2}{40}} \\\\\n&= \\frac{1}{\\sqrt{40 \\pi}} e^{-\\frac{\\left(x - 3\\right)^2}{9 \\cdot 40}} \\\\\n&= TODO...\n\\end{aligned}\\]"
  },
  {
    "objectID": "Ex_Seminar01.html#exercițiul-3",
    "href": "Ex_Seminar01.html#exercițiul-3",
    "title": "8  Seminar 01: Variabile aleatoare și probabilități",
    "section": "8.3 Exercițiul 3",
    "text": "8.3 Exercițiul 3\nConsiderând că scorul IQ urmează o distribuție \\(\\mathcal{N} \\; \\left(\\mu=100, \\sigma=15\\right)\\), calculați:\n\na). Probabilitatea ca o persoană oarecare să aibă IQ > 130\nb). Dacă populația globului este 8 miliarde, câți oameni au IQ mai mic decât 75\nc). (**)Ce IQ minim trebuie să ai pentru a fi între primii 2%?\n\n\nRezolvare\na). Probabilitatea ca o persoană oarecare să aibă IQ > 130 este: \\[\\begin{aligned}\nP(IQ > 130) &= \\int_{130}^{\\infty} w_{IQ}(x) dx \\\\\n&= F_{IQ}(\\infty) - F_{IQ}(130) \\\\\n&= 1 - \\frac{1}{2} \\left(1 + erf \\left(\\frac{130 - 100}{\\sqrt{2}\\cdot 15}\\right)\\right) \\\\\n&= 0.0227 = 2.27\\%\n\\end{aligned}\\]\nb). Trebuie să calculăm probabilitatea ca o persoană oarecare să aibă IQ < 75, și să înmulțim cu populația globului: \\[\\begin{aligned}\nP(IQ < 75) &= \\int_{-\\infty}^{75} w_{IQ}(x) dx \\\\\n&= F_{IQ}(75) - F_{IQ}(-\\infty) \\\\\n&= \\frac{1}{2} \\left(1 + erf \\left(\\frac{75 - 100}{\\sqrt{2}\\cdot 15}\\right)\\right) \\\\\n&= 0.0478\n\\end{aligned}\\] Așadar, numărul de oameni cu IQ < 75 este: \\[8 \\cdot 10^9 \\cdot 0.0478 = 382.4 \\cdot 10^6 = 382.4 \\; milioane\\]"
  },
  {
    "objectID": "Ex_Seminar01.html#exercițiul-4",
    "href": "Ex_Seminar01.html#exercițiul-4",
    "title": "8  Seminar 01: Variabile aleatoare și probabilități",
    "section": "8.4 Exercițiul 4",
    "text": "8.4 Exercițiul 4\nFie A o variabilă aleatoare discretă, cu valorile posibile \\(\\left\\lbrace 0, 1, 2, \\dots 10 \\right\\rbrace\\), toate având aceeași probabilitate.\n\na). Reprezentați grafic distribuția lui A\nb). Calculați probabilitatea \\(P(A \\in [3, \\; 7]\\)\nb). Care e probabilitatea ca A să fie număr impar?\n\n\nRezolvare\n\n\n\nb). Fiind o variabilă discretă, putem calcula probabilitățile ca număr de cazuri favorabile supra numărul total de cazuri posibile.\nProbabilitatea ca \\(A\\) să ia valori între 3 și 7 este: \\[P(A \\in [3, \\; 7]) = \\frac{5}{11}\\]\nc). Probabilitatea ca \\(A\\) să fie impar este: \\[P(A \\; \\text{impar}) = \\frac{5}{11}\\]"
  },
  {
    "objectID": "Ex_Seminar01.html#exercițiul-5",
    "href": "Ex_Seminar01.html#exercițiul-5",
    "title": "8  Seminar 01: Variabile aleatoare și probabilități",
    "section": "8.5 Exercițiul 5",
    "text": "8.5 Exercițiul 5\nCalculați probabilitatea ca 3 variabile aleatoare X, Y, Z, independente și identic distribuite (i.i.d) cu distribuția normală \\(\\mathcal{N}(\\mu = 1, \\sigma^2 = 1)\\) să fie pozitive simultan.\n\nRezolvare\nFiind variabile independente, probabilitatea că toate să fie pozitive este egală cu produsul probabilităților că fiecare să fie pozitivă: \\[P(X > 0 \\cap Y > 0 \\cap Z > 0) = P(X > 0) \\cdot P(Y > 0) \\cdot P(Z > 0)\\]\nÎntrucât toate urmează aceeași distribuție, probabilitatea ca \\(X\\) să fie pozitivă este egală cu probabilitatea ca \\(Y\\) sau ca Z să fie pozitivă, așadar trebuie de fapt să calculăm o singură probabilitate, și apoi să o ridicăm la puterea 3.\nAvem: \\[\\begin{aligned}\nP(X > 0) &= (Y > 0) = P(Z > 0) = \\int_{0}^{\\infty} w_X(x) dx = F(\\infty) - F(0) \\\\\n&= 1 - \\frac{1}{2} \\left(1 + erf \\left(\\frac{0 - 1}{\\sqrt{2}\\cdot 1}\\right)\\right) \\\\\n&= 1 - \\frac{1}{2} \\left(1 + erf \\left(-\\frac{1}{\\sqrt{2}}\\right)\\right) \\\\\n&= 0.841\n\\end{aligned}\\]\nAșadar, probabilitatea că toate să fie pozitive este: \\[P(X > 0, Y > 0, Z > 0) = 0.841^3 = 0.595\\]"
  },
  {
    "objectID": "Ex_Seminar01.html#exercițiul-6",
    "href": "Ex_Seminar01.html#exercițiul-6",
    "title": "8  Seminar 01: Variabile aleatoare și probabilități",
    "section": "8.6 Exercițiul 6",
    "text": "8.6 Exercițiul 6\nFie 3 variabile aleatoare cu distribuțiile: \\[\n\\begin{aligned}\nA &\\sim \\mathcal{N}\\; \\left(\\mu=1, \\sigma^2=3\\right) \\\\\nB &\\sim \\mathcal{N}\\; \\left(\\mu=-4, \\sigma^2=3\\right) \\\\\nC &\\sim \\mathcal{N}\\; \\left(\\mu=5, \\sigma^2=3\\right)\n\\end{aligned}\\]\n\na). Este mai probabil ca tripleta de valori (A, B, C) să ia valori în jurul lui (2, -6, 3) sau în jurul lui (-2, -3, 2)?\nb). Găsiți 3 valori pozitive \\((x, y, z)\\) pentru care probabilitatea ca (A, B, C) să aibă valori în jurul lui \\((x,y,z)\\) să fie egală cu probabilitatea de a avea valori în jurul lui (2, -6, 3)\n\n\nRezolvare\nTODO"
  },
  {
    "objectID": "Ex_Seminar02.html#exercițiul-1",
    "href": "Ex_Seminar02.html#exercițiul-1",
    "title": "9  Seminar 02: Medii statistice și temporale",
    "section": "9.1 Exercițiul 1",
    "text": "9.1 Exercițiul 1\nCalculați valoarea medie, valoarea pătratică medie și varianța unui proces aleator staționar având distribuția unui eșantion egală cu:\n\na). \\(w_1(x) = \\mathcal{U}[a,b]\\) pentru niște valori \\(a, b \\in \\mathbb{R}\\);\nb). \\(w_2(x) = \\begin{cases}  \\frac{1}{2} - \\frac{1}{8} x, &x \\in [0,4] \\\\  0, &în \\;\\; rest  \\end{cases}\\)\nÎn acest caz, reprezentați și distribuția și verificați faptul că integrala sa este egală cu 1.\n\n\nRezolvare\nVom folosi definițiile: \\[\\overline{X} = \\mu = \\int_{-\\infty}^{\\infty} x w(x) dx\\] \\[\\overline{X^2} = \\int_{-\\infty}^{\\infty} x^2 w(x) dx\\] \\[\\begin{aligned}\n\\sigma_X^2 &= \\int_{-\\infty}^{\\infty} (x - \\mu)^2 w(x) dx\\\\\n&= \\overline{X^2} - \\mu^2\n\\end{aligned}\\]\na). Pentru \\(w_1(x) = \\mathcal{U}[a,b]\\) , reprezentată mai jos, vem:\n\n\n\nDistribuția uniformă U[a,b]\n\n\nMedia: \\[\\begin{aligned}\n\\mu = \\overline{X} &= \\int_{-\\infty}^{\\infty} x \\cdot w(x) dx \\\\\n&= \\int_{a}^{b} x \\frac{1}{b-a} dx \\\\\n&= \\frac{1}{b-a} \\cdot \\frac{x^2}{2} \\Biggr|_{a}^{b} \\\\\n&= \\frac{1}{b-a} \\cdot \\frac{b^2 - a^2}{2} \\\\\n&= \\frac{b + a}{2}\n\\end{aligned}\\]\nValoarea pătratică medie: \\[\\begin{aligned}\n\\overline{X^2} &= \\int_{-\\infty}^{\\infty} x^2 \\cdot w(x) dx \\\\\n&= \\int_{a}^{b} x^2 \\frac{1}{b-a} dx \\\\\n&= \\frac{1}{b-a} \\cdot \\frac{x^3}{3} \\Biggr|_{a}^{b} \\\\\n&= \\frac{1}{b-a} \\cdot \\frac{b^3 - a^3}{3} \\\\\n&= \\frac{b^2 + ab + a^2}{3}\n\\end{aligned}\\]\nVarianța: \\[\\begin{aligned}\n\\sigma_X^2 &= \\int_{-\\infty}^{\\infty} (x - \\mu)^2 \\cdot w(x) dx \\\\\n&= \\int_{a}^{b} (x - \\frac{a+b}{2})^2 \\frac{1}{b-a} dx \\\\\n&= \\frac{1}{b-a} \\cdot \\frac{(x - \\frac{a+b}{2})^3}{3} \\Biggr|_{a}^{b} \\\\\n&= \\frac{1}{b-a} \\cdot \\frac{(b - \\frac{a+b}{2})^3 - (a - \\frac{a+b}{2})^3}{3} \\\\\n&= \\frac{1}{b-a} \\cdot \\frac{(b - a)^3}{12} \\\\\n&= \\frac{(b - a)^2}{12}\n\\end{aligned}\\]\nVarianța poate fi calculată și ca diferența dintre valoarea pătratică medie și pătratul mediei: \\[\\begin{aligned}\n\\sigma_X^2 &= \\overline{X^2} - \\mu^2 \\\\\n&= \\frac{b^2 + ab + a^2}{3} - \\frac{(b + a)^2}{4} \\\\\n&= \\frac{4b^2 + 4ab + 4a^2 - 3b^2 - 6ab - 3a^2}{12} \\\\\n&= \\frac{b^2 - 2ab + a^2}{12} \\\\\n&= \\frac{(b - a)^2}{12}\n\\end{aligned}\\]\nb). Graficul funcției \\(w_2(x)\\) este reprezentat mai jos. \\[w_2(x) = \\begin{cases}\n        \\frac{1}{2} - \\frac{1}{8} x, &x \\in [0,4] \\\\\n        0, &în  \\;\\; rest\n        \\end{cases}\\]\n\n\n\nDistribuția \\(w_2(x)\\)\n\n\nIntegrala sa reprezintă aria unui triunghi dreptunghic cu catetele \\(4\\) și \\(\\frac{1}{2}\\), deci: \\[\\int_{-\\infty}^{\\infty} w_2(x) dx = \\frac{4 \\cdot \\frac{1}{2}}{2} = 1\\]\nMedia: \\[\\begin{aligned}\n\\overline{X} &= \\int_{-\\infty}^{\\infty} x \\cdot w(x) dx \\\\\n&= \\int_{0}^{4} x \\cdot \\left(\\frac{1}{2} - \\frac{1}{8} x\\right) dx \\\\\n&= \\frac{1}{2} \\cdot \\frac{x^2}{2} \\Biggr|_{0}^{4} - \\frac{1}{8} \\cdot \\frac{x^3}{3} \\Biggr|_{0}^{4} \\\\\n&= \\frac{1}{2} \\cdot \\frac{4^2}{2} - \\frac{1}{8} \\cdot \\frac{4^3}{3} \\\\\n&= 4 - \\frac{8}{3} \\\\\n&= 1.333\n\\end{aligned}\\]\nValoarea pătratică medie: \\[\\begin{aligned}\n\\overline{X^2} &= \\int_{-\\infty}^{\\infty} x^2 \\cdot w(x) dx \\\\\n&= \\int_{0}^{4} x^2 \\cdot \\left(\\frac{1}{2} - \\frac{1}{8} x\\right) dx \\\\\n&= \\frac{1}{2} \\cdot \\frac{x^3}{3} \\Biggr|_{0}^{4} - \\frac{1}{8} \\cdot \\frac{x^4}{4} \\Biggr|_{0}^{4} \\\\\n&= \\frac{1}{2} \\cdot \\frac{4^3}{3} - \\frac{1}{8} \\cdot \\frac{4^4}{4} \\\\\n&= \\frac{32}{3} - 8 \\\\\n&= \\frac{8}{3}\n\\end{aligned}\\]\nVarianța: \\[\\begin{aligned}\n\\sigma_X^2 &= \\overline{X^2} - \\mu^2 \\\\\n&= \\frac{8}{3} - \\left(\\frac{4}{3}\\right)^2 \\\\\n&= \\frac{8}{3} - \\frac{16}{9} \\\\\n&= \\frac{8}{9}\n\\end{aligned}\\]"
  },
  {
    "objectID": "Ex_Seminar02.html#exercițiul-2",
    "href": "Ex_Seminar02.html#exercițiul-2",
    "title": "9  Seminar 02: Medii statistice și temporale",
    "section": "9.2 Exercițiul 2",
    "text": "9.2 Exercițiul 2\nCalculați valoarea medie temporală, valoarea pătratică medie temporală, varianța temporală și funcția de autocorelație temporală pentru următoarea realizare a unui proces aleator de lungime finită:\n\\[f = [-1, 2, -1, 2, -1, 2, -1, 2, -1, 2]\\]\n\nRezolvare\nPentru această secvență de zece numere, aplicăm definiițile mediilor temporale.\nValoarea medie temporală este media aritmetică a numerelor: \\[\\overline{f_t} = \\frac{-1 + 2 - 1 + 2 - 1 + 2 - 1 + 2 - 1 + 2}{10} = \\frac{5}{10} = 0.5\\]\nValoarea pătratică medie temporală este media aritmetică a pătratelor numerelor: \\[\\overline{f_t^2} = \\frac{(-1)^2 + 2^2 + (-1)^2 + 2^2 + (-1)^2 + 2^2 + (-1)^2 + 2^2 + (-1)^2 + 2^2}{10} = \\frac{25}{10} = 2.5\\]\nVarianța temporală este diferența dintre valoarea pătratică medie și pătratul mediei: \\[\\sigma_f^2 = \\overline{f_t^2} - \\overline{f_t}^2 = 2.5 - 0.5^2 = 2.25\\] De asemenea, se poate calcula si conform definiției.\nFuncția de autocorelație temporală de definește ca media produselor eșantioanelor separate de un interval de timp \\(k\\): \\[r_{ff}(k) = \\overline{f[t] \\cdot f[t+k]}\\] Așadar: \\[r_{ff}[0] = \\overline{f[t] \\cdot f[t]} = \\overline{f_t^2} = 2.5\\] \\[r_{ff}[1] = \\overline{f[t] \\cdot f[t+1]} = \\frac{(-1)2 + 2(-1) + (-1)2 + 2(-1) + (-1)2 + 2(-1) + (-1)2 + 2(-1)}{9} = -2\\] \\[r_{ff}[2] = \\overline{f[t] \\cdot f[t+2]} = \\frac{(-1)(-1) + 2\\cdot 2 + (-1)(-1) + 2\\cdot 2 + (-1)(-1) + 2\\cdot 2 + (-1)(-1) + 2\\cdot 2}{8} = 2.5\\] Se continuă în acest mod până la ultima valoare: \\[r_{ff}[9] = \\overline{f[t] \\cdot f[t+9]} = \\frac{(-1)(2)}{1} = -2\\] Valorile funcției de autocorelație pentru \\(k\\) negativ se obțin prin simetrie: \\[r_{ff}[-k] = r_{ff}[k]\\] Așadar: \\[r_{ff}[-1] = r_{ff}[1] = -2\\] \\[r_{ff}[-2] = r_{ff}[2] = 2.5\\] și așa mai departe până la: \\[r_{ff}[-9] = r_{ff}[9] = -2\\]"
  },
  {
    "objectID": "Ex_Seminar02.html#exercițiul-3",
    "href": "Ex_Seminar02.html#exercițiul-3",
    "title": "9  Seminar 02: Medii statistice și temporale",
    "section": "9.3 Exercițiul 3",
    "text": "9.3 Exercițiul 3\nCalculați valoarea medie temporală, valoarea pătratică medie temporală, varianța temporală și funcția de autocorelație temporală pentru următorul semnal deterministic, considerat pe durata unei singure perioade \\(T=\\frac{1}{f}\\):\n\\[ s(t) = cos(2 \\pi f t)\\]\n(Sugestie: Considerați \\(s(t)\\) ca fiind o realizare a unui proces aleator oarecare, și rezolvați ca la problema 2).\n\nRezolvare\nSemnalul \\(s(t)\\) este reprezentat mai jos.\n\n\n\nSemnalul \\(s(t)\\)\n\n\nPentru semnale continue, valoarea medie temporală reprezintă componenta de curent continuu a semnalului. Din figură se poate deduce că aceasta este \\(0\\), prin urmare: \\[\\overline{s(t)} = 0\\]\nValoarea medie pătratică temporală (media semnalului ridicat la pătrat) reprezintă “tensiunea efectivă” a semnalului (la pătrat), și se definește astfel: \\[\\overline{s^2(t)} = \\frac{1}{T} \\int_{0}^{T} s^2(t) dt\\]\nFolosind formula trigonometrică \\[cos^2(x) = \\frac{1 + cos(2x)}{2}\\] avem: \\[\\begin{aligned}\n\\overline{s^2(t)} &= \\frac{1}{T} \\int_{0}^{T} s^2(t) \\\\\n&= \\frac{1}{T} \\int_{0}^{T} \\cos^2(2 \\pi f t) dt \\\\\n&= \\frac{1}{T} \\int_{0}^{T} \\frac{1 + \\cos(4 \\pi f t)}{2} dt \\\\\n&= \\frac{1}{T} \\int_{0}^{T} \\frac{1}{2} dt + \\frac{1}{T} \\int_{0}^{T} \\frac{\\cos(4 \\pi f t)}{2} dt \\\\\n&= \\frac{1}{2} + \\frac{1}{2T} \\cdot \\frac{\\sin(4 \\pi f t)}{4 \\pi f} \\Biggr|_{0}^{T} \\\\\n&= \\frac{1}{2}\\\\\n\\end{aligned}\\]\nAceastă valoare se putea obține și folosindu-ne de faptul cunoscut că tensiunea efectivă a unui semnal sinusoidal de amplitudine \\(A\\) este egală cu \\(\\frac{A}{\\sqrt{2}}\\). Pentru \\(A=1\\), pătratul valorii efective este deci \\(\\frac{1}{2}\\).\nVarianța temporală se obține pe baza primelor două mărimi: \\[\\sigma_s^2 = \\overline{s^2(t)} - \\overline{s(t)}^2 = \\frac{1}{2} - 0^2 = \\frac{1}{2}\\]\nTODO restul"
  },
  {
    "objectID": "Ex_Seminar03.html#exercițiul-1",
    "href": "Ex_Seminar03.html#exercițiul-1",
    "title": "10  Seminar 03: Criteriul de decizie Maximum Likelihood",
    "section": "10.1 Exercițiul 1",
    "text": "10.1 Exercițiul 1\nFie detecția între două semnale constante, \\(s_0(t) = -1\\) și \\(s_1(t) = 4\\). Semnalele sunt afectate de zgomot alb cu distribuția \\(\\mathcal{N}\\;(\\mu=0, \\sigma^2=4)\\). Receptorul ia un singur eșantion la momentul \\(t_0 = 0.75\\), și valoarea obținută este \\(r = 1.8\\).\n\na). Scrieți expresiile celor două distribuții condiționate și reprezentați-le\nb). Ce decizie se ia cu criteriul Maximum Likelihood?\n\n\nRezolvare\na). Dacă suntem în situația \\(H_0\\), atunci eșantionul va fi \\(r = -1 + zgomot\\), ceea ce înseamnă ce distribuția lui \\(r\\) în cazul \\(H_0\\) este distribuția zgomotului dar centrată în \\(-1\\), adică \\(\\mathcal{N}(\\mu=-1, \\sigma^2=4)\\).\nÎn ipoteza \\(H_1\\), eșantionul va fi \\(r = 4 + zgomot\\),, așadar distribuția sa va fi \\(\\mathcal{N}(\\mu=4, \\sigma^2=4)\\).\n\n\n\nDistribuții condiționate\n\n\nCunoscând expresia generală a unei distribuții normale: \\[w(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x-\\mu)^2}{2 \\sigma^2}}\\] putem scrie așadar expresiile celor două distribuții condiționate: \\[w(r|H_0) = \\frac{1}{2 \\sqrt{2 \\pi}} e^{-\\frac{(r+1)^2}{8}}\\] \\[w(r|H_1) = \\frac{1}{2 \\sqrt{2 \\pi}} e^{-\\frac{(r-4)^2}{8}}\\]\nb). Confirm criteriului Maximum Likelihood, decizia luată pentru un eșantion de valoare \\(r = 1.8\\) este dată de distribuția care are valoarea mai mare în dreptul acestui punct \\(r = 1.8\\).\nDin figură, se observă că \\(r=1.8\\) se află la dreapta punctului de intersecție dintre cele două distribuții, situat la mijlocul distanței dintre \\(-1\\) și \\(4\\), adică \\(1.5\\). Așadar pentru \\(r = 1.8\\) mai înaltă este distribuția \\(w(r|H_1)\\), deci decizia este \\(D_1\\): \\[w(r|H_1) > w(r|H_0)\\Biggr|_{\\substack{r=1.8}}  \\Rightarrow D_1\\]"
  },
  {
    "objectID": "Ex_Seminar03.html#exercițiul-2",
    "href": "Ex_Seminar03.html#exercițiul-2",
    "title": "10  Seminar 03: Criteriul de decizie Maximum Likelihood",
    "section": "10.2 Exercițiul 2",
    "text": "10.2 Exercițiul 2\nFie detecția între două semnale, \\(s_0(t) = \\cos(2 \\pi t)\\) și \\(s_1(t) = \\sin(2 \\pi t)\\).\nSemnalele sunt afectate de zgomot alb cu distribuția \\(\\mathcal{N}(\\mu=0, \\sigma^2=2)\\).\nReceptorul ia un singur eșantion la momentul \\(t_0 = 0.75\\), și valoarea obținută este \\(r(t_0) = 3.5\\).\nCerințe:\n\na). Reprezentați grafic cele două distribuții condiționate și scrieți-le expresia matematică\nb). Ce decizie se ia conform criteriului Maximum Likelihood?\nc). Găsiți regiunile de decizie\nd). Calculați probabilitățile condiționate ale celor 4 scenarii (rejecție corectă, alarmă falsă, pierdere, detecție corectă)\ne). Care ar fi cel mai bun moment \\(t_0\\) de eșantionare, pentru a decide între semnale? Justificați\nf). Care ar fi cel mai rău moment \\(t_0\\) de eșantionare, pentru a decide între semnale? Justificați\ng). Repetați a) și b) dacă zgomotul are distribuție uniformă \\(\\mathcal{U}[-4,4]\\). Există valori pentru care nu se poate lua o decizie?\nh). Care este varianța maximă a unui zgomot uniform, cu media 0, pentru care se poate lua o decizie cu criteriul ML pentru \\(r = 3.5\\)?\n\n\nRezolvare\nLa momentul \\(t_0 = 0.75\\), semnalele originale au valoarea sunt \\(s_0(t_0) = \\cos(2 \\pi 0.75) = 0\\) și \\(s_1(t_0) = \\sin(2 \\pi 0.75) = -1\\). Prin urmare, în cazul \\(H_0\\) eșantionul va urma o distribuție normală în jurul lui \\(0\\), iar în cazul \\(H_1\\) o distribuție normală în jurul lui \\(-1\\): \\[H_0: \\mathcal{N}(\\mu=0, \\sigma^2=2)\\] \\[H_1: \\mathcal{N}(\\mu=-1, \\sigma^2=2)\\]\nExpresiile și reprezentarea grafică a acestor distribuții sunt prezentate mai jos: \\[w(r|H_0) = \\frac{1}{\\sqrt{4 \\pi}} e^{-\\frac{r^2}{4}}\\] \\[w(r|H_1) = \\frac{1}{\\sqrt{4 \\pi}} e^{-\\frac{(r+1)^2}{4}}\\]\n\n\n\nDistribuții condiționate\n\n\nSe observă că distribuția din stânga este acum \\(w(r|H_1)\\), iar cea din dreapta \\(w(r|H_0)\\).\nb). Conform criteriului Maximum Likelihood, pentru \\(r = 3.5\\) decizia este corespunzătoare distribuției mai înalte în acel punct, adică \\(D_0\\).\nc). Regiunea de decizie \\(R_0\\) cuprinde valorile \\(r\\) pentru care se ia decizia \\(D_0\\), adică intervalul în care funcția \\(w(r|H_0)\\) este mai înaltă decât \\(w(r|H_1)\\): \\[R_0 = (-0.5, \\infty)\\]\nRegiunea de decizie \\(R_1\\) cuprinde valorile \\(r\\) pentru care se ia decizia \\(D_1\\), adică intervalul în care funcția \\(w(r|H_1)\\) este mai înaltă: \\[R_1 = (-\\infty, 0.5-)\\]\nd). Cele patru probabilități corespund celor patru zone reprezentate în figura de mai jos. Fiecare distribuție dă naștere la două probabilități, integrând pe cele două regiuni de decizie.\n\n\n\nProbabilități condiționate\n\n\nCele patru arii reprezintă integrale din niște funcții de distribuție normale, care se pot calcula cu funcția de repartiție \\(F(x)\\). Așadar: \\[\\begin{aligned}\nP_{rc} &= P(D_0|H_0) = \\int_{R_0} w(r|H_0) dr \\\\\n&= F_{H_0}(\\infty) - F_{H_0}(-0.5) \\\\\n&= 1 - \\frac{1}{2}\\left(1 + erf  \\left(\\frac{-0.5 - 0}{\\sqrt{2}\\sqrt{2}}\\right)\\right) = 0.638\n\\end{aligned}\\] \\[\\begin{aligned}\nP_{af} &= P(D_1|H_0) = \\int_{R_1} w(r|H_0) dr \\\\\n&= F_{H_0}(-0.5) - F_{H_0}(-\\infty) \\\\\n&= \\frac{1}{2}\\left(1 + erf  \\left(\\frac{-0.5 - 0}{\\sqrt{2}\\sqrt{2}}\\right)\\right) = 0.362\n\\end{aligned}\\] \\[\\begin{aligned}\nP_{p} &= P(D_0|H_1) = \\int_{R_0} w(r|H_1) dr \\\\\n&= F_{H_1}(\\infty) - F_{H_1}(-0.5) \\\\\n&= 1 - \\frac{1}{2}\\left(1 + erf  \\left(\\frac{-0.5 + 1}{\\sqrt{2}\\sqrt{2}}\\right)\\right) = 0.362\n\\end{aligned}\\] \\[\\begin{aligned}\nP_{dc} &= P(D_1|H_1) = \\int_{R_1} w(r|H_1) dr \\\\\n&= F_{H_1}(-0.5) - F_{H_1}(-\\infty) \\\\\n&= \\frac{1}{2}\\left(1 + erf  \\left(\\frac{-0.5 + 1}{\\sqrt{2}\\sqrt{2}}\\right)\\right) = 0.638\n\\end{aligned}\\]\ne). Cel mai bun moment de eșantionare, în vederea deciziei, este acela în care semnalele originale sunt cît mai diferite între ele. În cazul nostru, semnalele \\(s_0(t)\\) și \\(s_1(t)\\), sinus și cosinus, sunt reprezentate în figura următoare.\n\n\n\nSemnalele \\(s_0(t)\\) și \\(s_1(t)\\)\n\n\nFrecvența semnalelor este \\(f=1\\), deci perioada acestora este \\(T = 1/f = 1\\).\nDiferența maximă între semnale se obține în dreptul valorilor \\(t = 0.375\\) și \\(t = 0.875\\), deci acestea sunt cele mai bune momente de eșantionare.\nf). Cel mai rău moment de eșantionare în vederea deciziei este acela în care semnalele originale sunt cît mai apropiate între ele. În cazul nostru, semnalele au aceeași valoare la momentele de timp \\(t = 0.125\\) și \\(t = 0.625\\), prin urmare acestea sunt cele mai nepotrivite moment de eșantionare.\ng). Dacă zgomotul are distribuție uniformă \\(\\mathcal{U}[-4,4]\\), atunci distribuțiile condiționate sunt cele de mai jos.\n\n\n\nDistribuții condiționate\n\n\n\\[w(r|H_0) = \\mathcal{U}[-4,4]\\] \\[w(r|H_1) = \\mathcal{U}[-5,3]\\]\nSe observă suprapunerea lor pe intervalul \\([-4,3]\\), ceea ce înseamnă că pentru toate valorile din acest interval nu se poate lua o decizie cu criteriul Maximum Likelihood (indecizie).\nPentru valoarea \\(r = 3.5\\), decizia este \\(D_0\\), deoarece distribuția \\(w(r|H_0)\\) este mai înaltă în acel punct.\nh). În condițiile de la punctul g), pentru \\(r = 3.5\\) decizia luată cu criteriul ML este \\(D_0\\). Întrebarea este: dacă creștem varianța zgomotului (distribuțiile devin mai late), la ce moment nu mai putem lua o decizie?\nAjungem la indecizie atunci când ambele distribuții devin egale în punctul \\(r = 3.5\\), adică atunci când distribuția \\(w(r|H_1\\) se va întinde până la \\(r = 3.5\\), așadar va fi o disribuție uniformă \\(\\mathcal{U}[-5.5,3.5]\\), centrată pe pucntul \\(-1\\) și de lățime totala egală cu \\(9\\).\nTrebuie să calculăm varianța acestei distribuții (care este egală cu varianța zgomotului) pentru acest caz limită. Pentru varianță contează doar lățimea distribuției, nu și centrul ei, așadar putem considera distribuția centrată pe \\(0\\) și de lățime \\(9\\), \\(\\mathcal{U}[-4.5,4.5]\\). Avem: \\[\\sigma^2 = \\int_{-4.5}^{4.5} (x - 0)^2 \\frac{1}{9} dx =\n\\frac{1}{9} \\cdot \\frac{x^3}{3} \\Biggr|_{-4.5}^{4.5} =\n\\frac{1}{9} \\cdot \\frac{4.5^2 \\cdot 2}{3} = 1.5\\]"
  },
  {
    "objectID": "Ex_Seminar04.html#exercițiul-1",
    "href": "Ex_Seminar04.html#exercițiul-1",
    "title": "11  Seminar 04: Decizii, decizii",
    "section": "11.1 Exercițiul 1",
    "text": "11.1 Exercițiul 1\nUn sistem airbag detectează un accident prin eșantionarea semnalului de la un senzor cu 2 valori posibile: \\(s_0(t) = 0\\) (OK) sau \\(s_1(t) = A\\) (accident), unde \\(A = 5\\).\nSemnalul este afectat de zgomot gaussian \\(\\mathcal{N}\\;(\\mu=0, \\sigma^2=2)\\).\nCosturile scenariilor sunt: \\(C_{00} = 0\\), \\(C_{01} = 100\\), \\(C_{10} = 10\\), \\(C_{11} = 0\\).\nProbabilitățile celor două ipoteze sunt \\(P(H_0) = 2/3\\), \\(P(H_1) = 1/3\\).\nLa recepție se ia un singur eșantion \\(r\\) din semnal.\nCerințe:\n\n\nGăsiți regiunile de decizie \\(R_0\\) și \\(R_1\\) pentru toate criteriile de mai jos:\n\n\nML\nMPE\nMR\nNeyman-Pearson cu probabilitatea (condiționată) de alarmă falsă \\(P_{af} \\leq 0.01\\)\nUn prag \\(T\\) ales arbitrar la valoarea \\(T=3\\)\n\n\nCalculați probabilitatea de pierdere, pentru toate criteriile de mai sus\n\n\nCare este decizia luată cu fiecare criteriu de mai sus, dacă \\(r = 3.1\\)?\n\n\nConsiderând criteriul MR, care este valoarea minimă a lui \\(A\\) pentru ca probabilitatea (necondiționată) de pierdere sa fie maxim \\(P_{p} \\leq 10^{-6}\\)?\n\n\n\nRezolvare\na). Zgomotul fiind de tip gaussian, pentru criteriile ML, MPE și MR pragul \\(T\\) care separă regiunile de decizie este dat de: \\[T = \\frac{s_0(t_0) + s_1(t_0)}{2} + \\frac{\\sigma^2}{s_1(t_0) - s_0(t_0)} \\cdot\\ln K\\] Conform figurilor de mai jos, regiunile de decizie vor fi intervalele \\((-\\infty, T)\\) și \\((T, \\infty)\\).\nAșadar, pentru criteriul ML, \\(K=1\\) și: \\[T_{ML} = \\frac{0 + 5}{2} + \\frac{2}{5 - 0} \\cdot\\ln 1 = 2.5\\] \\[R_0 = (-\\infty, 2.5),\\quad R_1 = (2.5, \\infty)\\]\n\n\n\nMaximum Likelihood\n\n\nPentru criteriul MPE, \\(K=\\frac{P(H_0)}{P(H_1)} = 2\\) și: \\[T_{MPE} = \\frac{0 + 5}{2} + \\frac{2}{5 - 0} \\cdot\\ln 2 = 2.77\\] \\[R_0 = (-\\infty, 2.77),\\quad R_1 = (2.77, \\infty)\\]\n\n\n\nMinimum Probability of Error\n\n\nPentru criteriul MR, \\(K=\\frac{(C_{10} - C_{00})P(H_0)}{(C_{01} - C_{11})P(H_1)} = \\frac{1}{5}\\) și: \\[T_{MR} = \\frac{0 + 5}{2} + \\frac{2}{5 - 0} \\cdot\\ln(\\frac{1}{5}) = 1.85\\] \\[R_0 = (-\\infty, 1.85),\\quad R_1 = (1.85, \\infty)\\]\n\n\n\nMaximum Risk\n\n\nCriteriul Neyman-Pearson se formulează astfel:\n“Se alege pragul \\(T\\) astfel încât să se maximizeze probabilitatea de detecție corectă \\(P_{dc} = P(D_1|H_1)\\), păstrând probabilitatea de alarmă falsă \\(P_{af} = P(D_1|H_0)\\) mai mică sau egală cu o valoare dată \\(\\lambda\\)”. În cazul nostru, \\(\\lambda = 0.01\\).\nValoarea pragului \\(T_{NP}\\) rezultă din cele două condiții enunțate mai sus, ilustrare în figura de mai jos:\n\npentru a maximiza \\(P(D_1|H_1)\\), adică verde din figură, pragul ar trebui să fie cât mai la stânga\nprobabilitatea de alarmă falsă \\(P(D_1|H_0)\\), adică aria colorată portocaliu în figură, nu trebuie să depășească 0.01\n\n\n\n\nNeyman-Pearson\n\n\nAcest lucru înseamnă că pragul \\(T_{NP}\\) trebuie să fie ales în așa fel încât aria colorată portocaliu să fie exact egală cu 0.01. Dacă este mai la stânga, probabilitatea de alarmă falsă depășește 0.01, iar dacă este mai la dreapta, probabilitatea de detecție corectă nu e cea maximă posibilă.\nProbabilitatea de alarmă falsă \\(P_{af}\\) este dată de: \\[P_{af} = P(D_1|H_0) = \\int_{T_{NP}}^{\\infty} w(r|H_0) dr = 1 - F_{H_0}(T_{NP})\\] unde funcția \\(F_{H_0}\\) este funcția de repartiție a lui \\(w(r|H_0)\\). \\[P_{af} = P(D_1|H_0) = \\int_{T_{NP}}^{\\infty} w(r|H_0) dr = 1 - F_{H_0}(T_{NP})\\]\nAșadar, condiția \\(P_{af} = 0.01\\) devine: \\[1 - F_{H_0}(T_{NP}) = 0.01\\] \\[1 - \\frac{1}{2}(1 + erf(\\frac{T_{NP} - 0}{2})) = 0.01\\] \\[erf(\\frac{T_{NP} - 0}{2}) = 0.98\\] \\[\\frac{T_{NP} - 0}{2} = erf^{-1}(0.98) = 1.64\\] \\[T_{NP} = 3.28\\]\nAșadar, pentru criteriul Neyman-Pearson, rezultatul este: \\[T_{NP} = 3.28\\] \\[R_0 = (-\\infty, 3.28),\\quad R_1 = (3.28, \\infty)\\]\nÎn fine, pentru situația unui prag arbitrar \\(T=3\\), regiunile de decizie sunt: \\[R_0 = (-\\infty, 3),\\quad R_1 = (3, \\infty)\\]\nb). Probabilitatea necondiționată de pierdere este dată de: \\[P_p = P(H_1) \\cdot P(D_0|H_1) = P(H_1) \\cdot \\int_{R_0} w(r|H_1) dr\\] unde probabilitatea condiționață de pierdere \\(P(D_0|H_1)\\) corespunde cu zona colorată în roșu din figura de mai jos.\n\n\n\nProbabilitatea de pierdere\n\n\nÎn funcție de pragul \\(T\\), \\(P(D_0|H_1)\\) este integrala dintre \\(-\\infty\\) și \\(T\\) din distribuția lui \\(w(r|H_1)\\), adică: \\[\n\\begin{align}\nP(D_0|H_1) &= \\int_{-\\infty}^{T} w(r|H_1) dr \\\\\n&= F_{H_1}(T) \\\\\n&= \\frac{1}{2}(1 + erf(\\frac{T - 5}{2})) \\\\\n\\end{align}\\]\nAșadar: \\[T_{ML} = 2.5, \\quad Pp = \\frac{1}{3} \\cdot \\frac{1}{2}(1 + erf(\\frac{2.5 - 5}{2})) = ...\\] \\[T_{MPE} = 2.77, \\quad Pp = \\frac{1}{3} \\cdot \\frac{1}{2}(1 + erf(\\frac{2.77 - 5}{2})) = ...\\] \\[T_{MR} = 1.85, \\quad Pp = \\frac{1}{3} \\cdot \\frac{1}{2}(1 + erf(\\frac{1.85 - 5}{2})) = ...\\] \\[T_{NP} = 3.28, \\quad Pp = \\frac{1}{3} \\cdot \\frac{1}{2}(1 + erf(\\frac{3.28 - 5}{2})) = ...\\] \\[T = 3, \\quad Pp = \\frac{1}{3} \\cdot \\frac{1}{2}(1 + erf(\\frac{3 - 5}{2})) = ...\\]\nc). Pentru un eșantion \\(r=3.1\\), tot ce avem de făcut este să verificăm în ce regiune de decizie se află acesta. Dacă \\(r \\in R_0\\), atunci decizia este \\(D_0\\), iar dacă \\(r \\in R_1\\), decizia este \\(D_1\\).\nAșadar, pentru criteriul ML, \\(r=3.1 \\in R_1\\), decizia este \\(D_1\\).\nPentru criteriul MPE, \\(r=3.1 \\in R_1\\), decizia este \\(D_1\\).\nPentru criteriul MR, \\(r=3.1 \\in R_1\\), decizia este \\(D_1\\).\nPentru criteriul NP, \\(r=3.1 \\in R_0\\), decizia este \\(D_0\\).\nPentru pragul \\(T=3\\), \\(r=3.1 \\in R_1\\), decizia este \\(D_1\\).\nd). Pentru criteriul MR, probabilitate de pierdere este \\(Pp \\leq 10^{-6}\\) implică \\(P(D_0|H_1) \\leq 3 \\cdot 10^{-6}\\). Pe de altă parte, avem \\[P(D_0|H_1) = F_{H_1}(T_{MR}) = \\frac{1}{2}(1 + erf(\\frac{T_{MR} - A}{2}))\\]\nValoarea lui \\(A\\) reprezintă valoarea lui \\(s_1(t)\\), și afectează valoarea lui \\(T_{MR}\\).\nAșadar, va trebui ca din condiția \\(P(D_0|H_1) \\leq 3 \\cdot 10^{-6}\\) să gasim condiția asupra lui \\(T_{MR}\\), din care apoi vom găsi condiția asupra lui \\(A\\).\nProcedăm astfel: \\[\n\\begin{align}\nP(D_0|H_1) &\\leq 3 \\cdot 10^{-6} \\\\\n\\frac{1}{2}(1 + erf(\\frac{T_{MR} - A}{2})) &\\leq 3 \\cdot 10^{-6} \\\\\nerf(\\frac{T_{MR} - A}{2}) &\\leq 6 \\cdot 10^{-6} - 1 \\\\\n\\frac{T_{MR} - A}{2} &\\leq erf^{-1}(6 \\cdot 10^{-6} - 1) \\\\\n\\frac{T_{MR} - A}{2} &\\leq -3.45 \\\\\nT_{MR} &\\leq A - 6.9 \\\\\n\\end{align}\\]\nLa rândul său, \\(T_{MR} = \\frac{s_0(t_0) + s_1(t_0)}{2} + \\frac{\\sigma^2}{s_1(t_0) - s_0(t_0)} \\cdot\\ln(K)\\), adică în cazul nostru: \\[T_{MR} = \\frac{0 + A}{2} + \\frac{2}{A - 0} \\cdot\\ln(\\frac{1}{5})\\]\nAșadar, condiția \\(T_{MR} \\leq A - 5.9\\) devine: \\[\\frac{A}{2} + \\frac{2}{A} \\cdot\\ln(\\frac{1}{5}) \\leq A - 6.9\\] \\[\\frac{A}{2} - \\frac{2}{A} \\cdot\\ln(\\frac{1}{5}) - 6.9 \\geq 0\\] \\[A^2 - 13.8 A + 4 \\ln(\\frac{1}{5}) \\geq 0\\]\nSoluțiile ecuației de gradul doi sunt: \\[A_{1,2} = \\frac{13.8 \\pm \\sqrt{13.8^2 - 4 \\cdot 4 \\ln(\\frac{1}{5})}}{2} = 28.5 ; -0.9\\]\nParabola \\(A^2 - 13.8 A + 4 \\ln(\\frac{1}{5})\\) este pozitivă în afara intervalului dintre cele două soluții, adică a intervalului \\((-0.9, 28.5)\\).\nPresupunând că \\(A\\) este pozitiv, rezultatul este \\(A \\geq 28.5\\)."
  },
  {
    "objectID": "Ex_Seminar04.html#exercițiul-2",
    "href": "Ex_Seminar04.html#exercițiul-2",
    "title": "11  Seminar 04: Decizii, decizii",
    "section": "11.2 Exercițiul 2",
    "text": "11.2 Exercițiul 2\nRepetați exercițiul 1 considerând zgomot uniform \\(U[-3, 3]\\) în loc de zgomot gaussian.\n\nRezolvare\na). Zgomotul fiind de tip uniform, pentru criteriile ML, MPE și MR nu mai putem folosi formulele rapide care ne furnizau pragul \\(T\\) în cazul zgomotului gaussian.\nPentru zgomot diferit de cel gaussian, va trebui să utilizăm formula generală: \\[\\frac{w(r|H_1)}{w(r|H_0)} \\grtlessH K\\]\nCele două distribuții condiționate \\(w(r|H_0)\\) și \\(w(r|H_1)\\) sunt reprezentate mai jos.\n\n\n\nZgomot uniform\n\n\nPutem calcula ușor valorile raportului \\(\\frac{w(r|H_1)}{w(r|H_0)}\\) pe intervale:\n\npentru \\(r \\in (-3, 2)\\): \\(\\frac{w(r|H_1)}{w(r|H_0)} = \\frac{0}{1/6} = 0\\)\npentru \\(r \\in (2, 3)\\): \\(\\frac{w(r|H_1)}{w(r|H_0)} = \\frac{1/6}{1/6} = 1\\)\npentru \\(r \\in (3, 8)\\): \\(\\frac{w(r|H_1)}{w(r|H_0)} = \\frac{1/6}{0} = \\infty\\)\nîn afara intervalului \\((-3, 8)\\), ambele distribuții sunt nule, deci această situație nu ne interesează (nu se întâmplă niciodată).\n\nAcum putem decide cărei regiuni aparține fiecare interval, comparând aceste valori cu \\(K\\).\nPentru criteriul ML, \\(K=1\\) și: \\[R_0 = (-3, 2),\\quad R_1 = (3, 8), \\quad (2,3) = indecizie\\]\nPentru criteriul MPE, \\(K=\\frac{P(H_0)}{P(H_1)} = 2\\) și: \\[R_0 = (-3, 3),\\quad R_1 = (3, 8)\\]\nPentru criteriul MR, \\(K = \\frac{1}{5}\\) și: \\[R_0 = (-3, 2),\\quad R_1 = (2, 8)\\]\nPentru criteriul Neyman-Pearson, probabilitățile sunt cele din figura de mai jos. Pragul \\(T_{NP}\\) trebuie ales astfel încât să avem condiția \\(P_{af} = 0.01\\), unde \\(P_{af}\\) este aria colorată cu portocaliu, adică un dreptunghi cu latura \\(3 - T_{NP}\\) și înălțimea \\(1/6\\).\n\n\n\nZgomot uniform, Neyman-Pearson\n\n\nAvem așadar: \\[(3 - T_{NP}) \\cdot \\frac{1}{6} = 0.01\\] de unde rezultă \\[T_{NP} = 2.94\\] și deci regiunile de decizie sunt: \\[R_0 = (-3, 2.94),\\quad R_1 = (2.94, 8)\\]\nÎn fine, pentru \\(T=3\\), regiunile de decizie sunt, în mod evident: \\[R_0 = (-3, 3),\\quad R_1 = (3, 8)\\]\nb). Probabilitatea necondiționată de pierdere este dată de: \\[P_p = P(H_1) \\cdot P(D_0|H_1) = P(H_1) \\cdot \\int_{R_0} w(r|H_1) dr\\] Integrala se calculează asupra funcției \\(w(r|H_1)\\) pe intervalul \\(R_0\\), după cum se vede în figura de mai jos.\n\n\n\nProbabilitatea (condiționată) de pierdere\n\n\nÎn funcție de regiunea de decizie \\(R_0\\) obținută anterior pentru fiecare criteriu, avem:\nPenru criteriul ML, \\(P_p = \\frac{1}{3} \\cdot \\int_{-3}^{2} 0 dr = 0\\).\nPenru criteriul MPE, \\(P_p = \\frac{1}{3} \\cdot 1 \\cdot \\frac{1}{6} = \\frac{1}{18}\\).\nPenru criteriul MR, \\(P_p = \\frac{1}{3} \\cdot 0 = 0\\).\nPentru criteriul NP, \\(P_p = \\frac{1}{3} \\cdot (2.94 - 2)\\frac{1}{6} = \\frac{0.94}{18}\\).\nÎn fine, pentru \\(T=3\\), \\(P_p = \\frac{1}{3} \\cdot 1 \\cdot \\frac{1}{6} = \\frac{1}{18}\\).\nc). Pentru un eșantion \\(r=3.1\\), tot ce avem de făcut este să verificăm în ce regiune de decizie se află acesta.\nPentru criteriul ML, \\(r=3.1 \\in R_1\\), decizia este \\(D_1\\).\nPentru criteriul MPE, \\(r=3.1 \\in R_1\\), decizia este \\(D_1\\).\nPentru criteriul MR, \\(r=3.1 \\in R_1\\), decizia este \\(D_1\\).\nPentru criteriul NP, \\(r=3.1 \\in R_1\\), decizia este \\(D_1\\).\nPentru pragul \\(T=3\\), \\(r=3.1 \\in R_1\\), decizia este \\(D_1\\).\nd). Pentru un \\(A\\) diferit de 5, distribuția lui \\(w(r|H_1)\\) se va întinde între \\(A-3\\) și \\(A+3\\). Dacă \\(A \\geq 6\\), atunci funcțiile nu se suprapun, iar \\(P_p = 0\\).\nDacă \\(A < 6\\), atunci funcțiile se suprapun, iar intervalul se suprapunere este \\([A-3, 3]\\). Acest interval face parte din regiunea de decizie \\(R_1\\), ceea ce înseamnă că probabilitatea \\(P(D_0|H_1)\\), care presupune integrarea funcției \\(w(r|H_1)\\) pe \\(R_0\\), este 0 întotdeauna.\nAșadar, \\(P_p = 0\\) indiferent de valoarea lui \\(A\\)."
  },
  {
    "objectID": "Ex_Seminar05.html#exercițiul-1",
    "href": "Ex_Seminar05.html#exercițiul-1",
    "title": "12  Seminar 05: Decizii cu mai multe eșantioane",
    "section": "12.1 Exercițiul 1",
    "text": "12.1 Exercițiul 1\nUn semnal poate avea două valori, \\(s_0(t) = 0\\) (ipoteza \\(H_0\\)) sau \\(s_1(t) = 6\\) (ipoteza \\(H_1\\)).\nSemnalul este afectat de zgomot gaussian \\(\\mathcal{N}(0, \\sigma^2=1)\\).\nLa recepție se iau 5 eșantioane, cu valorile \\(\\left\\{ 1.1, 4.4, 3.7, 4.1, 3.8 \\right\\}\\).\n\na). Ce decizie se ia cu criteriul ML?\nb). Ce decizie se ia cu criteriul MPE, dacă \\(P(H_0) = 2/3\\) and \\(P(H_1) = 1/3\\)?\nc). Care e intervalul de valori posibile ale lui \\(P(H_0)\\) pentru ca decizia cu criteriul MPE să fie \\(D_0\\)?\n\n\nRezolvare\nÎntrucât zgomotul este de tip gaussian, problema de decizie se reduce la compararea distanțelor euclidiene între semnalul recepționat și cele două semnale posibile. \\[d(\\mathbf{r}, \\mathbf{s_0})^2 \\grtlessH  d(\\mathbf{r}, \\mathbf{s_1})^2 + 2 \\sigma^2 \\ln(K)\\]\nÎntrucât decizia se ia pe baza a 5 eșantioane, \\(\\mathbf{r}\\), \\(\\mathbf{s_0}\\) și \\(\\mathbf{s_1}\\) sunt vectori cu 5 elemente.\n\n\n\n\n\n\nAtenție, eroare frecventă\n\n\n\nCând avem mai multe eșantioane, se lucrează cu vectori și se ia o singură decizie. Nu se iau \\(N\\) decizii pe baza fiecărui eșantion în parte.\n\n\nVectorul \\(\\mathbf{r}\\) cu eșantioanele observate este: \\[\\mathbf{r} = \\left[ 1.1, 4.4, 3.7, 4.1, 3.8 \\right]\\]\nVectorii \\(\\mathbf{s_0}\\) și \\(\\mathbf{s_1}\\) reprezintă valorile semnalelor originale \\(s_0(t)\\) și \\(s_1(t)\\), fără zgomot, la momentele de timp de eșantionare \\(t_1, t_2, \\ldots, t_N\\). Întrucât \\(s_0(t) = 0\\), cele 5 eșantioane ar trebui să fie toate 0, indiferent de momentul de timp: \\[\\mathbf{s_0} = \\left[ 0, 0, 0, 0, 0 \\right]\\] Iar pentru \\(s_1(t) = 6\\), avem: \\[\\mathbf{s_1} = \\left[ 6, 6, 6, 6, 6 \\right]\\]\nDecizia se ia comparând distanțele euclidiene. Avem: \\[d(\\mathbf{r}, \\mathbf{s_0})^2 = (1.1 - 0)^2 + (4.4 - 0)^2 + (3.7 - 0)^2 + (4.1 - 0)^2 + (3.8 - 0)^2 = 65.51\\] \\[d(\\mathbf{r}, \\mathbf{s_1})^2 = (1.1 - 6)^2 + (4.4 - 6)^2 + (3.7 - 6)^2 + (4.1 - 6)^2 + (3.8 - 6)^2 = 40.31\\]\na). Pentru criteriul ML, \\(K=1\\), \\(\\ln(K)=0\\) și decizia este dată de distanța cea mai mică: \\[d(\\mathbf{r}, \\mathbf{s_0})^2 > d(\\mathbf{r}, \\mathbf{s_1})^2 \\rightarrow D_1\\]\nb). Pentru criteriul MPE, \\(K\\) este: \\[K = \\frac{P(H_0)}{P(H_1)} = 2\\] \\[2 \\sigma^2 \\ln(K) = 2 \\cdot 1 \\cdot 0.69 = 1.38\\]\nDecizia este de asemenea \\(D_1\\): \\[65.51 > 40.31  + 1.38\\rightarrow D_1\\]\nc). Aici, trebuie să găsim valorile lui \\(P(H_0)\\) care conduc la decizia \\(D_0\\) cu criteriul MPE.\nProbabilitatea \\(P(H_0)\\) influențează doar termenul \\(K\\). Pentru ca decizia să fie \\(D_0\\), trebuie ca termenul din dreapta să depășească termenul din stânga în relația: \\[65.51 < 40.31  + 2 \\cdot 1 \\cdot \\ln(K) \\rightarrow D_0\\] \\[\\Leftrightarrow 2 \\ln(K) > 65.51-40.31\\] \\[\\Leftrightarrow \\ln(K) > 12.7\\] Aplicând \\(e^x\\) ambilor termeni, avem mai departe: \\[\\Leftrightarrow K > e^{12.7}\\] La rândul lui, \\(K = \\frac{P(H_0)}{P(H_1)}\\), iar \\(P(H_1)\\) nu este o variabilă independentă, ci depinde de \\(P(H_0)\\), fiind \\(P(H_1) = 1 - P(H_0)\\) (suma celor două probabilități este 1). Așadar, avem: \\[\\Leftrightarrow \\frac{P(H_0)}{1-P(H_0)} > e^{12.7}\\] \\[\\Leftrightarrow P(H_0) > e^{12.7} - P(H_0) \\cdot e^{12.7}\\] \\[\\Leftrightarrow P(H_0)(1 + e^{12.7}) > e^{12.7}\\] \\[\\Leftrightarrow P(H_0) > \\frac{e^{12.7}}{1 + e^{12.7}} = 0.99999694888\\]\nAșadar, pentru ca decizia să fie \\(D_0\\), probabilitatea \\(P(H_0)\\) trebuie să fie mai mare decât 0.99999694888."
  },
  {
    "objectID": "Ex_Seminar05.html#exercițiul-2",
    "href": "Ex_Seminar05.html#exercițiul-2",
    "title": "12  Seminar 05: Decizii cu mai multe eșantioane",
    "section": "12.2 Exercițiul 2",
    "text": "12.2 Exercițiul 2\nFie detecția unui semnal \\(s_1(t) = 3 \\sin(2 \\pi f_1 t)\\) care poate fi prezent (ipoteza \\(H_1\\)) sau absent (\\(s_0(t)=0\\), ipoteza \\(H_0\\)). Semnalul este afectat de zgomot gaussian \\(\\mathcal{ N}(0, \\sigma^2=1)\\). Valoarea lui \\(f_1 = 1\\). La recepție se iau două eșantioane la momentele de timp \\(t_1\\) și \\(t_2\\).\nLa recepție se iau citesc două eșantioane cu valorile \\(\\left\\{ 1.1, 4.4 \\right\\}\\), la momentele de timp \\(t_1 = 0.125\\) și \\(t_2 = 0.625\\).\nProbabilitățile a priori sunt \\(P(H_0) = 1/3\\) și \\(P(H_1) = 2/3\\).\nCe decizie se ia cu criteriul Minimum Probability of Error?\n\nRezolvare\nDiferența față de exercițiul anterior este că semnalul \\(s_1(t)\\) nu mai este constant. În rest, zgomotul fiind tot de natură gaussiană, se procedează la fel ca în exercițiul anterior, lucrând cu vectori de două elemente.\nVectorul observațiilor este: \\[\\mathbf{r} = \\left[ 1.1, 4.4 \\right]\\] La momentele de timp \\(t_1 = 0.125\\) și \\(t_2 = 0.625\\), semnalul \\(s_0(t) = 0\\) are valorile: \\[\\mathbf{s_0} = \\left[ 0, 0 \\right]\\] iar semnalul \\(s_1(t) = 3 \\sin(2 \\pi f_1 t)\\) are valorile: \\[\n\\begin{align}\n\\mathbf{s_1} &= \\left[ 3 \\sin(2 \\pi f_1 t_1), 3 \\sin(2 \\pi f_1 t_2) \\right] \\\\\n&= \\left[ 3 \\sin(2 \\pi \\cdot 1 \\cdot 0.125), 3 \\sin(2 \\pi \\cdot 1 \\cdot 0.625) \\right] \\\\\n&= \\left[ 3 \\sin(\\frac{\\pi}{4}), 3 \\sin(\\frac{5\\pi}{4})\\right] \\\\\n&= \\left[ 2.12, -2.12 \\right]\n\\end{align}\n\\]\nAplicăm criteriul MPE, folosind relația \\(d(\\mathbf{r}, \\mathbf{s_0})^2 \\grtlessH d(\\mathbf{r}, \\mathbf{s_1})^2 + 2 \\sigma^2 \\ln(K)\\). \\[d(\\mathbf{r}, \\mathbf{s_0})^2 = (1.1 - 0)^2 + (4.4 - 0)^2 = 20.57\\] \\[d(\\mathbf{r}, \\mathbf{s_1})^2 = (1.1 - 2.12)^2 + (4.4 + 2.12)^2 = 43.55\\] \\[2\\sigma^2 \\ln(K) = 2 \\cdot 1 \\cdot \\ln(\\frac{1}{2}) = -1.38\\]\nDecizia este \\(D_0\\): \\[20.57 < 43.55 - 1.38 \\rightarrow D_0\\]"
  },
  {
    "objectID": "Ex_Seminar05.html#exercițiul-3",
    "href": "Ex_Seminar05.html#exercițiul-3",
    "title": "12  Seminar 05: Decizii cu mai multe eșantioane",
    "section": "12.3 Exercițiul 3",
    "text": "12.3 Exercițiul 3\nUn semnal transmis poate avea forma \\(s_0(t)\\) sau \\(s_1(t)\\), conform figurilor. La recepție se primește semnalul \\(r(t)\\) reprezentat în figură. Semnalul este afectat de zgomot gaussian \\(\\mathcal{N}(0, \\sigma^2=2)\\). Se consideră \\(P(H_0) = \\frac{1}{4}\\) și \\(P(H_1) = \\frac{3}{4}\\).\nGăsiți decizia conform criteriului MPE, în două cazuri distincte:\n\nfolosind trei eșantioane luate la momentele de timp \\(t_1 = 0.5\\), \\(t_2 = 1.5\\) și \\(t_2 = 3.5\\)\nfolosind metoda observației continue (fără eșantionare)\n\n       \n\nRezolvare\n\nZgomotul fiind cu distribuție normală, procedăm ca în exercițiile anterioare, lucrând cu vectori de 3 elemente.\n\nÎntrucât nu avem expresiile semnalelor, ci doar reprezentări grafice, vom lua valorile semnalelor din figuri.\nLa momentele de timp \\(t_1 = 0.5\\), \\(t_2 = 1.5\\) și \\(t_2 = 3.5\\), semnalul \\(s_0(t)\\) are valorile: \\[\\mathbf{s_0} = \\left[ 2, 2, -2 \\right]\\] semnalul \\(s_1(t)\\) are valorile: \\[\\mathbf{s_1} = \\left[ -2, -2, 2 \\right]\\] iar semnalul recepționat \\(r(t)\\) are valorile: \\[\\mathbf{r} = \\left[ -1, -1, 1 \\right]\\]\nAvem: \\[d(\\mathbf{r}, \\mathbf{s_0})^2 = (-1 - 2)^2 + (-1 - 2)^2 + (1 + 2)^2 = 27\\] \\[d(\\mathbf{r}, \\mathbf{s_1})^2 = (-1 + 2)^2 + (-1 + 2)^2 + (1 - 2)^2 = 3\\] \\[2\\sigma^2 \\ln(K) = 2 \\cdot 2 \\cdot \\ln(\\frac{1}{3}) = -4.39\\] \\[d(\\mathbf{r}, \\mathbf{s_0})^2 >  d(\\mathbf{r}, \\mathbf{s_1})^2 + 2\\sigma^2 \\ln(K) \\Rightarrow D_1\\] Decizia este \\(D_1\\).\nb). În cazul observației continue, nu mai lucrăm cu vectori, ci direct cu funcțiile continue ale semnalelor \\(s_0(t)\\), \\(s_1(t)\\) și \\(r(t)\\).\nSe folosește aceeași comparație: \\[d(r(t), s_0(t))^2 \\grtlessH  d(r(t), s_1(t))^2 + 2 \\sigma^2 \\ln(K)\\] doar că acum distanțele sunt calculate ca integrale. Distanța (la pătrat) între două semnale continue \\(a(t)\\) și \\(b(t)\\) este: \\[d(\\; a(t), b(t) \\;)^2 = \\int_{-\\infty}^{\\infty} \\left( a(t) - b(t) \\right) ^2 dt\\]\nÎn cazul nostru, distanțele între semnale pot fi calculate în mod grafic. Pornind de la reprezentarea grafică a semnalelor \\(r(t)\\) și \\(s_0(t)\\), reprezentăm mai jos semnalul diferență \\(r(t) - s_0(t)\\), apoi acest semnal ridicat la pătrat, iar apoi îi calculăm integrala ca aria de sub grafic. \nÎn mod similar calculăm distanța între \\(r(t)\\) și \\(s_1(t)\\): \nCu aceste distanțe calculate, putem calcula decizia luată cu criteriul MPE: \\[d(r(t), s_0(t))^2 = 28\\] \\[d(r(t), s_1(t))^2 = 12\\] \\[d(\\mathbf{r}, \\mathbf{s_0})^2 >  d(\\mathbf{r}, \\mathbf{s_1})^2 + 2\\sigma^2 \\ln(K) \\Rightarrow D_1\\] Decizia este \\(D_1\\)."
  },
  {
    "objectID": "Ex_Seminar06.html#exercițiul-1-k-nn",
    "href": "Ex_Seminar06.html#exercițiul-1-k-nn",
    "title": "13  Seminar 06: K-NN, K-Means, estimare ML",
    "section": "13.1 Exercițiul 1: k-NN",
    "text": "13.1 Exercițiul 1: k-NN\n\nFie următorul set de 10 vectori, compus din 5 vectori din clasa A și 5 vectori din clasa B:\n\nClasa A: \\[\\mathbf{v}_1 = \\begin{bmatrix}2 \\\\ -4\\end{bmatrix}\\;\n\\mathbf{v}_2 = \\begin{bmatrix}1 \\\\ -5\\end{bmatrix}\\;\n\\mathbf{v}_3 = \\begin{bmatrix}-2 \\\\ 6\\end{bmatrix}\\;\n\\mathbf{v}_4 = \\begin{bmatrix}-3 \\\\ 4\\end{bmatrix}\\;\n\\mathbf{v}_5 = \\begin{bmatrix}2 \\\\ -5\\end{bmatrix}\\]\nClasa B: \\[\\mathbf{v}_6 = \\begin{bmatrix}3 \\\\ 1\\end{bmatrix}\\;\n\\mathbf{v}_7 = \\begin{bmatrix}-1 \\\\ 1\\end{bmatrix}\\;\n\\mathbf{v}_8 = \\begin{bmatrix}-4 \\\\ -3\\end{bmatrix}\\;\n\\mathbf{v}_9 = \\begin{bmatrix}-3 \\\\ 0\\end{bmatrix}\\;\n\\mathbf{v}_{10} = \\begin{bmatrix}-2 \\\\ 3\\end{bmatrix}\\]\n\n\nCalculați clasa vectorului \\(\\mathbf{x} = \\begin{bmatrix}-2 \\\\ 5 \\end{bmatrix}\\) folosind algoritmul k-NN, pentru diverse valori ale lui \\(k\\): \\(k=1\\), \\(k=3\\), \\(k=5\\), \\(k=7\\) și \\(k=9\\)\n\nRezolvare\nPentru a calcula clasa vectorului \\(\\mathbf{x}\\) folosind algoritmul k-NN, trebuie să găsim cei mai apropiați \\(k\\) vecini ai săi din setul de vectori dat și să determinăm clasa majoritară dintre acești vecini. Vom face acest lucru pentru fiecare valoare a lui \\(k\\): 1, 3, 5, 7 și 9.\nVecinii se determină folosind distanța Euclidiană între vectori. \\[d(\\mathbf{x}, \\mathbf{v}_i) = \\sqrt{ (x_1 - v_{i1})^2 + (x_2 - v_{i2})^2}\\]\nPentru \\(\\mathbf{x} = \\begin{bmatrix}-2 \\\\ 5 \\end{bmatrix}\\), distanțele față de vectorii din setul de date sunt: \\[d(\\mathbf{x}, \\mathbf{v}_1)    = \\sqrt{ (-2 - 2)^2  +  (5 + 4)^2} = \\sqrt{97}\\] \\[d(\\mathbf{x}, \\mathbf{v}_2)    = \\sqrt{ (-2 - 1)^2  +  (5 + 5)^2} = \\sqrt{109}\\] \\[d(\\mathbf{x}, \\mathbf{v}_3)    = \\sqrt{ (-2 + 2)^2  +  (5 - 6)^2} = \\sqrt{1}\\] \\[d(\\mathbf{x}, \\mathbf{v}_4)    = \\sqrt{ (-2 + 3)^2  +  (5 - 4)^2} = \\sqrt{2}\\] \\[d(\\mathbf{x}, \\mathbf{v}_5)    = \\sqrt{ (-2 - 2)^2  +  (5 + 5)^2} = \\sqrt{116}\\] \\[d(\\mathbf{x}, \\mathbf{v}_6)    = \\sqrt{ (-2 - 3)^2  +  (5 - 1)^2} = \\sqrt{41}\\] \\[d(\\mathbf{x}, \\mathbf{v}_7)    = \\sqrt{ (-2 + 1)^2  +  (5 - 1)^2} = \\sqrt{17}\\] \\[d(\\mathbf{x}, \\mathbf{v}_8)    = \\sqrt{ (-2 + 4)^2  +  (5 + 3)^2} = \\sqrt{68}\\] \\[d(\\mathbf{x}, \\mathbf{v}_9)    = \\sqrt{ (-2 + 3)^2  +  (5 - 0)^2} = \\sqrt{26}\\] \\[d(\\mathbf{x}, \\mathbf{v}_{10}) = \\sqrt{ (-2 + 2)^2  +  (5 - 3)^2} = \\sqrt{4}\\]\nAranjăm distanțele în ordine crescătoare: \\[\\sqrt{1}, \\sqrt{2}, \\sqrt{4}, \\sqrt{17}, \\sqrt{26}, \\sqrt{41}, \\sqrt{68}, \\sqrt{97}, \\sqrt{109}, \\sqrt{116}\\] care corespund cu următorii vecini ai lui \\(\\mathbf{x}\\), de la cel mai apropiat la cel mai îndepărtat: \\[\\mathbf{v}_3, \\mathbf{v}_4, \\mathbf{v}_{10}, \\mathbf{v}_7, \\mathbf{v}_9, \\mathbf{v}_6, \\mathbf{v}_8, \\mathbf{v}_1, \\mathbf{v}_2, \\mathbf{v}_5\\]\nDecizia asupra clasei vectorului \\(\\mathbf{x}\\) se ia în funcție de clasa majoritară a celor mai apropiați vecini ai săi, în număr de \\(k\\).\nPentru \\(k=1\\): considerăm doar primul vecin, \\(\\mathbf{v}_3\\), din clasa A, deci clasa lui \\(\\mathbf{x}\\) este A.\nPentru \\(k=3\\): primii \\(3\\) vecini sunt \\(\\mathbf{v}_3\\), \\(\\mathbf{v}_4\\) și \\(\\mathbf{v}_{10}\\), dintre care doi sunt din clasa A și unul din clasa B, deci clasa lui \\(\\mathbf{x}\\) este A.\nPentru \\(k=5\\): vecinii sunt \\(\\mathbf{v}_3\\), \\(\\mathbf{v}_4\\), \\(\\mathbf{v}_{10}\\), \\(\\mathbf{v}_7\\) și \\(\\mathbf{v}_9\\), dintre care doi sunt din clasa A și trei din clasa B, deci clasa lui \\(\\mathbf{x}\\) este B.\nPentru \\(k=7\\): vecinii sunt \\(\\mathbf{v}_3\\), \\(\\mathbf{v}_4\\), \\(\\mathbf{v}_{10}\\), \\(\\mathbf{v}_7\\), \\(\\mathbf{v}_9\\), \\(\\mathbf{v}_6\\) și \\(\\mathbf{v}_8\\), dintre care doi sunt din clasa A și cinci din clasa B, deci clasa lui \\(\\mathbf{x}\\) este B.\nPenru \\(k=9\\): vecinii sunt \\(\\mathbf{v}_3\\), \\(\\mathbf{v}_4\\), \\(\\mathbf{v}_{10}\\), \\(\\mathbf{v}_7\\), \\(\\mathbf{v}_9\\), \\(\\mathbf{v}_6\\), \\(\\mathbf{v}_8\\), \\(\\mathbf{v}_1\\) și \\(\\mathbf{v}_2\\), dintre care patru sunt din clasa A și cinci din B, deci clasa lui \\(\\mathbf{x}\\) este B."
  },
  {
    "objectID": "Ex_Seminar06.html#exercițiul-2-k-means",
    "href": "Ex_Seminar06.html#exercițiul-2-k-means",
    "title": "13  Seminar 06: K-NN, K-Means, estimare ML",
    "section": "13.2 Exercițiul 2: k-Means",
    "text": "13.2 Exercițiul 2: k-Means\nFie următoarele zece valori numerice: \\[\\mathbf{v} = \\left\\lbrace v_i \\right\\rbrace = [ 1.1, 0.9,\n5.5, 0.6, 5, 6, 1.3, 4.8, 6, 0.8 ] \\]\nEfectuați cinci iterații ale algoritmul k-Means pentru a găsi doi centroizi \\(\\mathbf{c}_1\\) și \\(\\mathbf{c}_2\\), pornind de la două valori aleatoare \\(\\mathbf{c}_1 = 0.95\\) și \\(\\mathbf{c}_2 = 0.96\\).\n\nRezolvare\nAlgoritmul k-Means urmărește găsirea a \\(k\\) centroizi care se grupeze datele de intrare în clustere bine definite.\nAlgoritmul are următorii pași:\n\nSe aleg \\(k\\) centroizi inițiali \\(\\mathbf{c}_1, \\mathbf{c}_2, \\dots, \\mathbf{c}_k\\). În cazul nostru, valorile inițiale sunt date: \\(\\mathbf{c}_1 = 0.95\\) și \\(\\mathbf{c}_2 = 0.96\\).\nPentru fiecare vector \\(\\mathbf{v}\\) din setul de date, se calculează distanțele față de fiecare centroid, \\(d(\\mathbf{v}, \\mathbf{c}_i)\\), și vectorul este asignat centroidului cel mai apropiat.\nSe recalculează centroizii ca fiind media vectorilor care au fost asignați fiecărui centroid în parte\nSe repetă pașii 2-4 până când centroizii nu se mai modifică, sau se atinge numărul maxim de iterații.\n\nÎn cazul nostru, avem \\(k=2\\) și \\(N=10\\) vectori de intrare (numerele individuale).\nLa iterația 1:\n\nnumerele asignate lui \\(c_1 = 0.95\\) sunt: \\([0.9, 0.6, 0.8]\\), iar cele asignate lui \\(c_2 = 0.96\\) sunt: \\([1.1, 5.5, 5, 6, 1.3, 4.8, 6]\\)\nrecalculăm centroizii: \\[c_1 = \\frac{0.9 + 0.6 + 0.8}{3} = 0.77\\] \\[c_2 = \\frac{1.1 + 5.5 + 5 + 6 + 1.3 + 4.8 + 6}{7} = 4.2\\]\n\nLa iterația 2:\n\nnumerele asignate lui \\(c_1 = 0.77\\) sunt: \\([0.9, 0.6, 0.8, 1.1, 1.3]\\), iar cele asignate lui \\(c_2 = 4.2\\) sunt: \\([5.5, 5, 6, 4.8, 6]\\)\nrecalculăm centroizii: \\[c_1 = \\frac{0.9 + 0.6 + 0.8 + 1.1 + 1.3}{5} = 0.94\\] \\[c_2 = \\frac{5.5 + 5 + 6 + 4.8 + 6}{5} = 5.46\\]\n\nLa iterația 3:\n\nnumerele asignate lui \\(c_1 = 0.94\\) sunt: \\([0.9, 0.6, 0.8, 1.1, 1.3]\\), iar cele asignate lui \\(c_2 = 5.46\\) sunt: \\([5.5, 5, 6, 4.8, 6]\\)\nrecalculăm centroizii: \\[c_1 = \\frac{0.9 + 0.6 + 0.8 + 1.1 + 1.3}{5} = 0.94\\] \\[c_2 = \\frac{5.5 + 5 + 6 + 4.8 + 6}{5} = 5.46\\]\n\nSe observă că centroizii nu se mai modifică, deci din acest moment iteratițiile pot fi terminate algoritmul converge.\nRezultatul final este cel de la ultima iterație:\n\ncentroidul \\(c_1\\) este \\(c_1 = 0.94\\) și are asignate numerele \\([0.9, 0.6, 0.8, 1.1, 1.3]\\)\ncentroidul \\(c_2\\) este \\(c_2 = 5.46\\) și are asignate numerele \\([5.5, 5, 6, 4.8, 6]\\)"
  },
  {
    "objectID": "Ex_Seminar06.html#exercițiul-3-estimare-ml",
    "href": "Ex_Seminar06.html#exercițiul-3-estimare-ml",
    "title": "13  Seminar 06: K-NN, K-Means, estimare ML",
    "section": "13.3 Exercițiul 3: estimare ML",
    "text": "13.3 Exercițiul 3: estimare ML\nSe recepționează un semnal constant de amplitudine necunoscută A, afectat de zgomot gaussian, \\(r(t) = \\underbrace{A}_{s_\\Theta(t)} + zgomot\\), unde zgomotul este de tip gaussian \\(\\mathcal{N}(\\mu = 0, \\sigma^2 = 2)\\).\nSemnalul este eșantionat la momentele \\(t_i = [0,1.5,3,4]\\) și se observă valorile \\(r_i = [4.6, 5.2, 5.35, 4.8]\\).\nEstimați valoarea lui A folosind estimarea Maximum Likelihood\n\nRezolvare\nÎntrucât zgomotul este de tip gaussian, estimarea Maximum Likelihood (ML) se reduce la problema minimizării distanței Euclidiene între semnalul observat și semnalul original. \\[\\hat{A}_{ML} = \\arg \\min_{A} d(\\mathbf{r}, \\mathbf{s})^2\\]\nVectorul observații este cel dat în problemă: \\[\\mathbf{r} = [4.6, 5.2, 5.35, 4.8]\\]\nVectorul semnalului original este ceea ce ar fi trebuit să observăm la cele patru momentele de timp \\(t_i = [0,1.5,3,4]\\) dacă nu ar fi existat zgomot, adică \\(A\\): \\[\\mathbf{s} = [A, A, A, A]\\]\nDistanța Euclidiană la pătrat între cei doi vectori este: \\[d(\\mathbf{r}, \\mathbf{s}) = (A - 4.6)^2 + (A - 5.2)^2 + (A - 5.35)^2 + (A - 4.8)^2\\]\nVrem să găsim valoarea lui \\(A\\) care minimizează această distanță. Pentru aceasta, derivăm expresia după \\(A\\) și o egalam cu 0: \\[\\frac{\\partial d(\\mathbf{r}, \\mathbf{s})}{\\partial A} =\n2 \\cdot (A - 4.6) + 2 \\cdot (A - 5.2) + 2 \\cdot (A - 5.35) + 2 \\cdot (A - 4.8) = 0\\]\nRezolvând aceasta ecuație, obținem estimarea ML a lui A: \\[\\hat{A}_{ML} = \\frac{4.6 + 5.2 + 5.35 + 4.8}{4} = 4.9875\\]"
  },
  {
    "objectID": "Ex_Seminar06.html#exercițiul-4-estimare-ml",
    "href": "Ex_Seminar06.html#exercițiul-4-estimare-ml",
    "title": "13  Seminar 06: K-NN, K-Means, estimare ML",
    "section": "13.4 Exercițiul 4: estimare ML",
    "text": "13.4 Exercițiul 4: estimare ML\nUn semnal de forma \\(r(t) = A \\cdot t^2 + 2 + zgomot\\) este eșantionat la momentele \\(t_i = [1,2,3,4,5]\\), și valorile obținute sunt \\(r_i = [1.2, 3.7, 8.5, 18, 25.8]\\). Distribuția zgomotului este \\(\\mathcal{N}(0,\\sigma^2=1)\\).\nEstimați parametrul \\(A\\) folosind estimarea ML.\n\nRezolvare\nSingura diferență față de exercițiul anterior este că semnalul original nu mai este constant, ci este de forma \\(A \\cdot t^2 + 2\\).\nAșadar, valorile semnalului original la momentele de eșantionare \\(t_i = [1,2,3,4,5]\\) sunt: \\[\\mathbf{s} = [A + 2, \\;\\; 4A + 2, \\;\\; 9A + 2, \\;\\; 16A + 2, \\;\\;25A + 2]\\]\nDistanța Euclidiană la pătrat între cei doi vectori este:\n\\[\\begin{aligned}\nd(\\mathbf{r}, \\mathbf{s}) &= (A + 2 - 1.2)^2 + (4A + 2 - 3.7)^2 + (9A + 2 - 8.5)^2 + (16A + 2 - 18)^2 + (25A + 2 - 25.8)^2 \\\\\n&= (A + 0.8)^2 + (4A - 1.7)^2 + (9A - 6.5)^2 + (16A - 16)^2 + (25A - 23.8)^2\n\\end{aligned}\\]\nDerivând expresia după \\(A\\) și o egalam cu 0, obținem estimarea ML a lui A: \\[\\frac{\\partial d(\\mathbf{r}, \\mathbf{s})}{\\partial A} =\n2 \\cdot (A + 0.8) + 2 \\cdot (4A - 1.7) \\cdot 4 + 2 \\cdot (9A - 6.5) \\cdot 9 + 2 \\cdot (16A - 16) \\cdot 16 + 2 \\cdot (25A - 23.8) \\cdot 25 = 0\\]\nRezolvând aceasta ecuație, obținem estimarea ML a lui A: \\[\\hat{A}_{ML} = \\frac{-0.8 + 1.7 \\cdot 4 + 6.5 \\cdot 9 + 16 \\cdot 16 + 23.8 \\cdot 25}{1 + 4^2 + 9^2 + 16^2 + 25^2} = 0.93\\]"
  },
  {
    "objectID": "Ex_Seminar06.html#exercițiul-5-estimare-ml",
    "href": "Ex_Seminar06.html#exercițiul-5-estimare-ml",
    "title": "13  Seminar 06: K-NN, K-Means, estimare ML",
    "section": "13.5 Exercițiul 5: estimare ML",
    "text": "13.5 Exercițiul 5: estimare ML\nValorile măsurate ale unei funcții liniare \\(y = ax\\), unde \\(a\\) este necunoscut, sunt următoarele: \\((x_i, y_i) = {(1,1.8),(2,4.1),(2.5, 5.1),(4,7.9),(4.3, 8.5)}\\). Presupunând că zgomotul are distribuția \\(\\mathcal{N}(0,\\sigma^2=1)\\), estimați valoarea lui \\(a\\) folosind estimarea ML\n\nRezolvare\nSuntem în același caz ca la exercițiile anterioare, doar că de data aceasta avem ușor altă formulare a problemei.\nÎn loc sa avem eșantioane din \\(r(t)\\) la momente de timp \\(t_i\\), avem eșantioane din \\(y(x)\\) la valori ale lui \\(x_i\\). Așadar, valorile \\(y_i\\) joacă rolul valorilor \\(r_i\\) din exercițiile anterioare, iar \\(x_i\\) rolul lui \\(t_i\\).\nValorile măsurate sunt cele ale \\(y_i\\): \\[\\mathbf{r} = \\mathbf{y} = [1.8, 4.1, 5.1, 7.9, 8.5]\\]\nÎn absența zgomotului, pentru o funcție liniară \\(y = ax\\), valorile semnalului original la valorile \\(x_i = [1,2,2.5,4,4.3]\\) ar fi fost: \\[\\mathbf{s} = [a \\cdot 1, \\;\\; a \\cdot 2, \\;\\; a \\cdot 2.5, \\;\\; a \\cdot 4, \\;\\; a \\cdot 4.3]\\]\nZgomotul fiind de tip gaussian, estimarea ML înseamnă minimizarea distanței Euclidiene între \\(\\mathbf{r}\\) și \\(\\mathbf{s}\\): \\[d(\\mathbf{r}, \\mathbf{s})^2 = (a-1.8)^2 + (2a-4.1)^2 + (2.5a-5.1)^2 + (4a-7.9)^2 + (4.3a-8.5)^2\\]\nAflăm minimul expresiei prin derivare și egalare cu 0: \\[\\frac{\\partial d(\\mathbf{r}, \\mathbf{s})}{\\partial a} = 2 \\cdot (a-1.8) + 2 \\cdot (2a-4.1) \\cdot 2 + 2 \\cdot (2.5a-5.1) \\cdot 2.5 + 2 \\cdot (4a-7.9) \\cdot 4 + 2 \\cdot (4.3a-8.5) \\cdot 4.3 = 0\\]\nRezolvând aceasta ecuație, obținem estimarea ML a lui A: \\[\\hat{a}_{ML} = \\frac{1.8 + 4.1 \\cdot 2 + 5.1 \\cdot 2.5 + 7.9 \\cdot 4 + 8.5 \\cdot 4.3}{1 + 4 + 2.5^2 + 16 + 4.3^2} = 2.29\\]"
  },
  {
    "objectID": "Ex_Seminar06.html#exercițiul-6-estimare-ml-cu-mai-mulți-parametri",
    "href": "Ex_Seminar06.html#exercițiul-6-estimare-ml-cu-mai-mulți-parametri",
    "title": "13  Seminar 06: K-NN, K-Means, estimare ML",
    "section": "13.6 Exercițiul 6: estimare ML cu mai mulți parametri",
    "text": "13.6 Exercițiul 6: estimare ML cu mai mulți parametri\nUn robot se deplasează pe o traiectorie liniară cu o viteză necunoscută \\(V\\) centimetri/secundă, pornind de la poziția \\(x = 0\\) la momentul inițial.\nLa intervale de o secundă, robotul măsoară distanța parcursă folosind un senzor, afectat de zgomot gaussian \\(\\mathcal{N}(0,\\sigma^2=0.1)\\).\nValorile măsurate la momentele \\(t_i = [1,2,3,4,5]\\) sunt \\(r_i = [4.9, 9.8, 14.3, 21.2, 25.7]\\)\nCerințe:\n\nEstimați viteza \\(V\\) a robotului folosind estimarea ML\nHint: Dacă viteza e constantă, distanta parcursă ar trebui să fie \\(x = V \\cdot t\\)\nPreziceți poziția robotului la momentul \\(6\\).\nDacă presupunem la momentul inițial poziția robotului nu este 0, ci o valoare necunoscută \\(x_0\\), estimați perechea de parametri [V, \\(x_0\\)] folosind estimarea ML. Preziceți poziția robotului la momentul \\(6\\).\nȘtiind că legea de mișcare este \\(x(t) = \\frac{a \\cdot t^2}{2} + v_0 \\cdot t + x_0\\), scrieți sistemul de ecuații pentru găsirea necunoscutelor [a, \\(v_0\\), \\(x_0\\)]. (accelerația constantă \\(a\\), viteza inițială \\(v_0\\), poziția inițială\\(x_0\\)).\n\n\nRezolvare\nAvem de a face cu estimarea ML în zgomot gaussian, deci vom proceda similar cu exercițiile anterioare.\n\nViteza robotului fiind constantă, poziția sa este dată de legea de mișcare \\[x(t) = V \\cdot t\\]\nÎn absența zgomotului, valorile poziției la momentele \\(t_i = [1,2,3,4,5]\\) ar fi fost: \\[\\mathbf{s} = [V \\;\\; 2V, \\;\\; 3V, \\;\\; 4V, \\;\\; 5V],\\] dar valorile observate sunt: \\[\\mathbf{r} = [4.9, 9.8, 14.3, 21.2, 25.7]\\]\nDistanța Euclidiană la pătrat între cei doi vectori este: \\[d(\\mathbf{r}, \\mathbf{s})^2 = (V - 4.9)^2 + (2V - 9.8)^2 + (3V - 14.3)^2 + (4V - 21.2)^2 + (5V - 25.7)^2\\] Derivăm: \\[\\frac{\\partial d(\\mathbf{r}, \\mathbf{s})}{\\partial V} = 2 \\cdot (V - 4.9) + 2 \\cdot (2V - 9.8) \\cdot 2 + 2 \\cdot (3V - 14.3) \\cdot 3 + 2 \\cdot (4V - 21.2) \\cdot 4 + 2 \\cdot (5V - 25.7) \\cdot 5 = 0\\] și obținem viteza: \\[\\hat{V}_{ML} = \\frac{4.9 + 9.8 \\cdot 2 + 14.3 \\cdot 3 + 21.2 \\cdot 4 + 25.7 \\cdot 5}{1 + 4 + 9 + 16 + 25} = 5.10\\]\nPrezicem poziția la momentul \\(t=6\\) aplicând aceeași lege de mișcare, folosind viteza estimată: \\[x(6) = 5.10 \\cdot 6 = 30.6\\]\nDacă poziția inițială este valoare necunoscută \\(x_0\\), atunci avem de estimat doi parametri: \\(V\\) și \\(x_0\\). Acest lucru se face în mod asemănător, după cum urmează.\nÎn absența zgomotului, valorile poziției la momentele \\(t_i = [1,2,3,4,5]\\) ar fi fost: \\[\\mathbf{s} = [V + x_0, \\;\\; 2V + x_0, \\;\\; 3V + x_0, \\;\\; 4V + x_0, \\;\\; 5V + x_0],\\] iar distanța pătratică față de valorile observate este: \\[d(\\mathbf{r}, \\mathbf{s})^2 = (V + x_0 - 4.9)^2 + (2V + x_0 - 9.8)^2 + (3V + x_0 - 14.3)^2 + (4V + x_0 - 21.2)^2 + (5V + x_0 - 25.7)^2\\]\nAvem acum o expresie cu două necunoscute, \\(V\\) și \\(x_0\\), pe care dorim să o minimizăm. Pentru aceasta derivăm după fiecare dintre ele, egalăm cu 0, și rezolvăm sistemul de ecuații astfel obținut.\nAvem: \\[\n\\begin{cases}\n\\frac{\\partial d(\\mathbf{r}, \\mathbf{s})}{\\partial V} = 2 \\cdot (V + x_0 - 4.9) + 2 \\cdot (2V + x_0 - 9.8) \\cdot 2 + 2 \\cdot (3V + x_0 - 14.3) \\cdot 3 + 2 \\cdot (4V + x_0 - 21.2) \\cdot 4 + 2 \\cdot (5V + x_0 - 25.7) \\cdot 5 = 0 \\\\\n\\frac{\\partial d(\\mathbf{r}, \\mathbf{s})}{\\partial x_0} = 2 \\cdot (V + x_0 - 4.9) + 2 \\cdot (2V + x_0 - 9.8) + 2 \\cdot (3V + x_0 - 14.3) + 2 \\cdot (4V + x_0 - 21.2) + 2 \\cdot (5V + x_0 - 25.7) = 0\n\\end{cases}\n\\] Simplificând și prelucrând relațiile, obținem: \\[\n\\begin{cases}\n55V + 15x_0 = 280.7 \\\\\n15V + 5x_0 = 75.9\n\\end{cases}\n\\] Rezolvând acest sistem, obținem soluția: \\[\\hat{V}_{ML} = 5.3, \\;\\; \\hat{x}_{0,ML} = -0.72\\]\nPentru a estima poziția la momentul \\(t=6\\), folosim aceeași lege de mișcare, cu parametrii estimati: \\[x(6) = V \\cdot 6 + x_0 = 5.3 \\cdot 6 - 0.72 = 31.08\\]\nLa punctul precedent am considerat o viteză constantă, deci accelerația egală cu 0. În cele ce urmează, considerăm un caz mai general, cu accelerație diferită de 0.\nLegea de mișcare este: \\[x(t) = \\frac{a \\cdot t^2}{2} + v_0 \\cdot t + x_0\\] unde \\(a\\) este accelerația, \\(v_0\\) este viteza inițială, iar \\(x_0\\) este poziția inițială. Toate cele trei mărimi sunt necunoscute care trebuie estimate.\nÎn absența zgomotului, valorile poziției la momentele \\(t_i = [1,2,3,4,5]\\) ar fi fost: \\[\\mathbf{s} = [\\frac{a}{2} + v_0 + x_0, \\;\\; 2a + 2v_0 + x_0, \\;\\; \\frac{9a}{2} + 3v_0 + x_0, \\;\\; 8a + 4v_0 + x_0, \\;\\; \\frac{25a}{2} + 5v_0 + x_0],\\] așadar distanța pătratică față de valorile observate este: \\[d(\\mathbf{r}, \\mathbf{s})^2 = (\\frac{a}{2} + v_0 + x_0 - 4.9)^2 + (2a + 2v_0 + x_0 - 9.8)^2 + (\\frac{9a}{2} + 3v_0 + x_0 - 14.3)^2 + (8a + 4v_0 + x_0 - 21.2)^2 + (\\frac{25a}{2} + 5v_0 + x_0 - 25.7)^2\\]\n\nCele trei derivate parțiale în raport cu necunoscutele formează un sistem de trei ecuații cu trei necunoscute, pe care îl rezolvăm pentru a obține estimările ML ale parametrilor: \\[\n\\begin{cases}\n\\frac{\\partial d(\\mathbf{r}, \\mathbf{s})}{\\partial a} = 2 \\cdot (\\frac{a}{2} + v_0 + x_0 - 4.9) \\cdot \\frac{1}{2} + 2 \\cdot (2a + 2v_0 + x_0 - 9.8) \\cdot 2 + 2 \\cdot (\\frac{9a}{2} + 3v_0 + x_0 - 14.3) \\cdot \\frac{9}{2} + 2 \\cdot (8a + 4v_0 + x_0 - 21.2) \\cdot 8 + 2 \\cdot (\\frac{25a}{2} + 5v_0 + x_0 - 25.7) \\cdot \\frac{25}{2} = 0 \\\\\n\\frac{\\partial d(\\mathbf{r}, \\mathbf{s})}{\\partial v_0} = 2 \\cdot (\\frac{a}{2} + v_0 + x_0 - 4.9) + 2 \\cdot (2a + 2v_0 + x_0 - 9.8) \\cdot 2 + 2 \\cdot (\\frac{9a}{2} + 3v_0 + x_0 - 14.3) \\cdot 3 + 2 \\cdot (8a + 4v_0 + x_0 - 21.2) \\cdot 4 + 2 \\cdot (\\frac{25a}{2} + 5v_0 + x_0 - 25.7) \\cdot 5 = 0 \\\\\n\\frac{\\partial d(\\mathbf{r}, \\mathbf{s})}{\\partial x_0} = 2 \\cdot (\\frac{a}{2} + v_0 + x_0 - 4.9) + 2 \\cdot (2a + 2v_0 + x_0 - 9.8) + 2 \\cdot (\\frac{9a}{2} + 3v_0 + x_0 - 14.3) + 2 \\cdot (8a + 4v_0 + x_0 - 21.2) + 2 \\cdot (\\frac{25a}{2} + 5v_0 + x_0 - 25.7) = 0\n\\end{cases}\n\\]\nRezolvarea acestui sistem este lăsată ca exercițiu pentru cititor."
  },
  {
    "objectID": "App01_OutlierDetection.html#python-implementation",
    "href": "App01_OutlierDetection.html#python-implementation",
    "title": "Outlier Detection with the 3-sigma Rule",
    "section": "Python implementation",
    "text": "Python implementation\nIn this application we study how to detect outliers from a time-series (i.e. a one-dimensional signal), using the 3-sigma rule.\nThe 3-sigma rule is simple:\n\nAny value which is more than \\(3 \\sigma\\) away from the mean value is an outlier.\n\nFirst, we need to import some libraries in Python\n\nimport numpy as numpy\nimport matplotlib.pyplot as plt\n\nSuppose we have the following data series.\nIn Python, with [ ] we create a list of objects. This list is then converted to a numpy array, which is similar to a Matlab array.\nA numpy array always has the attribute shape which indicates the shape of the data, e.g. the dimensions and length along each dimension.\n\ndata = np.array([20.1, 18.2, 19.9, 20.7, 18.9, 19.8, 214.33, 21.2, 20.5, 18.6, 22.3, 20.8, 19.7])\n\ndata.shape\n\n(13,)\n\n\nIf you see the shape (13,) above, this means your data array has a single dimension of size 13, i.e. it is a vector with 13 elements.\nLet’s compute the mean and the standard deviation of the data, using the functions: - numpy.mean() - numpy.std() - numpy.var() computes the variance (i.e. standard deviation squared) - We can use the shorthand notation np, since we imported numpy as np.\n\nmean = np.mean(data)\nstddev = np.std(data)   # ToMe: check ddof\nvar = np.var(data)      # We don't really need it, it's just for showing\n\nprint(f\"Mean = {mean}, standard deviation = {stddev}, variance = {var}\")  # Use f-strings\n\nMean = 35.002307692307696, standard deviation = 51.77831357057719, variance = 2680.9937562130176\n\n\nNow let’s check which values are more than \\(3 \\sigma\\) away from the mean, by checking if \\(|x - \\mu| > 3 \\sigma\\) for every value \\(x\\).\nnumpy.abs() does the absolute value of a number or array.\nThe resulting outliers is an array of the same shape as data, because of broadcasting rules: - data is an array - data - mean is an array - a scalar, which produces an array of same size as data, subtracting from each element the scalar value - np.abs() computes the absolute values, the shape stays the same (an array) - np.abs(...) > threshold is an array compared to a scalar, which produces an array of same size, comparing each element with the scalar\n\n# Set the threshold for outliers\nthreshold = 3 *stddev\n\n# Detect outliers\noutliers = np.abs(data - mean) > threshold\n\nprint(outliers)\n\n[False False False False False False  True False False False False False\n False]\n\n\nFinally, let’s do some plotting magic, using the matplotlib library (imported as plt).\n\nplt.plot() works similar to Matlab’s plot(), it draws a signal\nplt.scatter() places red circles at the locations of the outliers\nplt.text() places text at given locations\n\n\n# Display the time series data with outliers\nplt.plot(data)\nplt.scatter(np.where(outliers)[0], data[outliers], color='red')\n\n# Label the outliers\nfor i in range(len(data)):\n    if outliers[i]:\n        plt.text(i, data[i], str(data[i]), color='red')\n\nplt.show()"
  },
  {
    "objectID": "App01_OutlierDetection.html#matlab-implementation",
    "href": "App01_OutlierDetection.html#matlab-implementation",
    "title": "Outlier Detection with the 3-sigma Rule",
    "section": "Matlab implementation",
    "text": "Matlab implementation\nBelow is the same program, written in Matlab.\n% Calculate the mean and standard deviation of the data\nmeanValue = mean(data);\nstdDev = std(data);\n\n% Set the threshold for outliers\nthreshold = 3 * stdDev;\n\n% Detect outliers\noutliers = abs(data - meanValue) > threshold;\n\n% Display the time series data with outliers\nplot(data);\nhold on;\n\n% Mark the outliers on the plot\nscatter(find(outliers), data(outliers), 'ro');\nhold off;\n\n% Label the outliers\nfor i = 1:length(data)\n    if outliers(i)\n        text(i, data(i), num2str(data(i)), 'Color', 'red');\n    end\nend"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  }
]